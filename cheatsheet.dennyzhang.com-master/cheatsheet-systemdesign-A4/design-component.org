* System Design: Design Component                                 :Interview:
:PROPERTIES:
:type:     interview
:export_file_name: cheatsheet-systemdesign-A4.pdf
:END:
#+STARTUP: content
#+TAGS: noexport(n)
#+OPTIONS: toc:2
#+EXPORT_EXCLUDE_TAGS: exclude noexport
#+SEQ_TODO: TODO HALF ASSIGN | DONE BYPASS DELEGATE CANCELED DEFERRED
#+BEGIN_HTML
<a href="https://github.com/dennyzhang/cheatsheet.dennyzhang.com/tree/master/cheatsheet-systemdesign-A4"><img align="right" width="200" height="183" src="https://www.dennyzhang.com/wp-content/uploads/denny/watermark/github.png" /></a>
<div id="the whole thing" style="overflow: hidden;">
<div style="float: left; padding: 5px"> <a href="https://www.linkedin.com/in/dennyzhang001"><img src="https://www.dennyzhang.com/wp-content/uploads/sns/linkedin.png" alt="linkedin" /></a></div>
<div style="float: left; padding: 5px"><a href="https://github.com/dennyzhang"><img src="https://www.dennyzhang.com/wp-content/uploads/sns/github.png" alt="github" /></a></div>
<div style="float: left; padding: 5px"><a href="https://www.dennyzhang.com/slack" target="_blank" rel="nofollow"><img src="https://www.dennyzhang.com/wp-content/uploads/sns/slack.png" alt="slack"/></a></div>
</div>

<br/><br/>
<a href="http://makeapullrequest.com" target="_blank" rel="nofollow"><img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg" alt="PRs Welcome"/></a>
#+END_HTML
** Top K Frequent Elements in Recent X mins
Show top K frequent elements in the last 5 minutes, last 1 hour, last 1 day.

Similar Questions:
- Top URL hits

*** Typical Use Scenarios
*** Requirements With Clarifications
*** Scale
*** High Level Design
Algorithm(Time O(k), Space O(n)):
- LFU: double linked list + hashmap
- Sliding window: add at the right end, substract at the left end
*** Detail Design
*** Follow-up
*** Reference
- https://www.jiuzhang.com/qa/219/
- [[https://code.dennyzhang.com/top-k-frequent-elements][LeetCode: Top K Frequent Elements]]
*** misc                                                           :noexport:
https://www.1point3acres.com/bbs/forum.php?mod=viewthread&tid=461654&extra=&page=1
** Leaderboard Ranking
For realtime accurate ranking:

For realtime in-accurate ranking:
*** Typical Use Scenarios
*** Requirements With Clarifications
*** Scale
*** High Level Design
*** Detail Design
*** Follow-up
Follow-up: Support realtime ranking
- [[https://cloud.google.com/datastore/docs/articles/fast-and-reliable-ranking-in-datastore][Google: Fast and Reliable Ranking in Datastore]]
** Design a system checking the health of 10,000 nodes

Design a system that checks the health of 10,000 nodes. Each of 10,000 modes have an API exposed that you have to call and check the health. This API takes 1-5 seconds to respond. There is UI which tells which nodes are healthy OR not healthy. Your system should provide API for this UI. This UI refreshes every 10 mins. So, every 10 mins your system should be able to update data about those 10,000 nodes.
*** Typical Use Scenarios
*** Requirements With Clarifications
1. Users can always view the health of all nodes immediately.
2. Users are fine with not real-time data (10 minutes delay).
3. When some nodes are down, system should still functional. And be able to detect the failure.
*** Scale
1. QPS sent to dashboard system: **16.67 per second**.
   10K records send within 5 minute. 10000/(10\*60)=16.67

2. How big the record would be? **1 byte per record**.
   Let's say each record is 100 byte for unhealthy state including verbose error message. For healthy state, it's 1 byte. After checking the service SLA, let's assume the ratio of unhealthy/total is 0.01%. So the record size is 1.0099 (0.0001*100+0.9999*1).

3. How many hot data are stored? **43.2 GB**.
   Assume data retention is acceptable: Data older than 1 months can be discarded or moved to secondary storage.
   43,208,640 bytes(43.2 GB) = 1(byte)\*16.67(QPS)\*(30\*24\*60\*60)(1 month)
*** High Level Design
1. Data collection: push, pull or pull + push gateway
2. Related technologies: Nagios, Zabbix; Prometheus
*** Detail Design
** How to deploy 1GB binary to 10,000 servers
*** Typical Use Scenarios
*** Requirements With Clarifications
*** Scale
*** High Level Design
*** Detail Design
** Store 2TB data in three 1TB disks with redundancy
Say 2TB data is A and B. For three disks, we store data as A, B and A XOR B.

If any of three disks is down, we can still retrieve the original data: A and B.
** Merge big datasets in different servers
Many servers with 1 millions's records per server. How to sort it
*** Typical Use Scenarios
*** Requirements With Clarifications
*** Scale
*** High Level Design
*** Detail Design
*** Follow-up
** API Rate Limiter
*** Typical Use Scenarios
*** Requirements With Clarifications
*** Scale
*** High Level Design
*** Detail Design
Algorithm:
- Token bucket/Leaky bucket
- Fixed window
- Fixed log
- Sliding window
*** Follow-up
Follow-up: Build API rate limiter for a large scale service
- Sticky session in Loadbalancer
- Redis
- Lock-free with trade-off of accuracy

- [[https://medium.com/@saisandeepmopuri/system-design-rate-limiter-and-data-modelling-9304b0d18250][Medium: System Design — Rate limiter and Data modelling]]
** #  --8<-------------------------- separator ------------------------>8-- :noexport:
** Delayed task queue
*** Typical Use Scenarios
*** Requirements With Clarifications
*** Scale
*** High Level Design
*** Detail Design
*** Follow-up
** Spam Filter: design a system to block malicious IPs
*** Typical Use Scenarios
*** Requirements With Clarifications
- The granularity of blocking: whether to support blocking by subnet

[[https://github.com/pushinginertia/ip-blacklist/blob/master/ip_blacklist.conf][Github: ip-blacklist/ip_blacklist.conf]]

- Whether need TTL for the IP blocking?
- How big scale the traffic would be? The tolerance of the latency?
*** Scale
*** High Level Design
In-memory hashmap

K/V TTL: redis
*** Detail Design
*** Follow-up
Follow-up: how to support this feature for system with 20K+ QPS?
#+BEGIN_EXAMPLE
- Put IP blacklist to Redis
- Redis clustering
#+END_EXAMPLE
Industry Reference
- [[https://httpd.apache.org/docs/2.4/howto/access.html][Link: Apache Access Control]]
** How to implement redis clustering
*** Typical Use Scenarios
*** Requirements With Clarifications
*** Scale
*** High Level Design
Sharding + Active-passive replication

[[https://www.credera.com/blog/technology-insights/open-source-technology-insights/an-introduction-to-redis-cluster/][Link: An Introduction to Redis Cluster]]
*** Detail Design
*** Follow-up
Industry Reference

[[http://highscalability.com/blog/2014/9/8/how-twitter-uses-redis-to-scale-105tb-ram-39mm-qps-10000-ins.html][Link: How Twitter Uses Redis To Scale - 105TB RAM, 39MM QPS, 10,000+ Instances]]

[[https://www.youtube.com/watch?v=rP9EKvWt0zo][YouTube: Scaling Redis at Twitter]]
** Design twitter timeline feature
*** Typical Use Scenarios
*** Requirements With Clarifications
*** Scale
*** High Level Design
*** Detail Design
*** Follow-up
** Design a scalable notification service
*** Typical Use Scenarios
*** Requirements With Clarifications
*** Scale
*** High Level Design
*** Detail Design
*** Follow-up
** Real-time Deduping At Scale
*** Typical Use Scenarios
- Due to unreliable networks, clients may retry events until they receive a 200 OK message
- For MQ with at-least-once delivery, duplicate messages will be received
*** Requirements With Clarifications
- Dedeuplicatoin for how big of the time window?
- What's the expected accuracy?
*** Scale
*** High Level Design
How to identify duplicate events:

- K/V DB with uniq key + TTL
- If low accuracy is accepted, use bloom filters. (Need to keep rebuilding the bloom filter)
*** Detail Design
*** Follow-up
- [[https://amplitude.engineering/dedupe-events-at-scale-f9e416e46ca9][Medium: Deduplication at Scale]]
- [[http://eng.tapjoy.com/blog-list/real-time-deduping-at-scale][Link: REAL-TIME DEDUPING AT SCALE]]
- [[https://engineering.mixpanel.com/2019/07/18/petabyte-scale-data-deduplication/][Link: Petabyte Scale Data Deduplication]]
** How to upload large videos at scale
*** Typical Use Scenarios
*** Requirements With Clarifications
- Do we need to upload multiple resolution versions of video, or single version is fine?
- What is the expectation of upload latency?
*** Scale
*** High Level Design
Speed up uploading:

- Divide one binary video into multiple small segments

How to repair video, when it's inconsistent?
*** Detail Design
*** Follow-up
- [[https://instagram-engineering.com/video-upload-latency-improvements-at-instagram-bcf4b4c5520a][Medium: Video Upload Latency Improvements at Instagram]]
** Find duplicates files across 1000 servers with 10 million files
*** Typical Use Scenarios
*** Requirements With Clarifications
*** Scale
*** High Level Design
*** Detail Design
*** Follow-up
- [[https://www.1point3acres.com/bbs/forum.php?mod=viewthread&tid=303107&highlight=sre][易贝 SRE 面经]]
** Web crawler for 1 billion URL from 1 seed URL
*** Typical Use Scenarios
*** Requirements With Clarifications
*** Scale
*** High Level Design
*** Detail Design
*** Follow-up
** #  --8<-------------------------- separator ------------------------>8-- :noexport:
** How to lookup country name via a coordination of latitude, longitude?
