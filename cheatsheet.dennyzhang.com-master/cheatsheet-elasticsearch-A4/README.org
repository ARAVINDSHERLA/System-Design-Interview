* Elasticsearch CheatSheet                                            :Tools:
:PROPERTIES:
:type:     database
:export_file_name: cheatsheet-elasticsearch-A4.pdf
:END:

#+BEGIN_HTML
<a href="https://github.com/dennyzhang/cheatsheet.dennyzhang.com/tree/master/cheatsheet-elasticsearch-A4"><img align="right" width="200" height="183" src="https://www.dennyzhang.com/wp-content/uploads/denny/watermark/github.png" /></a>
<div id="the whole thing" style="overflow: hidden;">
<div style="float: left; padding: 5px"> <a href="https://www.linkedin.com/in/dennyzhang001"><img src="https://www.dennyzhang.com/wp-content/uploads/sns/linkedin.png" alt="linkedin" /></a></div>
<div style="float: left; padding: 5px"><a href="https://github.com/dennyzhang"><img src="https://www.dennyzhang.com/wp-content/uploads/sns/github.png" alt="github" /></a></div>
<div style="float: left; padding: 5px"><a href="https://www.dennyzhang.com/slack" target="_blank" rel="nofollow"><img src="https://www.dennyzhang.com/wp-content/uploads/sns/slack.png" alt="slack"/></a></div>
</div>

<br/><br/>
<a href="http://makeapullrequest.com" target="_blank" rel="nofollow"><img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg" alt="PRs Welcome"/></a>
#+END_HTML

- PDF Link: [[https://github.com/dennyzhang/cheatsheet.dennyzhang.com/blob/master/cheatsheet-elasticsearch-A4/cheatsheet-elasticsearch-A4.pdf][cheatsheet-elasticsearch-A4.pdf]], Category: [[https://cheatsheet.dennyzhang.com/category/tools/][tools]]
- Blog URL: https://cheatsheet.dennyzhang.com/cheatsheet-elasticsearch-A4
- Related posts: [[https://cheatsheet.dennyzhang.com/cheatsheet-couchbase-A4][Couchbase CheatSheet]], [[https://github.com/topics/denny-cheatsheets][#denny-cheatsheets]]

File me [[https://github.com/dennyzhang/cheatsheet.dennyzhang.com/issues][Issues]] or star [[https://github.com/dennyzhang/cheatsheet.dennyzhang.com][this repo]].
** Elasticsearch Summary
| Name                  | Command                                        |
|-----------------------+------------------------------------------------|
| elasticsearch-head[1] | A web tool: [[http://localhost:9200/_plugin/head/][$es_ip:$es_port/_plugin/head/]]      |
| elasticdump           | Import and export tools                        |
| Get cluster health    | =$es_ip:$es_port/_cluster/health?pretty=       |
| Get cluster setting   | =$es_ip:$es_port/_cluster/settings?v=          |
| Get Index Setting     | =$es_ip:$es_port/$es_name/_settings?v=         |
| List Nodes            | =$es_ip:$es_port/_cat/nodes?v=                 |
| List shards           | =$es_ip:$es_port/_cat/shards?v=                |
| List indices          | =$es_ip:$es_port/_cat/indices?v=               |
| Get allocation        | =$es_ip:$es_port/_cat/allocation?v=            |
| Get Version           | =$es_ip:$es_port=                              |
| Version By CLI        | =bin/elasticsearch --version=                  |
| Indice Summary        | =$es_ip:$es_port/$index/_count?pretty=         |
| Indice Stats          | =$es_ip:$es_port/$index/_stats?pretty=         |
| Get all docs          | =$es_ip:$es_port/$index/_search?pretty=        |
| Full Text Search      | =$es_ip:$es_port/$index/_search?q=50=          |
| Search By field       | =$es_ip:$es_port/$index/_search?q=f1:50=       |
| Search By 2 fields    | $es_ip:$es_port/$index/_search?q="f1:v1&f2=v2" |

** More Resources
https://www.dennyzhang.com/query_elasticsearch

License: Code is licensed under [[https://www.dennyzhang.com/wp-content/mit_license.txt][MIT License]].
#+BEGIN_HTML
<a href="https://cheatsheet.dennyzhang.com"><img align="right" width="201" height="268" src="https://raw.githubusercontent.com/USDevOps/mywechat-slack-group/master/images/denny_201706.png"></a>
<a href="https://cheatsheet.dennyzhang.com"><img align="right" src="https://raw.githubusercontent.com/dennyzhang/cheatsheet.dennyzhang.com/master/images/cheatsheet_dns.png"></a>

<a href="https://www.linkedin.com/in/dennyzhang001"><img align="bottom" src="https://www.dennyzhang.com/wp-content/uploads/sns/linkedin.png" alt="linkedin" /></a>
<a href="https://github.com/dennyzhang"><img align="bottom"src="https://www.dennyzhang.com/wp-content/uploads/sns/github.png" alt="github" /></a>
<a href="https://www.dennyzhang.com/slack" target="_blank" rel="nofollow"><img align="bottom" src="https://www.dennyzhang.com/wp-content/uploads/sns/slack.png" alt="slack"/></a>
#+END_HTML
* org-mode configuration                                           :noexport:
#+STARTUP: overview customtime noalign logdone showall
#+DESCRIPTION:
#+KEYWORDS:
#+LATEX_HEADER: \usepackage[margin=0.6in]{geometry}
#+LaTeX_CLASS_OPTIONS: [8pt]
#+LATEX_HEADER: \usepackage[english]{babel}
#+LATEX_HEADER: \usepackage{lastpage}
#+LATEX_HEADER: \usepackage{fancyhdr}
#+LATEX_HEADER: \pagestyle{fancy}
#+LATEX_HEADER: \fancyhf{}
#+LATEX_HEADER: \rhead{Updated: \today}
#+LATEX_HEADER: \rfoot{\thepage\ of \pageref{LastPage}}
#+LATEX_HEADER: \lfoot{\href{https://github.com/dennyzhang/cheatsheet.dennyzhang.com/tree/master/cheatsheet-elasticsearch-A4}{GitHub: https://github.com/dennyzhang/cheatsheet.dennyzhang.com/tree/master/cheatsheet-elasticsearch-A4}}
#+LATEX_HEADER: \lhead{\href{https://cheatsheet.dennyzhang.com/cheatsheet-elasticsearch-A4}{Blog URL: https://cheatsheet.dennyzhang.com/cheatsheet-elasticsearch-A4}}
#+AUTHOR: Denny Zhang
#+EMAIL:  denny@dennyzhang.com
#+TAGS: noexport(n)
#+PRIORITIES: A D C
#+OPTIONS:   H:3 num:t toc:nil \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:nil skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+EXPORT_EXCLUDE_TAGS: exclude noexport
#+SEQ_TODO: TODO HALF ASSIGN | DONE BYPASS DELEGATE CANCELED DEFERRED
#+LINK_UP:
#+LINK_HOME:
* TODO [#A] Why es run into yellow                       :noexport:IMPORTANT:
[staging-index-839920f07e6b11e6b71d0401f8d88101-new3][[staging-index-839920f07e6b11e6b71d0401f8d88101-new3][5]] ElasticsearchException[failed to create shard]; nested: LockObtainFailedException[Can't lock shard [staging-index-839920f07e6b11e6b71d0401f8d88101-new3][5], timed out after 5000ms];
        at org.elasticsearch.index.IndexService.createShard(IndexService.java:389)
        at org.elasticsearch.indices.cluster.IndicesClusterStateService.applyInitializingShard(IndicesClusterStateService.java:601)
        at org.elasticsearch.indices.cluster.IndicesClusterStateService.applyNewOrUpdatedShards(IndicesClusterStateService.java:501)
        at org.elasticsearch.indices.cluster.IndicesClusterStateService.clusterChanged(IndicesClusterStateService.java:166)
        at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:610)
        at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
        at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
        at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.lucene.store.LockObtainFailedException: Can't lock shard [staging-index-839920f07e6b11e6b71d0401f8d88101-new3][5], timed out after 5000ms
        at org.elasticsearch.env.NodeEnvironment$InternalShardLock.acquire(NodeEnvironment.java:609)
        at org.elasticsearch.env.NodeEnvironment.shardLock(NodeEnvironment.java:537)
        at org.elasticsearch.index.IndexService.createShard(IndexService.java:306)
        ... 10 more
[2018-03-30 13:25:18,904][WARN ][indices.cluster          ] [bematech-do-es-15.localdomain] [[staging-index-4fc7bce0072311e890833a4115ef3a9f][7]] marking and sending shard failed due to [failed to create shard]
[staging-index-4fc7bce0072311e890833a4115ef3a9f][[staging-index-4fc7bce0072311e890833a4115ef3a9f][7]] ElasticsearchException[failed to create shard]; nested: LockObtainFailedException[Can't lock shard [staging-index-4fc7bce0072311e890833a4115ef3a9f][7], timed out after 5000ms];
        at org.elasticsearch.index.IndexService.createShard(IndexService.java:389)
        at org.elasticsearch.indices.cluster.IndicesClusterStateService.applyInitializingShard(IndicesClusterStateService.java:601)
        at org.elasticsearch.indices.cluster.IndicesClusterStateService.applyNewOrUpdatedShards(IndicesClusterStateService.java:501)
        at org.elasticsearch.indices.cluster.IndicesClusterStateService.clusterChanged(IndicesClusterStateService.java:166)
        at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:610)
        at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
        at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
        at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.lucene.store.LockObtainFailedException: Can't lock shard [staging-index-4fc7bce0072311e890833a4115ef3a9f][7], timed out after 5000ms
        at org.elasticsearch.env.NodeEnvironment$InternalShardLock.acquire(NodeEnvironment.java:609)
        at org.elasticsearch.env.NodeEnvironment.shardLock(NodeEnvironment.java:537)
        at org.elasticsearch.index.IndexService.createShard(IndexService.java:306)
        ... 10 more
* TODO test es5                                                    :noexport:
http://injenkins.carol.ai:48080/job/DockerDeployAllInOne/506/console
denny-es5
1.91-elasticsearch5

es5-fresh-deployment

qa

ssh root@159.89.154.53
export env1_ip="159.89.154.53"
export env2_ip="138.68.245.33"

wget -O app-1.91.0-es5-SNAPSHOT.jar http://injenkins.carol.ai:28001/1.91-elasticsearch5/app-1.91.0-es5-SNAPSHOT.jar
wget -O backupserver-1.91.0-es5-SNAPSHOT.jar http://injenkins.carol.ai:28001/1.91-elasticsearch5/backupserver-1.91.0-es5-SNAPSHOT.jar

couchbase: http://138.68.245.33:8091

https://www.dennyzhang.com/backup_elasticsearch
** DONE update firwall
   CLOSED: [2018-05-21 Mon 16:05]
qa

ssh root@159.89.154.53

ufw allow from 159.89.154.53
ufw allow from 45.33.87.74
http://138.68.245.33:8091
** HALF flush all cb buckets: http://138.68.245.33:8091
** scp es2
scp -r /usr/share/elasticsearch/repo/* root@138.68.245.33:/usr/share/elasticsearch/repo

export snapshot_name="snapshot_20180518"

time curl -XPOST "http://$es_ip:$es_port/_snapshot/$repo_name/$snapshot_name/_restore?wait_for_completion=true" -d "{
    \"indices\": \"$es_index_list\",
    \"ignore_unavailable\": true,
    \"include_global_state\": false
}'"


curl -XGET "http://$es_ip:$es_port/_snapshot/$repo_name/_all"
** check es version
curl $es_ip:9200/
** #  --8<-------------------------- separator ------------------------>8-- :noexport:
** DONE
*** HALF /etc/elasticsearch/jvm.options: -Dlog4j2.disable.jmx=true
https://github.com/elastic/elasticsearch/issues/21932
*** HALF remove path.repo: ''
*** HALF target ES 5: mkdir -p /usr/share/elasticsearch/repo && chmod 777 /usr/share/elasticsearch/repo
** backup es2
es_ip=$(/sbin/ifconfig eth0 | grep 'inet addr:' | cut -d: -f2 | awk '{ print $1}')
curl $es_ip:9200/_cat/indices?v

#+BEGIN_EXAMPLE
root@all-in-one-DockerDeployAllInOne-463:/# curl $es_ip:9200/_cat/indices?v
health status index                                          pri rep docs.count docs.deleted store.size pri.store.size
green  open   staging-index-13a1f8adbec032ed68f3d035449ef48d   1   0          0            0       159b           159b
green  open   config-index-e4010da4110ba377d100f050cb4440db    1   0        272            1    323.6kb        323.6kb
green  open   master-index-13a1f8adbec032ed68f3d035449ef48d    1   0          0            0       159b           159b
green  open   master-index-46078234297e400a1648d9c427dc8c4b    1   0          2            1     20.1kb         20.1kb
green  open   config-index-098f6bcd4621d373cade4e832627b4f6    1   0          1            2     12.2kb         12.2kb
green  open   master-index-e4010da4110ba377d100f050cb4440db    1   0        130            0    206.9kb        206.9kb
green  open   staging-index-8cd6e43115e9416eb23609486fa053e3   1   0          1            0    116.6kb        116.6kb
green  open   config-index-8cd6e43115e9416eb23609486fa053e3    1   0        445           32      1.3mb          1.3mb
green  open   master-index-098f6bcd4621d373cade4e832627b4f6    1   0          0            0       159b           159b
green  open   config-index-46078234297e400a1648d9c427dc8c4b    1   0          3            2     30.4kb         30.4kb
green  open   config-index-13a1f8adbec032ed68f3d035449ef48d    1   0          1            0      8.7kb          8.7kb
green  open   staging-index-098f6bcd4621d373cade4e832627b4f6   1   0          0            0       159b           159b
green  open   staging-index-e4010da4110ba377d100f050cb4440db   1   0     111781            8    110.5mb        110.5mb
green  open   staging-index-46078234297e400a1648d9c427dc8c4b   1   0      50159           13     48.3mb         48.3mb
green  open   master-index-8cd6e43115e9416eb23609486fa053e3    1   0       1679            0    999.5kb        999.5kb
#+END_EXAMPLE

export es_index_list="*-index-8cd6e43115e9416eb23609486fa053e3,*-index-e4010da4110ba377d100f050cb4440db"
es_ip=$(/sbin/ifconfig eth0 | grep 'inet addr:' | cut -d: -f2 | awk '{ print $1}')
es_port=9200
export repo_name="my_backup"
export es_fs_mnt="/usr/share/elasticsearch/repo"

curl -X PUT "http://$es_ip:$es_port/_snapshot/$repo_name" -d "{
    \"type\": \"fs\",
    \"settings\": {
        \"location\": \"$es_fs_mnt\",
        \"compress\": true,
        \"chunk_size\": \"10m\"
    }
}"

export snapshot_name="snapshot_20180518"

time curl -XPUT "http://$es_ip:$es_port/_snapshot/$repo_name/${snapshot_name}?wait_for_completion=true" -d "{
    \"indices\": \"$es_index_list\",
    \"ignore_unavailable\": true,
    \"include_global_state\": false
}"

ls -lth $es_fs_mnt
* TODO local notes                                                 :noexport:
** TODO [#A] Blog: es setting incompatible change: ES2 to ES5
*** TODO discovery.zen.ping.multicast.enabled
 #+BEGIN_EXAMPLE
	 Suppressed: java.lang.IllegalArgumentException: unknown setting [discovery.zen.ping.multicast.enabled] please check that any required plugins are installed, or check the breaking changes documentation for removed settings
		 at org.elasticsearch.common.settings.AbstractScopedSettings.validate(AbstractScopedSettings.java:293) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.common.settings.AbstractScopedSettings.validate(AbstractScopedSettings.java:256) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.common.settings.SettingsModule.<init>(SettingsModule.java:139) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.node.Node.<init>(Node.java:344) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.node.Node.<init>(Node.java:245) ~[elasticsearch-5.6.3.jar:5.6.3]
 #+END_EXAMPLE
*** HALF threadpool.bulk.queue_size -> thread_pool.bulk.queue_size
 #+BEGIN_EXAMPLE
	 Suppressed: java.lang.IllegalArgumentException: unknown setting [threadpool.bulk.queue_size] did you mean any of [thread_pool.bulk.queue_size, thread_pool.get.queue_size, thread_pool.index.queue_size, thread_pool.search.queue_size, thread_pool.bulk.size, thread_pool.listener.queue_size]?
		 at org.elasticsearch.common.settings.AbstractScopedSettings.validate(AbstractScopedSettings.java:293) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.common.settings.AbstractScopedSettings.validate(AbstractScopedSettings.java:256) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.common.settings.SettingsModule.<init>(SettingsModule.java:139) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.node.Node.<init>(Node.java:344) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.node.Node.<init>(Node.java:245) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.bootstrap.Bootstrap$5.<init>(Bootstrap.java:233) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:233) ~[elasticsearch-5.6.3.jar:5.6.3]
 #+END_EXAMPLE
*** HALF monitor.jvm.gc.old.debug -> monitor.jvm.gc.overhead.debug?
 https://github.com/elastic/elasticsearch/issues/19852
 https://discuss.elastic.co/t/documentation-about-monitor-jvm-gc-overhead/92248/2
 #+BEGIN_EXAMPLE
	 Suppressed: java.lang.IllegalArgumentException: unknown setting [monitor.jvm.gc.old.debug] did you mean [monitor.jvm.gc.overhead.debug]?
		 at org.elasticsearch.common.settings.AbstractScopedSettings.validate(AbstractScopedSettings.java:293) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.common.settings.AbstractScopedSettings.validate(AbstractScopedSettings.java:256) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.common.settings.SettingsModule.<init>(SettingsModule.java:139) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.node.Node.<init>(Node.java:344) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.node.Node.<init>(Node.java:245) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.bootstrap.Bootstrap$5.<init>(Bootstrap.java:233) ~[elasticsearch-5.6.3.jar:5.6.3]
 #+END_EXAMPLE
*** HALF indices.recovery.concurrent_streams -> cluster.routing.allocation.node_concurrent_recoveries
 #+BEGIN_EXAMPLE
	 Suppressed: java.lang.IllegalArgumentException: unknown setting [indices.recovery.concurrent_streams] please check that any required plugins are installed, or check the breaking changes documentation for removed settings
		 at org.elasticsearch.common.settings.AbstractScopedSettings.validate(AbstractScopedSettings.java:293) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.common.settings.AbstractScopedSettings.validate(AbstractScopedSettings.java:256) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.common.settings.SettingsModule.<init>(SettingsModule.java:139) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.node.Node.<init>(Node.java:344) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.node.Node.<init>(Node.java:245) ~[elasticsearch-5.6.3.jar:5.6.3]

 #+END_EXAMPLE
*** HALF index.query.bool.max_clause_count -> indices.query.bool.max_clause_count
 https://www.elastic.co/guide/en/elasticsearch/reference/current/breaking_50_settings_changes.html
 The setting index.query.bool.max_clause_count has been removed. In order to set the maximum number of boolean clauses indices.query.bool.max_clause_count should be used instead.
 #+BEGIN_EXAMPLE
	 Suppressed: java.lang.IllegalArgumentException: unknown setting [index.query.bool.max_clause_count] did you mean [indices.query.bool.max_clause_count]?
		 at org.elasticsearch.common.settings.AbstractScopedSettings.validate(AbstractScopedSettings.java:293) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.common.settings.AbstractScopedSettings.validate(AbstractScopedSettings.java:256) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.common.settings.SettingsModule.<init>(SettingsModule.java:139) ~[elasticsearch-5.6.3.jar:5.6.3]

 #+END_EXAMPLE
*** TODO discovery.zen.ping.multicast.enabled
 #+BEGIN_EXAMPLE
	 Suppressed: java.lang.IllegalArgumentException: unknown setting [discovery.zen.ping.multicast.enabled] please check that any required plugins are installed, or check the breaking changes documentation for removed settings
		 at org.elasticsearch.common.settings.AbstractScopedSettings.validate(AbstractScopedSettings.java:293) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.common.settings.AbstractScopedSettings.validate(AbstractScopedSettings.java:256) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.common.settings.SettingsModule.<init>(SettingsModule.java:139) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.node.Node.<init>(Node.java:344) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.node.Node.<init>(Node.java:245) ~[elasticsearch-5.6.3.jar:5.6.3]

 #+END_EXAMPLE
*** DONE bootstrap.mlockall -> bootstrap.memory_lock
    CLOSED: [2017-11-02 Thu 18:28]
 https://www.elastic.co/guide/en/elasticsearch/reference/current/breaking_50_settings_changes.html
 #+BEGIN_EXAMPLE
 java.lang.IllegalArgumentException: unknown setting [bootstrap.mlockall] please check that any required plugins are installed, or check the breaking changes documentation for removed settings
	 at org.elasticsearch.common.settings.AbstractScopedSettings.validate(AbstractScopedSettings.java:293) ~[elasticsearch-5.6.3.jar:5.6.3]
	 at org.elasticsearch.common.settings.AbstractScopedSettings.validate(AbstractScopedSettings.java:256) ~[elasticsearch-5.6.3.jar:5.6.3]
	 at org.elasticsearch.common.settings.SettingsModule.<init>(SettingsModule.java:139) ~[elasticsearch-5.6.3.jar:5.6.3]
	 at org.elasticsearch.node.Node.<init>(Node.java:344) ~[elasticsearch-5.6.3.jar:5.6.3]
	 at org.elasticsearch.node.Node.<init>(Node.java:245) ~[elasticsearch-5.6.3.jar:5.6.3]
	 at org.elasticsearch.bootstrap.Bootstrap$5.<init>(Bootstrap.java:233) ~[elasticsearch-5.6.3.jar:5.6.3]
 #+END_EXAMPLE
*** DONE discovery.zen.ping.timeout -> discovery.zen.ping_timeout
    CLOSED: [2017-11-02 Thu 18:25]
 https://github.com/elastic/elasticsearch/issues/9581
 #+BEGIN_EXAMPLE
	 Suppressed: java.lang.IllegalArgumentException: unknown setting [discovery.zen.ping.timeout] did you mean any of [discovery.zen.ping_timeout, discovery.zen.fd.ping_timeout, discovery.zen.join_timeout, discovery.zen.publish_timeout, discovery.zen.commit_timeout]?
		 at org.elasticsearch.common.settings.AbstractScopedSettings.validate(AbstractScopedSettings.java:293) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.common.settings.AbstractScopedSettings.validate(AbstractScopedSettings.java:256) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.common.settings.SettingsModule.<init>(SettingsModule.java:139) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.node.Node.<init>(Node.java:344) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.node.Node.<init>(Node.java:245) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.bootstrap.Bootstrap$5.<init>(Bootstrap.java:233) ~[elasticsearch-5.6.3.jar:5.6.3]
		 at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:233) ~[elasticsearch-5.6.3.jar:5.6.3]
 #+END_EXAMPLE
*** timeout
 #+BEGIN_EXAMPLE
 *************************************************************************************
 Found index level settings on node level configuration.

 Since elasticsearch 5.x index level settings can NOT be set on the nodes
 configuration like the elasticsearch.yaml, in system properties or command line
 arguments.In order to upgrade all indices the settings must be updated via the
 /${index}/_settings API. Unless all settings are dynamic all indices must be closed
 in order to apply the upgradeIndices created in the future should use index templates
 to set default values.

 Please ensure all required values are updated on all indices by executing:

 curl -XPUT 'http://localhost:9200/_all/_settings?preserve_existing=true' -d '{
   "index.indexing.slowlog.threshold.index.warn" : "12s",
   "index.search.slowlog.threshold.query.warn" : "10s",
   "index.unassigned.node_left.delayed_timeout" : "5m"
 }'
 *************************************************************************************

 [2017-11-02T23:13:16,417][ERROR][o.e.b.Bootstrap          ] Exception
 java.lang.IllegalArgumentException: node settings must not contain any index level settings
         at org.elasticsearch.common.settings.SettingsModule.<init>(SettingsModule.java:132) ~[elasticsearch-5.6.3.jar:5.6.3]
         at org.elasticsearch.node.Node.<init>(Node.java:344) ~[elasticsearch-5.6.3.jar:5.6.3]
         at org.elasticsearch.node.Node.<init>(Node.java:245) ~[elasticsearch-5.6.3.jar:5.6.3]
         at org.elasticsearch.bootstrap.Bootstrap$5.<init>(Bootstrap.java:233) ~[elasticsearch-5.6.3.jar:5.6.3]
         at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:233) ~[elasticsearch-5.6.3.jar:5.6.3]
         at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:342) [elasticsearch-5.6.3.jar:5.6.3]
         at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:132) [elasticsearch-5.6.3.jar:5.6.3]
         at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:123) [elasticsearch-5.6.3.jar:5.6.3]
         at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:70) [elasticsearch-5.6.3.jar:5.6.3]
         at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:134) [elasticsearch-5.6.3.jar:5.6.3]
         at org.elasticsearch.cli.Command.main(Command.java:90) [elasticsearch-5.6.3.jar:5.6.3]
         at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:91) [elasticsearch-5.6.3.jar:5.6.3]
         at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:84) [elasticsearch-5.6.3.jar:5.6.3]
 [2017-11-02T23:13:16,425][WARN ][o.e.b.ElasticsearchUncaughtExceptionHandler] [default-ubuntu-1404] uncaught exception in thread [main]
 #+END_EXAMPLE
*** HALF discovery.zen.ping.unicast.hosts
 https://github.com/elastic/cookbook-elasticsearch/issues/426
*** HALF Multi data path bug in Elasticsearch 5.3.0
 https://www.elastic.co/blog/multi-data-path-bug-in-elasticsearch-5-3-0
*** [#A] web page: Settings changes | Elasticsearch Reference [5.6] | Elastic
 https://www.elastic.co/guide/en/elasticsearch/reference/current/breaking_50_settings_changes.html
**** webcontent                                                    :noexport:
 #+begin_example
 Location: https://www.elastic.co/guide/en/elasticsearch/reference/current/breaking_50_settings_changes.html
 Questions? Feedback? powered by Olark live chat software

 elastic-logo-mobile

   *
   *
   * EN
       + English
       + Français
       + Deutsch
       + 日本語
       + 한국어
       + 简体中文

 elastic-logo

   * Products
   * Cloud
   * Services
   * Customers
   * Learn

   * downloads
   *
   * contact
   *
   *
   * EN
       + English
       + Français
       + Deutsch
       + 日本語
       + 한국어
       + 简体中文

   * [                    ]

 Docs
 Docs
 Elasticsearch Reference [5.6] » Breaking changes » Breaking changes in 5.0 » Settings changes
 «  Document API changes     Allocation changes  »

 Settings changesedit

 From Elasticsearch 5.0 on all settings are validated before they are applied. Node level and
 default index level settings are validated on node startup, dynamic cluster and index setting are
 validated before they are updated/added to the cluster state.

 Every setting must be a known setting. All settings must have been registered with the node or
 transport client they are used with. This implies that plugins that define custom settings must
 register all of their settings during plugin loading using the SettingsModule#registerSettings
 (Setting) method.

 Index Level Settingsedit

 In previous versions Elasticsearch allowed to specify index level setting as defaults on the node
 level, inside the elasticsearch.yaml file or even via command-line parameters. From Elasticsearch
 5.0 on only selected settings like for instance index.codec can be set on the node level. All other
 settings must be set on each individual index. To set default values on every index, index
 templates should be used instead.

 Node settingsedit

 The name setting has been removed and is replaced by node.name. Usage of -Dname=some_node_name is
 not supported anymore.

 The node.add_id_to_custom_path was renamed to add_lock_id_to_custom_path.

 The default for the node.name settings is now the first 7 characters of the node id, which is in
 turn a randomly generated UUID.

 The settings node.mode and node.local are removed. Local mode should be configured via
 transport.type: local. In order to disable HTTP please use http.enabled: false

 Node attribute settingsedit

 Node level attributes used for allocation filtering, forced awareness or other node identification
 / grouping must be prefixed with node.attr. In previous versions it was possible to specify node
 attributes with the node. prefix. All node attributes except of node.master, node.data and
 node.ingest must be moved to the new node.attr. namespace.

 Node types settingsedit

 The node.client setting has been removed. A node with such a setting set will not start up.
 Instead, each node role needs to be set separately using the existing node.master, node.data and
 node.ingest supported static settings.

 Gateway settingsedit

 The gateway.format setting for configuring global and index state serialization format has been
 removed. By default, smile is used as the format.

 Transport Settingsedit

 All settings with a netty infix have been replaced by their already existing transport synonyms.
 For instance transport.netty.bind_host is no longer supported and should be replaced by the
 superseding setting transport.bind_host.

 Security manager settingsedit

 The option to disable the security manager security.manager.enabled has been removed. In order to
 grant special permissions to elasticsearch users must edit the local Java Security Policy.

 Network settingsedit

 The _non_loopback_ value for settings like network.host would arbitrarily pick the first interface
 not marked as loopback. Instead, specify by address scope (e.g. _local_,_site_ for all loopback and
 private network addresses) or by explicit interface names, hostnames, or addresses.

 The netty.epollBugWorkaround settings is removed. This settings allow people to enable a netty work
 around for a high CPU usage issue with early JVM versions. This bug was fixed in Java 7. Since
 Elasticsearch 5.0 requires Java 8 the settings is removed. Note that if the workaround needs to be
 reintroduced you can still set the org.jboss.netty.epollBugWorkaround system property to control
 Netty directly.

 Forbid changing of thread pool typesedit

 Previously, thread pool types could be dynamically adjusted. The thread pool type effectively
 controls the backing queue for the thread pool and modifying this is an expert setting with minimal
 practical benefits and high risk of being misused. The ability to change the thread pool type for
 any thread pool has been removed. It is still possible to adjust relevant thread pool parameters
 for each of the thread pools (e.g., depending on the thread pool type, keep_alive, queue_size,
 etc.).

 Threadpool settingsedit

 The suggest threadpool has been removed, now suggest requests use the search threadpool.

 The prefix on all thread pool settings has been changed from threadpool to thread_pool.

 The minimum size setting for a scaling thread pool has been changed from min to core.

 The maximum size setting for a scaling thread pool has been changed from size to max.

 The queue size setting for a fixed thread pool must be queue_size (all other variants that were
 previously supported are no longer supported).

 Thread pool settings are now node-level settings. As such, it is not possible to update thread pool
 settings via the cluster settings API.

 Analysis settingsedit

 The index.analysis.analyzer.default_index analyzer is not supported anymore. If you wish to change
 the analyzer to use for indexing, change the index.analysis.analyzer.default analyzer instead.

 Ping settingsedit

 Previously, there were three settings for the ping timeout: discovery.zen.initial_ping_timeout,
 discovery.zen.ping.timeout and discovery.zen.ping_timeout. The former two have been removed and the
 only setting key for the ping timeout is now discovery.zen.ping_timeout. The default value for ping
 timeouts remains at three seconds.

 discovery.zen.master_election.filter_client and discovery.zen.master_election.filter_data have been
 removed in favor of the new discovery.zen.master_election.ignore_non_master_pings. This setting
 control how ping responses are interpreted during master election and should be used with care and
 only in extreme cases. See documentation for details.

 Recovery settingsedit

 Recovery settings deprecated in 1.x have been removed:

   * index.shard.recovery.translog_size is superseded by indices.recovery.translog_size
   * index.shard.recovery.translog_ops is superseded by indices.recovery.translog_ops
   * index.shard.recovery.file_chunk_size is superseded by indices.recovery.file_chunk_size
   * indices.recovery.concurrent_streams is superseded by
     cluster.routing.allocation.node_concurrent_recoveries
   * index.shard.recovery.concurrent_small_file_streams is superseded by
     indices.recovery.concurrent_small_file_streams
   * indices.recovery.max_size_per_sec is superseded by indices.recovery.max_bytes_per_sec

 If you are using any of these settings please take the time to review their purpose. All of the
 settings above are considered expert settings and should only be used if absolutely necessary. If
 you have set any of the above setting as persistent cluster settings please use the settings update
 API and set their superseded keys accordingly.

 The following settings have been removed without replacement

   * indices.recovery.concurrent_small_file_streams - recoveries are now single threaded. The number
     of concurrent outgoing recoveries are throttled via allocation deciders
   * indices.recovery.concurrent_file_streams - recoveries are now single threaded. The number of
     concurrent outgoing recoveries are throttled via allocation deciders

 Translog settingsedit

 The index.translog.flush_threshold_ops setting is not supported anymore. In order to control
 flushes based on the transaction log growth use index.translog.flush_threshold_size instead.

 Changing the translog type with index.translog.fs.type is not supported anymore, the buffered
 implementation is now the only available option and uses a fixed 8kb buffer.

 The translog by default is fsynced after every index, create, update, delete, or bulk request. The
 ability to fsync on every operation is not necessary anymore. In fact, it can be a performance
 bottleneck and it's trappy since it enabled by a special value set on index.translog.sync_interval.
 Now, index.translog.sync_interval doesn't accept a value less than 100ms which prevents fsyncing
 too often if async durability is enabled. The special value 0 is no longer supported.

 index.translog.interval has been removed.

 Request Cache Settingsedit

 The deprecated settings index.cache.query.enable and indices.cache.query.size have been removed and
 are replaced with index.requests.cache.enable and indices.requests.cache.size respectively.

 indices.requests.cache.clean_interval has been replaced with indices.cache.clean_interval and is no
 longer supported.

 Field Data Cache Settingsedit

 The indices.fielddata.cache.clean_interval setting has been replaced with
 indices.cache.clean_interval.

 Allocation settingsedit

 The cluster.routing.allocation.concurrent_recoveries setting has been replaced with
 cluster.routing.allocation.node_concurrent_recoveries.

 Similarity settingsedit

 The default similarity has been renamed to classic.

 Indexing settingsedit

 The indices.memory.min_shard_index_buffer_size and indices.memory.max_shard_index_buffer_size have
 been removed as Elasticsearch now allows any one shard to use amount of heap as long as the total
 indexing buffer heap used across all shards is below the node's indices.memory.index_buffer_size
 (defaults to 10% of the JVM heap).

 Removed es.max-open-filesedit

 Setting the system property es.max-open-files to true to get Elasticsearch to print the number of
 maximum open files for the Elasticsearch process has been removed. This same information can be
 obtained from the Nodes Info API, and a warning is logged on startup if it is set too low.

 Removed es.netty.gatheringedit

 Disabling Netty from using NIO gathering could be done via the escape hatch of setting the system
 property "es.netty.gathering" to "false". Time has proven enabling gathering by default is a
 non-issue and this non-documented setting has been removed.

 Removed es.useLinkedTransferQueueedit

 The system property es.useLinkedTransferQueue could be used to control the queue implementation
 used in the cluster service and the handling of ping responses during discovery. This was an
 undocumented setting and has been removed.

 Cache concurrency level settings removededit

 Two cache concurrency level settings indices.requests.cache.concurrency_level and
 indices.fielddata.cache.concurrency_level because they no longer apply to the cache implementation
 used for the request cache and the field data cache.

 Using system properties to configure Elasticsearchedit

 Elasticsearch can no longer be configured by setting system properties. This means that support for
 all of the following has been removed:

   * setting via command line arguments to elasticsearch as -Des.name.of.setting=value.of.setting
   * setting via the JAVA_OPTS environment variable JAVA_OPTS=$JAVA_OPTS -Des.name.of.setting=
     value.of.setting
   * setting via the ES_JAVA_OPTS environment variable ES_JAVA_OPTS=$ES_JAVA_OPTS
     -Des.name.of.setting=value.of.setting

 Instead, use -Ename.of.setting=value.of.setting.

 Removed using double-dashes to configure Elasticsearchedit

 Elasticsearch could previously be configured on the command line by setting settings via
 --name.of.setting value.of.setting. This feature has been removed. Instead, use -Ename.of.setting=
 value.of.setting.

 Remove support for .properties config filesedit

 The Elasticsearch configuration and logging configuration can no longer be stored in the Java
 properties file format (line-delimited key=value pairs with a .properties extension).

 Discovery Settingsedit

 The discovery.zen.minimum_master_node must be set for nodes that have network.host,
 network.bind_host, network.publish_host, transport.host, transport.bind_host, or
 transport.publish_host configuration options set. We see those nodes as in "production" mode and
 thus require the setting.

 Realtime get settingedit

 The action.get.realtime setting has been removed. This setting was a fallback realtime setting for
 the get and mget APIs when realtime wasn't specified. Now if the parameter isn't specified we
 always default to true.

 Memory lock settingsedit

 The setting bootstrap.mlockall has been renamed to bootstrap.memory_lock.

 Snapshot settingsedit

 The default setting include_global_state for restoring snapshots has been changed from true to
 false. It has not been changed for taking snapshots and still defaults to true in that case.

 Time value parsingedit

 The unit w representing weeks is no longer supported.

 Fractional time values (e.g., 0.5s) are no longer supported. For example, this means when setting
 timeouts "0.5s" will be rejected and should instead be input as "500ms".

 Node max local storage nodesedit

 Previous versions of Elasticsearch defaulted to allowing multiple nodes to share the same data
 directory (up to 50). This can be confusing where users accidentally startup multiple nodes and end
 up thinking that they've lost data because the second node will start with an empty data directory.
 While the default of allowing multiple nodes is friendly to playing with forming a small cluster on
 a laptop, and end-users do sometimes run multiple nodes on the same host, this tends to be the
 exception. Keeping with Elasticsearch's continual movement towards safer out-of-the-box defaults,
 and optimizing for the norm instead of the exception, the default for node.max_local_storage_nodes
 is now one.

 Script settingsedit

 Indexed script settingsedit

 Due to the fact that indexed script has been replaced by stored scripts the following settings have
 been replaced to:

   * script.indexed has been replaced by script.stored
   * script.engine.*.indexed.aggs has been replaced by script.engine.*.stored.aggs (where *
     represents the script language, like groovy, mustache, painless etc.)
   * script.engine.*.indexed.mapping has been replaced by script.engine.*.stored.mapping (where *
     represents the script language, like groovy, mustache, painless etc.)
   * script.engine.*.indexed.search has been replaced by script.engine.*.stored.search (where *
     represents the script language, like groovy, mustache, painless etc.)
   * script.engine.*.indexed.update has been replaced by script.engine.*.stored.update (where *
     represents the script language, like groovy, mustache, painless etc.)
   * script.engine.*.indexed.plugin has been replaced by script.engine.*.stored.plugin (where *
     represents the script language, like groovy, mustache, painless etc.)

 Script mode settingsedit

 Previously script mode settings (e.g., "script.inline: true", "script.engine.groovy.inline.aggs:
 false", etc.) accepted a wide range of "truthy" or "falsy" values. This is now much stricter and
 supports only the true and false options.

 Script sandbox settings removededit

 Prior to 5.0 a third option could be specified for the script.inline and script.stored settings
 ("sandbox"). This has been removed, you can now only set script.inline: true or script.stored:
 true.

 Search settingsedit

 The setting index.query.bool.max_clause_count has been removed. In order to set the maximum number
 of boolean clauses indices.query.bool.max_clause_count should be used instead.

 «  Document API changes     Allocation changes  »

 Getting Started Videos

   * Elasticsearch Demo
   * Kibana 101
   * Logstash Primer

 Be in the know with the latest and greatest from Elastic.

 Thanks for subscribing! We'll keep you updated with new releases.

 Products >

   * Elasticsearch
   * Kibana
   * Beats
   * Logstash
   * X-Pack
   * Elastic Cloud
   * Security (formerly Shield)
   * Alerting (via Watcher)
   * Monitoring (formerly Marvel)
   * Graph
   * Reporting
   * Machine Learning
   * ES-Hadoop

 Resources

   * Blog
   * Cloud Status
   * Community
   * Customers & Use Cases
   * Documentation
   * Elastic{ON} Events
   * Forums
   * Meetups
   * Subscriptions
   * Support Portal
   * Videos & Webinars
   * Training

 About >

   * Careers/Jobs
   * Contact
   * Leadership
   * Partners
   * Press
   * Elastic Store

 Language

   * English
   * Français
   * Deutsch
   * 日本語
   * 한국어
   * 简体中文

 FOLLOW US

   *
   *
   *
   *
   *

   * Trademarks
   * Terms of Use
   * Privacy
   * Cookie Policy
   * Brand

 [logo-elast]

 © 2017. All Rights Reserved - Elasticsearch

 Elasticsearch is a trademark of Elasticsearch BV, registered in the U.S. and in other countries.

 Apache, Apache Lucene, Apache Hadoop, Hadoop, HDFS and the yellow elephant logo are trademarks of
 the Apache Software Foundation in the United States and/or other countries.

 #+end_example
*** HALF NoSuchFileException: /usr/share/elasticsearch/config
 https://github.com/elastic/elasticsearch/issues/21118
 https://github.com/elastic/elasticsearch/issues/26699
*** HALF [#A] elasticsearch5 start: java.security.AccessControlException: access denied ("javax.management.MBeanTrustPermission" "register")
 https://github.com/elastic/ansible-elasticsearch/issues/328
 https://github.com/elastic/elasticsearch/issues/25843
*** TODO [#A] make sure all ES configuration reserve
*** TODO [#A] elasticsearch install plugin: head
*** TODO elasticsearch logging.yml
*** TODO jenkins job incompatible for unicast format in elasticsearch.yml and mdm.yml
*** TODO ES plugin
    describe command('/usr/share/elasticsearch/bin/plugin list') do
      its(:stdout) { should contain " - #{plugin}" }
    end
*** TODO No such file or directory - /usr/share/elasticsearch/bin/plugin
 https://github.com/elastic/cookbook-elasticsearch/issues/524

 > basic.rb && vim basic.rb
** TODO [#A] elasticsearch node in explore env: worker not balanced
** TODO elasticsearch disk capacity issue
#+BEGIN_EXAMPLE
Kung Wang [10:24 AM]
Sure, do you think the block disk solution will help?

denny zhang [10:30 AM]
Kung, I think that would help at infra layer. However we might still be using machine inefficiently.

Say big es shards won't distribute well across different machines; "garbage data" wastes resource.

My opinion would be: while working on infra layer, we also put effort on application layer or db layer.
Those 2 tickets are what I'm thinking about. (edited)

[10:30]
Cut big elasticsearch shard of huge indice into small pieces
https://trello.com/c/hOOCjXMC

Clean up old elasticsearch data to reclaim disk capacity
https://trello.com/c/daddhKXc

[10:31]
What do you think?

Kung Wang [10:32 AM]
yes, great idea

[10:32]
this sprint we have a story to provide one more means to cut shards when tenant is created

[10:33]
also, we need to discuss in the backend on the compacting process and situation Bruno mentioned before

denny zhang [10:34 AM]
Well, let me work on the block disk solution. Then we join-force to re-evaluate the issue at the end of this sprint!

Kung Wang [10:35 AM]
end of this sprint is today

[10:35]
we have demo at 1:30PM PST, please join us

denny zhang [10:35 AM]
hmm, I might be able to deliver that next Mon or Tue

[10:36]
Sure. I will definitely dial in, Kung

Kung Wang [10:36 AM]
demo whatever you have

denny zhang [10:37 AM]
Cool. I will.

Once we have resolved this es disk issue, we might see much less nagios alerts in both prod env and explore env.

It's really noisy these days.
#+END_EXAMPLE
** TODO use elasticsearch head api
** TODO elasticsearch mlockall
curl http://`ifconfig | grep inet | awk '{print $2}' | grep -v 127 | cut -d":" -f2`:9200/_nodes/process?pretty 2>/dev/null | egrep "name|mlockall" | grep -v cluster | sed 'N;s/\n/ /g' | grep -v app | grep false
      "name" : "prod-es-4",         "mlockall" : false
      "name" : "prod-es-6",         "mlockall" : false
      "name" : "prod-es-3",         "mlockall" : false
      "name" : "prod-es-1",         "mlockall" : false
      "name" : "prod-es-5",         "mlockall" : false
      "name" : "prod-es-2",         "mlockall" : false
All these servers should have mlockall to true. If we are using chef to configuration elasticsearch.yml, why this is happening?

mlockall
** TODO elasticsearch for SSD
For elasticsearch, The default is 20 MB/s, which is a good setting for spinning disks. If you have SSDs, you might consider increasing this to 100–200 MB/s. Test to see what works for your system:
curl -XPUT http://`ifconfig | grep inet | awk '{print $2}' | grep -v 127 | cut -d":" -f2`:9200/_cluster/settings -d '
{
    "persistent" : {
        "indices.store.throttle.max_bytes_per_sec" : "100mb"
    }
}'
** TODO get detail status of elasticsearch initializing shards
Every 2.0s: curl 138.197.217.103:9200/_cat/shards?v | grep -v STARTED                                                                              Wed Jan 11 23:02:02 2017

  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
   0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  31 52360   31 16301    0     0  25226      0  0:00:02 --:--:--  0:00:02 25194 100 52360  1
00 52360    0     0  81018      0 --:--:-- --:--:-- --:--:-- 80927
index                                          shard prirep state             docs   store ip              node
master-index-abae8b30ac9b11e692000401f8d88101  3     r      INITIALIZING                   138.197.198.250 prod-es-22
master-index-abae8b30ac9b11e692000401f8d88101  3     r      INITIALIZING                   138.68.46.207   prod-es-20
** TODO suspicious es audit log in prod-es-03: /usr/share/elasticsearch/hs_err_pid*.log
root@prod-audit-03:/usr/share/elasticsearch# tail hs_err_pid29794.log



Memory: 4k page, physical 8175240k(6404268k free), swap 0k(0k free)

vm_info: Java HotSpot(TM) 64-Bit Server VM (25.40-b25) for linux-amd64 JRE (1.8.0_40-b26), built on Mar  7 2015 15:08:31 by "java_re" with gcc 4.3.0 20080428 (Red Hat 4.3.0-8)

time: Sat Mar 18 15:43:42 2017
elapsed time: 0 seconds (0d 0h 0m 0s)

root@prod-audit-03:/usr/share/elasticsearch# free -ml
             total       used       free     shared    buffers     cached
Mem:          7983       1724       6259          0         77       1462
Low:          7983       1724       6259
High:            0          0          0
-/+ buffers/cache:        184       7799
Swap:            0          0          0
** TODO elasticsearch backup individual index
** TODO elasticsearch reindex indices
> /tmp/es_reindex.sh && vim /tmp/es_reindex.sh

bash /tmp/es_reindex.sh staging-index-8cd6e43115e9416eb23609486fa053e3

export old_index_name="staging-index-46078234297e400a1648d9c427dc8c4b"
export new_index_name="${old_index_name}-new"
export alias_index_name=$(echo "$old_index_name" | sed 's/-index//g')
export shard_count=5
export replica_count=0
export es_ip=$(/sbin/ifconfig eth0 | grep 'inet addr:' | cut -d: -f2 | awk '{ print $1}')
export es_port=9200
*** Bruno's input
export es_ip=$(/sbin/ifconfig eth0 | grep 'inet addr:' | cut -d: -f2 | awk '{ print $1}')
export old_index_name=staging-index-46078234297e400a1648d9c427dc8c4b
export new_index_name="${old_index_name}-new"
export alias_index_name=$(echo "$old_index_name" | sed 's/-index//g')
export shard_count=5
export replica_count=0

# create index with 3 shards and 2 replicas
curl -XPUT 'http://localhost:9200/master-index-8cd6e43115e9416eb23609486fa053e3-1?pretty' -d '
{
"settings" : {
"index" : {
"number_of_shards" : 1,
"number_of_replicas" : 0
}
}
}'

# reindex index
curl -XPOST 'http://localhost:9200/_reindex?pretty' -d '
{
"conflicts": "proceed",
"source": {
"index": "master-index-8cd6e43115e9416eb23609486fa053e3"
},
"dest": {
"index": "master-index-8cd6e43115e9416eb23609486fa053e3-1",
"op_type": "create"
}
}'

# get all re-index tasks
curl -XGET 'http://localhost:9200/_tasks?detailed=true&actions=*reindex&pretty'

# add index to existing alias and remove old index from that alias
curl -XPOST 'http://localhost:9200/_aliases' -d '
{
"actions": [
{ "remove": {
"alias": "master-8cd6e43115e9416eb23609486fa053e3",
"index": "master-index-8cd6e43115e9416eb23609486fa053e3"
}},
{ "add": {
"alias": "master-8cd6e43115e9416eb23609486fa053e3",
"index": "master-index-8cd6e43115e9416eb23609486fa053e3-1"
}}
]
}'

# delete index
curl -XDELETE 'http://localhost:9200/master-index-8cd6e43115e9416eb23609486fa053e3?pretty'
** TODO elasticsearch how to rename index
** TODO read https://qbox.io/blog/optimizing-elasticsearch-how-many-shards-per-index
** TODO elasticsearch: rollover indexes based on count of documents and age.
https://www.linkedin.com/feed/update/urn:li:activity:6255734578187689984/
** TODO elasticsearch cluster fix
In prod-es-18

[2017-04-11 19:05:32,847][WARN ][http.netty               ] [prod-es-18] Caught exception while handling client http traffic, closing connection [id: 0xd3eaf2fa, /138.68.250.138:34596 => /138.197.217.98:9200]
java.lang.IllegalArgumentException: empty text
        at org.jboss.netty.handler.codec.http.HttpVersion.<init>(HttpVersion.java:89)
        at org.jboss.netty.handler.codec.http.HttpVersion.valueOf(HttpVersion.java:62)
        at org.jboss.netty.handler.codec.http.HttpRequestDecoder.createMessage(HttpRequestDecoder.java:75)
        at org.jboss.netty.handler.codec.http.HttpMessageDecoder.decode(HttpMessageDecoder.java:191)
        at org.jboss.netty.handler.codec.http.HttpMessageDecoder.decode(HttpMessageDecoder.java:102)
        at org.jboss.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:500)
        at org.jboss.netty.handler.codec.replay.ReplayingDecoder.messageReceived(ReplayingDecoder.java:435)
        at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)
        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
        at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
        at org.elasticsearch.common.netty.OpenChannelsHandler.handleUpstream(OpenChannelsHandler.java:75)
        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)
        at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268)
        at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)
        at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)
        at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)
        at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
        at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)
        at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)
        at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
        at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
** TODO [#A] prod-es-18 node issue
java.net.NoRouteToHostException: No route to host
        at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
        at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
        at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
        at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
        at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
        at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
        at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
        at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
        at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
[2017-04-11 19:30:37,675][WARN ][transport.netty          ] [prod-es-18] exception caught on transport layer [[id: 0x6aef8272]], closing connection
java.net.NoRouteToHostException: No route to host
        at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
        at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
        at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
        at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
        at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
        at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
        at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
        at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
        at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
[2017-04-11 19:30:39,133][INFO ][cluster.service          ] [prod-es-18] new_master {prod-es-18}{cpSFXw_uSbGM6Xof3wY66w}{138.197.217.98}{prod-es-18/138.197.217.98:9300}{max_local_storage_nodes=1}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2017-04-11 19:30:39,170][INFO ][http                     ] [prod-es-18] publish_address {prod-es-18/138.197.217.98:9200}, bound_addresses {138.197.217.98:9200}
[2017-04-11 19:30:39,170][INFO ][node                     ] [prod-es-18] started
** TODO elasticsearch fail to insert
curl -XPUT "http://prod-es-16:9200/master-8cd6e43115e9416eb23609486fa053e3/mdmEntityTemplateType/f5bf48aa40cad7891eb709fcf1fde128" -d '{"mdmName":"product","mdmDescription":{"en-US":"Product","pt-BR":"Produto"},"mdmId":"f5bf48aa40cad7891eb709fcf1fde128","mdmEntityType":"mdmEntityTemplateType","mdmCreated":"2017-04-07T21:12:31.688Z","mdmLastUpdated":"2017-04-07T21:12:31.805Z","mdmTenantId":"8cd6e43115e9416eb23609486fa053e3"}'
** TODO why /data/elasticsearch/repo not exists in your server?
** TODO Issue: install nfs-common in elasticsearch nodes: need to run apt-get update first
http://injenkins.carol.ai:48080/job/DockerDeployAllInOne/522/console
** TODO Issue: after provision elasticsearch node, mkdir -p /data/elasticsearch/repo/
** TODO elasticsearch log warning about max file descriptors
[2017-04-18 13:10:57,549][INFO ][env                      ] [bematech-do-es-20] heap size [11.9gb], compressed ordinary object pointers [true]
[2017-04-18 13:10:57,550][WARN ][env                      ] [bematech-do-es-20] max file descriptors [64000] for elasticsearch process likely too low, consider increasing to at least [65536]

#+BEGIN_EXAMPLE
root@bematech-do-es-20:/proc/6294# cat  ./limits
Limit                     Soft Limit           Hard Limit           Units
Max cpu time              unlimited            unlimited            seconds
Max file size             unlimited            unlimited            bytes
Max data size             unlimited            unlimited            bytes
Max stack size            8388608              unlimited            bytes
Max core file size        0                    unlimited            bytes
Max resident set          unlimited            unlimited            bytes
Max processes             128560               128560               processes
Max open files            64000                64000                files
Max locked memory         unlimited            unlimited            bytes
Max address space         unlimited            unlimited            bytes
Max file locks            unlimited            unlimited            locks
Max pending signals       128560               128560               signals
Max msgqueue size         819200               819200               bytes
Max nice priority         0                    0
Max realtime priority     0                    0
Max realtime timeout      unlimited            unlimited            us
#+END_EXAMPLE
** TODO elasticsearch make sure attribute are indexed
** TODO elasticsearch create mapping
https://www.elastic.co/guide/en/elasticsearch/reference/2.3/mapping.html
http://stackoverflow.com/questions/21876857/elasticsearch-index-creation-with-mapping
** TODO elasticsearch how mapping works?
** TODO elasticsearch how to check whether index has been created?
** TODO How does elasticsearch mapping work
** TODO explore env: elasticsearch cluster
denny zhang [7:58 AM]
➜  ~ ssh -p 2702 root@173.255.243.91 "curl 173.255.243.91:9200/_cluster/health?pretty"
Warning: Permanently added '[173.255.243.91]:2702' (RSA) to the list of known hosts.
 % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                Dload  Upload   Total   Spent    Left  Speed
100   475  100   475    {     0      0      0 --:--:-- --:--:-- --:--:--     0
 "cluster_name" : "mdm",
 "status" : "yellow",
 "timed_out" : false,
 "number_of_nodes" : 17,
 "number_of_data_nodes" : 12,
 "active_primary_shards" : 141,
 "active_shards" : 281,
 "relocating_shards" : 0,
 "initializing_shards" : 1,
 "unassigned_shards" : 0,
 "delayed_unassigned_shards" : 0,
 "number_of_pending_tasks" : 0,
 "number_of_in_flight_fetch" : 0,
 "task_max_waiting_in_queue_millis" : 0,
 "active_shards_percent_as_number" : 99.64539007092199
}
** TODO how many records in couchbase, elasticsearch
** TODO check elasticsearch shards health
denny zhang [12:15 AM]
added and commented on this Plain Text snippet
root@prod-es-16:/data/elasticsearch# curl $es_ip:9200/_cat/shards?v | grep -v STARTED
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0index                                          shard prirep state           docs   store ip              node
staging-index-d0935b506a4311e6b61d0401f8d88101 0     r      UNASSIGNED
master-index-abae8b30ac9b11e692000401f8d88101  4     r      UNASSIGNED
1 Comment Click to expand inline 10 lines
We get 2 unassigned ES shards. Not sure why this happens.

denny zhang [12:16 AM]
1.  staging-index-d0935b506a4311e6b61d0401f8d88101(~50GB)
2. master-index-abae8b30ac9b11e692000401f8d88101(~170 GB)

Let's see whether ES cluster can recover it automatically.

[12:20]
Each shard has 2 replicas. Should be fine. I will pay close watch to this early tomorrow morning.

denny zhang [7:52 AM]
Currently ES cluster has 2 unassigned shards for over 8 hours.

> curl $es_ip:9200/_cluster/health?pretty

We have available disk. Looks like high RAM usage Is the problem.

> root@prod-es-16:/data/elasticsearch# curl $es_ip:9200/_cat/nodes?v | grep es-
> host            ip              heap.percent ram.percent load node.role master name
> 107.170.216.152 107.170.216.152           61          98 1.26 d         m      prod-es-14
> 159.203.192.146 159.203.192.146           53          99 1.66 d         m      prod-es-6
> 159.203.219.53  159.203.219.53            44          86 1.71 d         m      prod-es-4
> 192.241.211.99  192.241.211.99            28          99 1.38 d         m      prod-es-3
> 107.170.212.76  107.170.212.76            58          97 1.14 d         *      prod-es-2
> 107.170.253.222 107.170.253.222           56          87 0.06 d         m      prod-es-15
> 159.203.211.150 159.203.211.150           50          98 2.02 d         m      prod-es-5
> 192.241.206.113 192.241.206.113           63          86 3.16 d         m      prod-es-13
> 104.236.187.173 104.236.187.173           70          98 1.60 d         m      prod-es-10
> 192.241.203.166 192.241.203.166           63          99 0.87 d         m      prod-es-8
> 107.170.237.239 107.170.237.239           58          98 2.81 d         m      prod-es-7
> 107.170.252.123 107.170.252.123           36          94 2.21 d         m      prod-es-11
> 192.241.228.149 192.241.228.149           66          97 2.11 d         m      prod-es-12
> 198.199.95.111  198.199.95.111            37          87 3.42 d         m      prod-es-9
> 138.68.3.169    138.68.3.169              67          95 2.56 d         m      prod-es-16
> 159.203.216.25  159.203.216.25            54          97 1.10 d         m      prod-es-1
** TODO how elasticsearch rebalancing shards
*** Shard Allocation Filtering: allows certain nodes or groups of nodes excluded from allocation so that they can be decommissioned.
https://www.elastic.co/guide/en/elasticsearch/reference/current/allocation-filtering.html
For instance, we could decommission a node using its IP address as follows:

PUT _cluster/settings
{
  "transient" : {
    "cluster.routing.allocation.exclude._ip" : "10.0.0.1"
  }
}
*** Disk-based Shard Allocation
https://www.elastic.co/guide/en/elasticsearch/reference/current/disk-allocator.html#disk-allocator

cluster.routing.allocation.disk.watermark.low
Controls the low watermark for disk usage. It defaults to 85%, meaning ES will not allocate new shards to nodes once they have more than 85% disk used. It can also be set to an absolute byte value (like 500mb) to prevent ES from allocating shards if less than the configured amount of space is available.
cluster.routing.allocation.disk.watermark.high
Controls the high watermark. It defaults to 90%, meaning ES will attempt to relocate shards to another node if the node disk usage rises above 90%. It can also be set to an absolute byte value (similar to the low watermark) to relocate shards once less than the configured amount of space is available on the node.
*** TODO Memory-based Shard Allocation??
** TODO change elasticsearch index shards count without recreating
** TODO elasticsearch shards migration
root@prod-es-16:/data/elasticsearch# curl $es_ip:9200/_cat/shards?v | grep -v STARTED
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0index                                          shard prirep state           docs   store ip              node
staging-index-8cd6e43115e9416eb23609486fa053e3 4     p      RELOCATING  17245659  16.5gb 159.203.219.53  prod-es-4 -> 159.203.216.25 QZ7lxcfNTMG-cR4TJuGCJQ prod-es-1
master-index-abae8b30ac9b11e692000401f8d88101  3     p      RELOCATING 159558808 223.2gb 159.203.216.25  prod-es-1 -> 138.68.3.169 njktyOSCSEqJmK4eeANPLA prod-es-16

#+BEGIN_EXAMPLE
Bruno Volpato [2:31 PM]
also seems that ES is not very smart or starts process in parallel without considering others

[2:31]
prod-es-1 is moving 200gb to prod-es-16, thus freeing 200gb of space

[2:32]
but prod-es-4 is transferring 16gb to prod-es-1, maybe assuming that the space is free already


Nagios BOT [2:33 PM]
prod-es-6/check_disk_rootfs is CRITICAL:
DISK CRITICAL used :  / 9.61% free

Bruno Volpato [2:33 PM]
so if upload is slower than download, the disk may get to 100% in-between

denny zhang [2:33 PM]
Yes, I understand what you're talking about.

A bit buggy calculation.
#+END_EXAMPLE
** TODO elasticsearch how to pause one index relocation
#+BEGIN_EXAMPLE
Bruno Volpato [2:31 PM]
also seems that ES is not very smart or starts process in parallel without considering others

[2:31]
prod-es-1 is moving 200gb to prod-es-16, thus freeing 200gb of space

[2:32]
but prod-es-4 is transferring 16gb to prod-es-1, maybe assuming that the space is free already


Nagios BOT [2:33 PM]
prod-es-6/check_disk_rootfs is CRITICAL:
DISK CRITICAL used :  / 9.61% free

Bruno Volpato [2:33 PM]
so if upload is slower than download, the disk may get to 100% in-between

denny zhang [2:33 PM]
Yes, I understand what you're talking about.

A bit buggy calculation.

[2:35]
Free disk of es-1 keeps dropping.

So "data in" is faster than "data out".
#+END_EXAMPLE
** TODO check es master nodes
https://www.elastic.co/guide/en/elasticsearch/guide/1.x/_important_configuration_changes.html#_minimum_master_nodes
https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html#split-brain
** TODO force elasticsearch rebalancing: https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-reroute.html
** TODO why watch fails: watch "ps -ef | grep elasticsearch"
** TODO prod env: elasticsearch list shard count for all index
curl $es_ip:9200/staging-index-8cd6e43115e9416eb23609486fa053e3/_settings?pretty
#+BEGIN_EXAMPLE
root@prod-es-25:~# curl 138.197.217.168:9200/_stats?v
curl 138.197.217.168:9200/_stats?v
{"_shards":{"total":419,"successful":417,"failed":0},
"_all":{"primaries":
{"docs":{"count":1107141129,"deleted":257801340},"store":{"size_in_bytes":1147650167850,"throttle_time_in_millis":0},"indexing":{"index_total":17100501,"index_time_in_millis":72706683,"index_current":0,"index_failed":181331,"delete_total":5350506,"delete_time_in_millis":3111936,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":164287549,"query_time_in_millis":413004512,"query_current":0,"fetch_total":17051483,"fetch_time_in_millis":6736791,"fetch_current":0,"scroll_total":136340862,"scroll_time_in_millis":11049718218,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":784363,"total_time_in_millis":249494358,"total_docs":943760263,"total_size_in_bytes":1474569536086,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":29576214,"total_auto_throttle_in_bytes":2880706566},"refresh":{"total":84760083,"total_time_in_millis":1378878186},"flush":{"total":2538,"total_time_in_millis":669268},"warmer":{"current":0,"total":16448008,"total_time_in_millis":290974360},"query_cache":{"memory_size_in_bytes":467945064,"total_count":14036665640,"hit_count":1057611682,"miss_count":12979053958,"cache_size":23619,"cache_count":149041,"evictions":125422},"fielddata":{"memory_size_in_bytes":13591047148,"evictions":29867},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":1464,"memory_in_bytes":1719173603,"terms_memory_in_bytes":1534607975,"stored_fields_memory_in_bytes":118749008,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":3619072,"doc_values_memory_in_bytes":62197548,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":16720901561,"version_map_memory_in_bytes":35088,"fixed_bit_set_memory_in_bytes":737268184},"translog":{"operations":374178,"size_in_bytes":153660761},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":2,"current_as_target":0,"throttle_time_in_millis":29900257}},
"total":{"docs":{"count":2903739066,"deleted":643805577},"store":{"size_in_bytes":2997093692946,"throttle_time_in_millis":0},"indexing":{"index_total":29938908,"index_time_in_millis":130014107,"index_current":0,"index_failed":582073,"delete_total":10471604,"delete_time_in_millis":6637479,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":150,"time_in_millis":22,"exists_total":150,"exists_time_in_millis":22,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":293725914,"query_time_in_millis":723859747,"query_current":0,"fetch_total":35892096,"fetch_time_in_millis":15455520,"fetch_current":0,"scroll_total":242913947,"scroll_time_in_millis":22620185365,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":1554945,"total_time_in_millis":482364224,"total_docs":1969686909,"total_size_in_bytes":2899056225536,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":63253415,"total_auto_throttle_in_bytes":8351420792},"refresh":{"total":162724965,"total_time_in_millis":1990648433},"flush":{"total":3919,"total_time_in_millis":1222173},"warmer":{"current":0,"total":32271061,"total_time_in_millis":367286040},"query_cache":{"memory_size_in_bytes":1296658144,"total_count":22226749372,"hit_count":1650246898,"miss_count":20576502474,"cache_size":66063,"cache_count":276180,"evictions":210117},"fielddata":{"memory_size_in_bytes":29180295432,"evictions":116055},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":4219,"memory_in_bytes":4527427442,"terms_memory_in_bytes":4023904558,"stored_fields_memory_in_bytes":311415208,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":10397376,"doc_values_memory_in_bytes":181710300,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":52809796292,"version_map_memory_in_bytes":108880,"fixed_bit_set_memory_in_bytes":1928977552},"translog":{"operations":1122645,"size_in_bytes":461350855},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":2,"current_as_target":0,"throttle_time_in_millis":58840248}}},

"indices":{"master-index-8a6a5b30ade911e698710401f8d88c01":{"primaries":{"docs":{"count":325215,"deleted":136612},"store":{"size_in_bytes":373136467,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":418329,"query_time_in_millis":198991,"query_current":0,"fetch_total":26447,"fetch_time_in_millis":1982,"fetch_current":0,"scroll_total":247591,"scroll_time_in_millis":106419493,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":104857600},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":15,"total_time_in_millis":70},"query_cache":{"memory_size_in_bytes":205536,"total_count":6006819,"hit_count":786075,"miss_count":5220744,"cache_size":496,"cache_count":592,"evictions":96},"fielddata":{"memory_size_in_bytes":643588,"evictions":397},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":42,"memory_in_bytes":6339263,"terms_memory_in_bytes":5399215,"stored_fields_memory_in_bytes":76784,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":140864,"doc_values_memory_in_bytes":722400,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":538918912,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":166680},"translog":{"operations":0,"size_in_bytes":215},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":19324}},"total":{"docs":{"count":975645,"deleted":409836},"store":{"size_in_bytes":1119409401,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":1086779,"query_time_in_millis":631249,"query_current":0,"fetch_total":124546,"fetch_time_in_millis":11760,"fetch_current":0,"scroll_total":641379,"scroll_time_in_millis":270108986,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":314572800},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":45,"total_time_in_millis":187},"query_cache":{"memory_size_in_bytes":556488,"total_count":17091519,"hit_count":2063099,"miss_count":15028420,"cache_size":1556,"cache_count":1734,"evictions":178},"fielddata":{"memory_size_in_bytes":1824572,"evictions":723},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":126,"memory_in_bytes":19017789,"terms_memory_in_bytes":16197645,"stored_fields_memory_in_bytes":230352,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":422592,"doc_values_memory_in_bytes":2167200,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":1397646950,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":500040},"translog":{"operations":0,"size_in_bytes":645},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":58870}}},"staging-index-8a6a5b30ade911e698710401f8d88c01":{"primaries":{"docs":{"count":131,"deleted":107},"store":{"size_in_bytes":4335574,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":823841,"query_time_in_millis":422493,"query_current":0,"fetch_total":487,"fetch_time_in_millis":75,"fetch_current":0,"scroll_total":670169,"scroll_time_in_millis":54735627,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":104857600},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":15,"total_time_in_millis":19},"query_cache":{"memory_size_in_bytes":0,"total_count":43424001,"hit_count":0,"miss_count":43424001,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":12404,"evictions":55},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":8,"memory_in_bytes":2660787,"terms_memory_in_bytes":2539475,"stored_fields_memory_in_bytes":2528,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":16192,"doc_values_memory_in_bytes":102592,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":343900815,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":672},"translog":{"operations":0,"size_in_bytes":215},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":19}},"total":{"docs":{"count":393,"deleted":321},"store":{"size_in_bytes":13006722,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":1946868,"query_time_in_millis":913805,"query_current":0,"fetch_total":1320,"fetch_time_in_millis":341,"fetch_current":0,"scroll_total":1582212,"scroll_time_in_millis":129156811,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":314572800},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":45,"total_time_in_millis":154},"query_cache":{"memory_size_in_bytes":0,"total_count":102818031,"hit_count":0,"miss_count":102818031,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":35472,"evictions":166},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":24,"memory_in_bytes":7982361,"terms_memory_in_bytes":7618425,"stored_fields_memory_in_bytes":7584,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":48576,"doc_values_memory_in_bytes":307776,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":885379727,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":2016},"translog":{"operations":0,"size_in_bytes":645},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":52}}},"staging-index-799e458055c611e6bb000401f8d88101":{"primaries":{"docs":{"count":55023,"deleted":49307},"store":{"size_in_bytes":143071863,"throttle_time_in_millis":0},"indexing":{"index_total":6166,"index_time_in_millis":11885,"index_current":0,"index_failed":20,"delete_total":9667,"delete_time_in_millis":10639,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":27154,"query_time_in_millis":74131,"query_current":0,"fetch_total":8331,"fetch_time_in_millis":867,"fetch_current":0,"scroll_total":22768,"scroll_time_in_millis":1349605,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":336,"total_time_in_millis":12248,"total_docs":447888,"total_size_in_bytes":243075771,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":20971520},"refresh":{"total":18270,"total_time_in_millis":39408},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":14140,"total_time_in_millis":2387},"query_cache":{"memory_size_in_bytes":31888,"total_count":4809206,"hit_count":168038,"miss_count":4641168,"cache_size":41,"cache_count":50,"evictions":9},"fielddata":{"memory_size_in_bytes":427480,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":10,"memory_in_bytes":322656,"terms_memory_in_bytes":295856,"stored_fields_memory_in_bytes":13112,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":1088,"doc_values_memory_in_bytes":12600,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":536870912,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":13624},"translog":{"operations":356459,"size_in_bytes":89720261},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":3301}},"total":{"docs":{"count":165069,"deleted":147942},"store":{"size_in_bytes":429244088,"throttle_time_in_millis":0},"indexing":{"index_total":24784,"index_time_in_millis":33665,"index_current":0,"index_failed":28,"delete_total":37957,"delete_time_in_millis":17427,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":115090,"query_time_in_millis":553172,"query_current":0,"fetch_total":33609,"fetch_time_in_millis":5515,"fetch_current":0,"scroll_total":95916,"scroll_time_in_millis":5953968,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":1261,"total_time_in_millis":47523,"total_docs":1344510,"total_size_in_bytes":764929575,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":62914560},"refresh":{"total":73335,"total_time_in_millis":228226},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":55945,"total_time_in_millis":13477},"query_cache":{"memory_size_in_bytes":95616,"total_count":20805264,"hit_count":545466,"miss_count":20259798,"cache_size":120,"cache_count":143,"evictions":23},"fielddata":{"memory_size_in_bytes":1274716,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":31,"memory_in_bytes":981166,"terms_memory_in_bytes":897490,"stored_fields_memory_in_bytes":39648,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":3328,"doc_values_memory_in_bytes":40700,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":1220576542,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":40920},"translog":{"operations":1069363,"size_in_bytes":269148140},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":6397}}},"master-index-860245c0841e11e6a8260401f8d88101":{"primaries":{"docs":{"count":417494,"deleted":115994},"store":{"size_in_bytes":292678543,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":359143,"query_time_in_millis":329855,"query_current":0,"fetch_total":161963,"fetch_time_in_millis":14183,"fetch_current":0,"scroll_total":165061,"scroll_time_in_millis":84007350,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":20971520},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":3,"total_time_in_millis":13},"query_cache":{"memory_size_in_bytes":131176,"total_count":9579137,"hit_count":892134,"miss_count":8687003,"cache_size":119,"cache_count":154,"evictions":35},"fielddata":{"memory_size_in_bytes":1077560,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":14,"memory_in_bytes":1218552,"terms_memory_in_bytes":1039808,"stored_fields_memory_in_bytes":49192,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":26880,"doc_values_memory_in_bytes":102672,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":512000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":151528},"translog":{"operations":0,"size_in_bytes":43},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":39844}},"total":{"docs":{"count":1252482,"deleted":347982},"store":{"size_in_bytes":878035629,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":496302,"query_time_in_millis":452531,"query_current":0,"fetch_total":240165,"fetch_time_in_millis":19010,"fetch_current":0,"scroll_total":244500,"scroll_time_in_millis":118521584,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":62914560},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":9,"total_time_in_millis":76},"query_cache":{"memory_size_in_bytes":456496,"total_count":12703856,"hit_count":1259494,"miss_count":11444362,"cache_size":344,"cache_count":403,"evictions":59},"fielddata":{"memory_size_in_bytes":2554576,"evictions":391},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":42,"memory_in_bytes":3655656,"terms_memory_in_bytes":3119424,"stored_fields_memory_in_bytes":147576,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":80640,"doc_values_memory_in_bytes":308016,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":245204582,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":454584},"translog":{"operations":0,"size_in_bytes":129},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":41262}}},"staging-index-860245c0841e11e6a8260401f8d88101":{"primaries":{"docs":{"count":3,"deleted":0},"store":{"size_in_bytes":111717,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":752861,"query_time_in_millis":371779,"query_current":0,"fetch_total":197,"fetch_time_in_millis":130,"fetch_current":0,"scroll_total":526243,"scroll_time_in_millis":51024390,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":20971520},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":3,"total_time_in_millis":1},"query_cache":{"memory_size_in_bytes":0,"total_count":18080396,"hit_count":0,"miss_count":18080396,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":900,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":1,"memory_in_bytes":79916,"terms_memory_in_bytes":78768,"stored_fields_memory_in_bytes":312,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":64,"doc_values_memory_in_bytes":772,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":512000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":48},"translog":{"operations":0,"size_in_bytes":43},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":0}},"total":{"docs":{"count":9,"deleted":0},"store":{"size_in_bytes":335151,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":1046764,"query_time_in_millis":542454,"query_current":0,"fetch_total":252,"fetch_time_in_millis":182,"fetch_current":0,"scroll_total":760526,"scroll_time_in_millis":71320307,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":62914560},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":9,"total_time_in_millis":3},"query_cache":{"memory_size_in_bytes":0,"total_count":26361754,"hit_count":0,"miss_count":26361754,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":2700,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":3,"memory_in_bytes":239748,"terms_memory_in_bytes":236304,"stored_fields_memory_in_bytes":936,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":192,"doc_values_memory_in_bytes":2316,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":1536000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":144},"translog":{"operations":0,"size_in_bytes":129},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":0}}},"staging-index-d0935b506a4311e6b61d0401f8d88101":{"primaries":{"docs":{"count":52913298,"deleted":15687153},"store":{"size_in_bytes":54581190264,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":820424,"query_time_in_millis":17995557,"query_current":0,"fetch_total":191,"fetch_time_in_millis":240,"fetch_current":0,"scroll_total":552221,"scroll_time_in_millis":53504721,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":20971520},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":3,"total_time_in_millis":891},"query_cache":{"memory_size_in_bytes":14145944,"total_count":661926532,"hit_count":53570380,"miss_count":608356152,"cache_size":480,"cache_count":1543,"evictions":1063},"fielddata":{"memory_size_in_bytes":274453104,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":34,"memory_in_bytes":66049309,"terms_memory_in_bytes":55216661,"stored_fields_memory_in_bytes":9580808,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":13184,"doc_values_memory_in_bytes":1238656,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":341852815,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":8829808},"translog":{"operations":0,"size_in_bytes":43},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":1884187}},"total":{"docs":{"count":158739894,"deleted":47061459},"store":{"size_in_bytes":163743570792,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":1304148,"query_time_in_millis":25490184,"query_current":0,"fetch_total":262,"fetch_time_in_millis":315,"fetch_current":0,"scroll_total":940987,"scroll_time_in_millis":85940234,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":62914560},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":9,"total_time_in_millis":2578},"query_cache":{"memory_size_in_bytes":46944776,"total_count":1143138820,"hit_count":89787118,"miss_count":1053351702,"cache_size":1384,"cache_count":2609,"evictions":1225},"fielddata":{"memory_size_in_bytes":697794028,"evictions":271},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":102,"memory_in_bytes":198147927,"terms_memory_in_bytes":165649983,"stored_fields_memory_in_bytes":28742424,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":39552,"doc_values_memory_in_bytes":3715968,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":342876815,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":26489424},"translog":{"operations":0,"size_in_bytes":129},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":1884187}}},"master-index-d0935b506a4311e6b61d0401f8d88101":{"primaries":{"docs":{"count":66764796,"deleted":20654605},"store":{"size_in_bytes":34081549610,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":342959,"query_time_in_millis":1586341,"query_current":0,"fetch_total":159730,"fetch_time_in_millis":11608,"fetch_current":0,"scroll_total":162898,"scroll_time_in_millis":85605519,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":20971520},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":3,"total_time_in_millis":1958},"query_cache":{"memory_size_in_bytes":22492440,"total_count":21797859,"hit_count":1630973,"miss_count":20166886,"cache_size":242,"cache_count":368,"evictions":126},"fielddata":{"memory_size_in_bytes":189924620,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":31,"memory_in_bytes":64581149,"terms_memory_in_bytes":59583769,"stored_fields_memory_in_bytes":4781240,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":42624,"doc_values_memory_in_bytes":173516,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":341852815,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":31113848},"translog":{"operations":0,"size_in_bytes":43},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":1312397}},"total":{"docs":{"count":200294388,"deleted":61963815},"store":{"size_in_bytes":102244648830,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":461911,"query_time_in_millis":2016911,"query_current":0,"fetch_total":226177,"fetch_time_in_millis":14387,"fetch_current":0,"scroll_total":230433,"scroll_time_in_millis":116491982,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":62914560},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":9,"total_time_in_millis":5601},"query_cache":{"memory_size_in_bytes":87311832,"total_count":28664302,"hit_count":2229825,"miss_count":26434477,"cache_size":691,"cache_count":847,"evictions":156},"fielddata":{"memory_size_in_bytes":449208452,"evictions":654},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":93,"memory_in_bytes":193743447,"terms_memory_in_bytes":178751307,"stored_fields_memory_in_bytes":14343720,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":127872,"doc_values_memory_in_bytes":520548,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":627242161,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":93341544},"translog":{"operations":0,"size_in_bytes":129},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":1619685}}},"master-index-799e458055c611e6bb000401f8d88101":{"primaries":{"docs":{"count":2839328,"deleted":80033},"store":{"size_in_bytes":1184513442,"throttle_time_in_millis":0},"indexing":{"index_total":402575,"index_time_in_millis":1805425,"index_current":0,"index_failed":0,"delete_total":74026,"delete_time_in_millis":161186,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":316786,"query_time_in_millis":493702,"query_current":0,"fetch_total":165298,"fetch_time_in_millis":35525,"fetch_current":0,"scroll_total":269317,"scroll_time_in_millis":657350625,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":11996,"total_time_in_millis":998527,"total_docs":13056977,"total_size_in_bytes":8875376170,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":20971520},"refresh":{"total":193877,"total_time_in_millis":5886741},"flush":{"total":26,"total_time_in_millis":10910},"warmer":{"current":0,"total":240277,"total_time_in_millis":329615},"query_cache":{"memory_size_in_bytes":1092704,"total_count":6047336,"hit_count":577273,"miss_count":5470063,"cache_size":171,"cache_count":187,"evictions":16},"fielddata":{"memory_size_in_bytes":7149924,"evictions":1060},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":24,"memory_in_bytes":5005187,"terms_memory_in_bytes":4624043,"stored_fields_memory_in_bytes":235056,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":16640,"doc_values_memory_in_bytes":129448,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":341852815,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":1097048},"translog":{"operations":151,"size_in_bytes":182738},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":25367}},"total":{"docs":{"count":8517984,"deleted":179340},"store":{"size_in_bytes":3508590742,"throttle_time_in_millis":0},"indexing":{"index_total":1207653,"index_time_in_millis":4068530,"index_current":0,"index_failed":72,"delete_total":216866,"delete_time_in_millis":226696,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":950050,"query_time_in_millis":1148664,"query_current":0,"fetch_total":495132,"fetch_time_in_millis":84903,"fetch_current":0,"scroll_total":807597,"scroll_time_in_millis":1971005250,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":36451,"total_time_in_millis":2387231,"total_docs":39273221,"total_size_in_bytes":26628816321,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":3639,"total_auto_throttle_in_bytes":61008058},"refresh":{"total":581206,"total_time_in_millis":12363742},"flush":{"total":78,"total_time_in_millis":42464},"warmer":{"current":0,"total":712053,"total_time_in_millis":620703},"query_cache":{"memory_size_in_bytes":4010128,"total_count":18093690,"hit_count":1820137,"miss_count":16273553,"cache_size":618,"cache_count":700,"evictions":82},"fielddata":{"memory_size_in_bytes":21816244,"evictions":2686},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":65,"memory_in_bytes":14689773,"terms_memory_in_bytes":13571561,"stored_fields_memory_in_bytes":699720,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":46080,"doc_values_memory_in_bytes":372412,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":1025558445,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":3268384},"translog":{"operations":420,"size_in_bytes":508118},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":32001}}},"staging-index-b74f5a703d5e11e68ac00401f8d88501":{"primaries":{"docs":{"count":88819,"deleted":18266},"store":{"size_in_bytes":350616835,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":2963119,"query_time_in_millis":7723419,"query_current":0,"fetch_total":548,"fetch_time_in_millis":870,"fetch_current":0,"scroll_total":2291143,"scroll_time_in_millis":244891889,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":104857600},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":15,"total_time_in_millis":82},"query_cache":{"memory_size_in_bytes":131520,"total_count":678670924,"hit_count":58561307,"miss_count":620109617,"cache_size":2180,"cache_count":12322,"evictions":10142},"fielddata":{"memory_size_in_bytes":421008,"evictions":252},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":37,"memory_in_bytes":16110676,"terms_memory_in_bytes":13129120,"stored_fields_memory_in_bytes":110632,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":44352,"doc_values_memory_in_bytes":2826572,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":286925346,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":18416},"translog":{"operations":0,"size_in_bytes":215},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":32541}},"total":{"docs":{"count":266457,"deleted":54798},"store":{"size_in_bytes":1051850505,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":4301127,"query_time_in_millis":9980137,"query_current":0,"fetch_total":789,"fetch_time_in_millis":1180,"fetch_current":0,"scroll_total":3366729,"scroll_time_in_millis":333973167,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":314572800},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":45,"total_time_in_millis":184},"query_cache":{"memory_size_in_bytes":368008,"total_count":989998039,"hit_count":85838646,"miss_count":904159393,"cache_size":6366,"cache_count":23045,"evictions":16679},"fielddata":{"memory_size_in_bytes":1319308,"evictions":418},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":111,"memory_in_bytes":48332028,"terms_memory_in_bytes":39387360,"stored_fields_memory_in_bytes":331896,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":133056,"doc_values_memory_in_bytes":8479716,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":2234137913,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":55248},"translog":{"operations":0,"size_in_bytes":645},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":54903}}},"master-index-d3ae95b0d12811e69edf0401f8d88501":{"primaries":{"docs":{"count":3,"deleted":0},"store":{"size_in_bytes":24510,"throttle_time_in_millis":0},"indexing":{"index_total":7,"index_time_in_millis":20,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":1223743,"query_time_in_millis":105931,"query_current":0,"fetch_total":12,"fetch_time_in_millis":2,"fetch_current":0,"scroll_total":567176,"scroll_time_in_millis":268848029,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":104857600},"refresh":{"total":44,"total_time_in_millis":109},"flush":{"total":3,"total_time_in_millis":70},"warmer":{"current":0,"total":35,"total_time_in_millis":11},"query_cache":{"memory_size_in_bytes":0,"total_count":790145,"hit_count":0,"miss_count":790145,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":1452,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":3,"memory_in_bytes":15092,"terms_memory_in_bytes":13688,"stored_fields_memory_in_bytes":936,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":192,"doc_values_memory_in_bytes":276,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":2560000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":144},"translog":{"operations":0,"size_in_bytes":215},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":0}},"total":{"docs":{"count":9,"deleted":0},"store":{"size_in_bytes":73529,"throttle_time_in_millis":0},"indexing":{"index_total":21,"index_time_in_millis":87,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":1792471,"query_time_in_millis":174953,"query_current":0,"fetch_total":27,"fetch_time_in_millis":10,"fetch_current":0,"scroll_total":900308,"scroll_time_in_millis":414636248,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":314572800},"refresh":{"total":96,"total_time_in_millis":419},"flush":{"total":9,"total_time_in_millis":406},"warmer":{"current":0,"total":105,"total_time_in_millis":73},"query_cache":{"memory_size_in_bytes":0,"total_count":1563078,"hit_count":0,"miss_count":1563078,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":3432,"evictions":119},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":9,"memory_in_bytes":45276,"terms_memory_in_bytes":41064,"stored_fields_memory_in_bytes":2808,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":576,"doc_values_memory_in_bytes":828,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":349020815,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":432},"translog":{"operations":0,"size_in_bytes":645},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":0}}},"staging-index-8cd6e43115e9416eb23609486fa053e3":{"primaries":{"docs":{"count":86212794,"deleted":32673698},"store":{"size_in_bytes":88248034449,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":1354573,"query_time_in_millis":12923768,"query_current":0,"fetch_total":230,"fetch_time_in_millis":127,"fetch_current":0,"scroll_total":1086001,"scroll_time_in_millis":91214573,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":104857600},"refresh":{"total":757,"total_time_in_millis":92},"flush":{"total":2,"total_time_in_millis":8},"warmer":{"current":0,"total":15,"total_time_in_millis":3629},"query_cache":{"memory_size_in_bytes":30660480,"total_count":1087602434,"hit_count":39456020,"miss_count":1048146414,"cache_size":844,"cache_count":1281,"evictions":437},"fielddata":{"memory_size_in_bytes":433586660,"evictions":365},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":134,"memory_in_bytes":226608929,"terms_memory_in_bytes":212868969,"stored_fields_memory_in_bytes":12681880,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":67968,"doc_values_memory_in_bytes":990112,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":1307063746,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":14886488},"translog":{"operations":0,"size_in_bytes":215},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":646665}},"total":{"docs":{"count":172425588,"deleted":65347396},"store":{"size_in_bytes":176496067305,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":2116924,"query_time_in_millis":19841350,"query_current":0,"fetch_total":355,"fetch_time_in_millis":227,"fetch_current":0,"scroll_total":1702887,"scroll_time_in_millis":141399068,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":209715200},"refresh":{"total":1461,"total_time_in_millis":94},"flush":{"total":2,"total_time_in_millis":8},"warmer":{"current":0,"total":30,"total_time_in_millis":6205},"query_cache":{"memory_size_in_bytes":67709992,"total_count":1693176062,"hit_count":62731260,"miss_count":1630444802,"cache_size":1687,"cache_count":2357,"evictions":670},"fielddata":{"memory_size_in_bytes":863002692,"evictions":4640},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":268,"memory_in_bytes":453217858,"terms_memory_in_bytes":425737938,"stored_fields_memory_in_bytes":25363760,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":135936,"doc_values_memory_in_bytes":1980224,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":3544406643,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":29772976},"translog":{"operations":0,"size_in_bytes":430},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":2382750}}},"staging-index-839920f07e6b11e6b71d0401f8d88101":{"primaries":{"docs":{"count":1626682,"deleted":172098},"store":{"size_in_bytes":7065554047,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":203478,"query_time_in_millis":2105379,"query_current":0,"fetch_total":573,"fetch_time_in_millis":60574,"fetch_current":0,"scroll_total":166985,"scroll_time_in_millis":13938635,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":20971520},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":3,"total_time_in_millis":29},"query_cache":{"memory_size_in_bytes":107048,"total_count":95408140,"hit_count":3243717,"miss_count":92164423,"cache_size":383,"cache_count":1872,"evictions":1489},"fielddata":{"memory_size_in_bytes":13381532,"evictions":109},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":16,"memory_in_bytes":17785950,"terms_memory_in_bytes":14638918,"stored_fields_memory_in_bytes":1864856,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":7616,"doc_values_memory_in_bytes":1274560,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":341852815,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":225680},"translog":{"operations":0,"size_in_bytes":43},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":140829}},"total":{"docs":{"count":4880046,"deleted":516294},"store":{"size_in_bytes":21196662141,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":434377,"query_time_in_millis":5267726,"query_current":0,"fetch_total":1168,"fetch_time_in_millis":151134,"fetch_current":0,"scroll_total":354863,"scroll_time_in_millis":29252431,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":62914560},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":9,"total_time_in_millis":84},"query_cache":{"memory_size_in_bytes":289160,"total_count":203917831,"hit_count":6918047,"miss_count":196999784,"cache_size":932,"cache_count":3890,"evictions":2958},"fielddata":{"memory_size_in_bytes":28096516,"evictions":517},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":48,"memory_in_bytes":53357850,"terms_memory_in_bytes":43916754,"stored_fields_memory_in_bytes":5594568,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":22848,"doc_values_memory_in_bytes":3823680,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":799691406,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":677040},"translog":{"operations":0,"size_in_bytes":129},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":305475}}},"master-index-41d17930c8e211e6aae30401f8d88101":{"primaries":{"docs":{"count":2,"deleted":0},"store":{"size_in_bytes":19581,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":812024,"query_time_in_millis":73678,"query_current":0,"fetch_total":1,"fetch_time_in_millis":2,"fetch_current":0,"scroll_total":450334,"scroll_time_in_millis":207115903,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":104857600},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":15,"total_time_in_millis":5},"query_cache":{"memory_size_in_bytes":0,"total_count":495846,"hit_count":0,"miss_count":495846,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":1176,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":2,"memory_in_bytes":11186,"terms_memory_in_bytes":10250,"stored_fields_memory_in_bytes":624,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":128,"doc_values_memory_in_bytes":184,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":2560000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":96},"translog":{"operations":0,"size_in_bytes":215},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":0}},"total":{"docs":{"count":6,"deleted":0},"store":{"size_in_bytes":58744,"throttle_time_in_millis":0},"indexing":{"index_total":1,"index_time_in_millis":8,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":2668054,"query_time_in_millis":391815,"query_current":0,"fetch_total":6,"fetch_time_in_millis":3,"fetch_current":0,"scroll_total":1467992,"scroll_time_in_millis":664629994,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":314572800},"refresh":{"total":7,"total_time_in_millis":19},"flush":{"total":2,"total_time_in_millis":14},"warmer":{"current":0,"total":50,"total_time_in_millis":12},"query_cache":{"memory_size_in_bytes":0,"total_count":3159118,"hit_count":0,"miss_count":3159118,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":2912,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":6,"memory_in_bytes":33558,"terms_memory_in_bytes":30750,"stored_fields_memory_in_bytes":1872,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":384,"doc_values_memory_in_bytes":552,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":7680000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":288},"translog":{"operations":0,"size_in_bytes":645},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":0}}},"staging-index-f1e6b200c8e611e6aae30401f8d88101":{"primaries":{"docs":{"count":0,"deleted":0},"store":{"size_in_bytes":795,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":363433,"query_time_in_millis":16106,"query_current":0,"fetch_total":0,"fetch_time_in_millis":0,"fetch_current":0,"scroll_total":9,"scroll_time_in_millis":24,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":104857600},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":15,"total_time_in_millis":1},"query_cache":{"memory_size_in_bytes":0,"total_count":0,"hit_count":0,"miss_count":0,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":0,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":0,"memory_in_bytes":0,"terms_memory_in_bytes":0,"stored_fields_memory_in_bytes":0,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":0,"doc_values_memory_in_bytes":0,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":2560000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":0},"translog":{"operations":0,"size_in_bytes":215},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":0}},"total":{"docs":{"count":0,"deleted":0},"store":{"size_in_bytes":2385,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":1235458,"query_time_in_millis":67050,"query_current":0,"fetch_total":0,"fetch_time_in_millis":0,"fetch_current":0,"scroll_total":45,"scroll_time_in_millis":312,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":314572800},"refresh":{"total":1,"total_time_in_millis":6},"flush":{"total":1,"total_time_in_millis":0},"warmer":{"current":0,"total":46,"total_time_in_millis":4},"query_cache":{"memory_size_in_bytes":0,"total_count":0,"hit_count":0,"miss_count":0,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":0,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":0,"memory_in_bytes":0,"terms_memory_in_bytes":0,"stored_fields_memory_in_bytes":0,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":0,"doc_values_memory_in_bytes":0,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":828404258,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":0},"translog":{"operations":0,"size_in_bytes":645},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":0}}},"master-index-3fa847206b9911e6b61d0401f8d88101":{"primaries":{"docs":{"count":4,"deleted":0},"store":{"size_in_bytes":34254,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":192980,"query_time_in_millis":54343,"query_current":0,"fetch_total":108184,"fetch_time_in_millis":1308,"fetch_current":0,"scroll_total":109739,"scroll_time_in_millis":43658967,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":20971520},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":3,"total_time_in_millis":0},"query_cache":{"memory_size_in_bytes":0,"total_count":908240,"hit_count":0,"miss_count":908240,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":3396,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":4,"memory_in_bytes":21649,"terms_memory_in_bytes":19777,"stored_fields_memory_in_bytes":1248,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":256,"doc_values_memory_in_bytes":368,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":512000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":0},"translog":{"operations":0,"size_in_bytes":43},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":0}},"total":{"docs":{"count":12,"deleted":0},"store":{"size_in_bytes":102762,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":303537,"query_time_in_millis":68427,"query_current":0,"fetch_total":172061,"fetch_time_in_millis":1789,"fetch_current":0,"scroll_total":174683,"scroll_time_in_millis":72386876,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":62914560},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":9,"total_time_in_millis":1},"query_cache":{"memory_size_in_bytes":0,"total_count":1416796,"hit_count":0,"miss_count":1416796,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":8828,"evictions":187},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":12,"memory_in_bytes":64947,"terms_memory_in_bytes":59331,"stored_fields_memory_in_bytes":3744,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":768,"doc_values_memory_in_bytes":1104,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":1536000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":0},"translog":{"operations":0,"size_in_bytes":129},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":0}}},"staging-index-da1c1280ac9b11e68e250401f8d88501":{"primaries":{"docs":{"count":5173186,"deleted":9087},"store":{"size_in_bytes":3665193109,"throttle_time_in_millis":0},"indexing":{"index_total":421388,"index_time_in_millis":1016412,"index_current":0,"index_failed":447,"delete_total":1308,"delete_time_in_millis":144255,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":1729147,"query_time_in_millis":9471101,"query_current":0,"fetch_total":40216,"fetch_time_in_millis":6380,"fetch_current":0,"scroll_total":1377600,"scroll_time_in_millis":102213034,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":17021,"total_time_in_millis":2290193,"total_docs":38207923,"total_size_in_bytes":23730838981,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":1097,"total_auto_throttle_in_bytes":102951098},"refresh":{"total":574960,"total_time_in_millis":2428667},"flush":{"total":621,"total_time_in_millis":65194},"warmer":{"current":0,"total":350740,"total_time_in_millis":57014},"query_cache":{"memory_size_in_bytes":1381952,"total_count":734612010,"hit_count":72042395,"miss_count":662569615,"cache_size":9190,"cache_count":65495,"evictions":56305},"fielddata":{"memory_size_in_bytes":26032276,"evictions":2198},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":98,"memory_in_bytes":10940193,"terms_memory_in_bytes":9956777,"stored_fields_memory_in_bytes":822856,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":6272,"doc_values_memory_in_bytes":154288,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":2560000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":0},"translog":{"operations":0,"size_in_bytes":215},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":154425}},"total":{"docs":{"count":15519558,"deleted":27360},"store":{"size_in_bytes":10995542057,"throttle_time_in_millis":0},"indexing":{"index_total":794259,"index_time_in_millis":1466928,"index_current":0,"index_failed":2421,"delete_total":1435,"delete_time_in_millis":144267,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":3289756,"query_time_in_millis":17895017,"query_current":0,"fetch_total":74291,"fetch_time_in_millis":10064,"fetch_current":0,"scroll_total":2665739,"scroll_time_in_millis":194759899,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":30171,"total_time_in_millis":3861078,"total_docs":65968383,"total_size_in_bytes":42075244015,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":1779,"total_auto_throttle_in_bytes":310759796},"refresh":{"total":1013058,"total_time_in_millis":4624006},"flush":{"total":1120,"total_time_in_millis":108786},"warmer":{"current":0,"total":622786,"total_time_in_millis":109940},"query_cache":{"memory_size_in_bytes":4143848,"total_count":1470183456,"hit_count":141126179,"miss_count":1329057277,"cache_size":26062,"cache_count":116711,"evictions":90649},"fielddata":{"memory_size_in_bytes":78107240,"evictions":10294},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":297,"memory_in_bytes":32827567,"terms_memory_in_bytes":29888931,"stored_fields_memory_in_bytes":2469576,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":19008,"doc_values_memory_in_bytes":450052,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":7680000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":0},"translog":{"operations":0,"size_in_bytes":645},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":235415}}},".kibana":{"primaries":{"docs":{"count":88,"deleted":3},"store":{"size_in_bytes":858087,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":8533,"query_time_in_millis":553,"query_current":0,"fetch_total":1932,"fetch_time_in_millis":140,"fetch_current":0,"scroll_total":0,"scroll_time_in_millis":0,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":20971520},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":3,"total_time_in_millis":2},"query_cache":{"memory_size_in_bytes":0,"total_count":105847,"hit_count":0,"miss_count":105847,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":0,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":7,"memory_in_bytes":32771,"terms_memory_in_bytes":26135,"stored_fields_memory_in_bytes":2200,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":3136,"doc_values_memory_in_bytes":1300,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":536870912,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":0},"translog":{"operations":0,"size_in_bytes":43},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":12}},"total":{"docs":{"count":176,"deleted":6},"store":{"size_in_bytes":1716173,"throttle_time_in_millis":0},"indexing":{"index_total":1,"index_time_in_millis":8,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":150,"time_in_millis":22,"exists_total":150,"exists_time_in_millis":22,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":65847,"query_time_in_millis":4596,"query_current":0,"fetch_total":14050,"fetch_time_in_millis":1071,"fetch_current":0,"scroll_total":0,"scroll_time_in_millis":0,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":41943040},"refresh":{"total":2,"total_time_in_millis":8},"flush":{"total":1,"total_time_in_millis":11},"warmer":{"current":0,"total":10,"total_time_in_millis":2},"query_cache":{"memory_size_in_bytes":0,"total_count":823473,"hit_count":0,"miss_count":823473,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":0,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":14,"memory_in_bytes":65542,"terms_memory_in_bytes":52270,"stored_fields_memory_in_bytes":4400,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":6272,"doc_values_memory_in_bytes":2600,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":537382912,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":0},"translog":{"operations":0,"size_in_bytes":86},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":13}}},"master-index-da1c1280ac9b11e68e250401f8d88501":{"primaries":{"docs":{"count":2,"deleted":0},"store":{"size_in_bytes":16195,"throttle_time_in_millis":0},"indexing":{"index_total":70,"index_time_in_millis":534,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":665297,"query_time_in_millis":44978,"query_current":0,"fetch_total":22,"fetch_time_in_millis":0,"fetch_current":0,"scroll_total":354769,"scroll_time_in_millis":164731733,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":104857600},"refresh":{"total":863,"total_time_in_millis":578},"flush":{"total":70,"total_time_in_millis":5875},"warmer":{"current":0,"total":295,"total_time_in_millis":65},"query_cache":{"memory_size_in_bytes":0,"total_count":255025,"hit_count":0,"miss_count":255025,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":868,"evictions":7},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":2,"memory_in_bytes":9740,"terms_memory_in_bytes":8804,"stored_fields_memory_in_bytes":624,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":128,"doc_values_memory_in_bytes":184,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":2560000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":0},"translog":{"operations":0,"size_in_bytes":215},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":0}},"total":{"docs":{"count":6,"deleted":0},"store":{"size_in_bytes":48587,"throttle_time_in_millis":0},"indexing":{"index_total":179,"index_time_in_millis":910,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":2016971,"query_time_in_millis":133824,"query_current":0,"fetch_total":67,"fetch_time_in_millis":5,"fetch_current":0,"scroll_total":1057771,"scroll_time_in_millis":534601919,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":314572800},"refresh":{"total":2865,"total_time_in_millis":1861},"flush":{"total":179,"total_time_in_millis":7899},"warmer":{"current":0,"total":761,"total_time_in_millis":208},"query_cache":{"memory_size_in_bytes":0,"total_count":602428,"hit_count":0,"miss_count":602428,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":2296,"evictions":9},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":6,"memory_in_bytes":29220,"terms_memory_in_bytes":26412,"stored_fields_memory_in_bytes":1872,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":384,"doc_values_memory_in_bytes":552,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":7680000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":0},"translog":{"operations":0,"size_in_bytes":645},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":0}}},"staging-index-41d17930c8e211e6aae30401f8d88101":{"primaries":{"docs":{"count":0,"deleted":0},"store":{"size_in_bytes":795,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":699077,"query_time_in_millis":49501,"query_current":0,"fetch_total":0,"fetch_time_in_millis":0,"fetch_current":0,"scroll_total":566689,"scroll_time_in_millis":46544451,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":104857600},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":15,"total_time_in_millis":0},"query_cache":{"memory_size_in_bytes":0,"total_count":0,"hit_count":0,"miss_count":0,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":0,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":0,"memory_in_bytes":0,"terms_memory_in_bytes":0,"stored_fields_memory_in_bytes":0,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":0,"doc_values_memory_in_bytes":0,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":2560000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":0},"translog":{"operations":0,"size_in_bytes":215},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":0}},"total":{"docs":{"count":0,"deleted":0},"store":{"size_in_bytes":2385,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":5257686,"query_time_in_millis":535291,"query_current":0,"fetch_total":0,"fetch_time_in_millis":0,"fetch_current":0,"scroll_total":4149379,"scroll_time_in_millis":485653908,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":314572800},"refresh":{"total":1,"total_time_in_millis":10},"flush":{"total":1,"total_time_in_millis":0},"warmer":{"current":0,"total":46,"total_time_in_millis":0},"query_cache":{"memory_size_in_bytes":0,"total_count":0,"hit_count":0,"miss_count":0,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":0,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":0,"memory_in_bytes":0,"terms_memory_in_bytes":0,"stored_fields_memory_in_bytes":0,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":0,"doc_values_memory_in_bytes":0,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":349020815,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":0},"translog":{"operations":0,"size_in_bytes":645},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":0}}},"staging-index-3366bf206f2a11e694f80401f8d88c01":{"primaries":{"docs":{"count":559,"deleted":1083},"store":{"size_in_bytes":4343422,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":20660,"query_time_in_millis":16968,"query_current":0,"fetch_total":4,"fetch_time_in_millis":6,"fetch_current":0,"scroll_total":16275,"scroll_time_in_millis":1214456,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":20971520},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":3,"total_time_in_millis":3},"query_cache":{"memory_size_in_bytes":0,"total_count":3469322,"hit_count":0,"miss_count":3469322,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":15116,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":6,"memory_in_bytes":1856283,"terms_memory_in_bytes":1702691,"stored_fields_memory_in_bytes":2192,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":640,"doc_values_memory_in_bytes":150760,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":512000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":480},"translog":{"operations":0,"size_in_bytes":43},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":1}},"total":{"docs":{"count":1677,"deleted":3249},"store":{"size_in_bytes":13030266,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":450304,"query_time_in_millis":607726,"query_current":0,"fetch_total":89,"fetch_time_in_millis":265,"fetch_current":0,"scroll_total":367435,"scroll_time_in_millis":30463109,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":62914560},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":9,"total_time_in_millis":8},"query_cache":{"memory_size_in_bytes":0,"total_count":79882723,"hit_count":0,"miss_count":79882723,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":42412,"evictions":968},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":18,"memory_in_bytes":5568849,"terms_memory_in_bytes":5108073,"stored_fields_memory_in_bytes":6576,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":1920,"doc_values_memory_in_bytes":452280,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":1536000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":1440},"translog":{"operations":0,"size_in_bytes":129},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":27}}},"master-index-cf7388b0542411e68c440401f8d88501":{"primaries":{"docs":{"count":183,"deleted":17},"store":{"size_in_bytes":502071,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":76160,"query_time_in_millis":19268,"query_current":0,"fetch_total":45816,"fetch_time_in_millis":317,"fetch_current":0,"scroll_total":46487,"scroll_time_in_millis":18731852,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":20971520},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":3,"total_time_in_millis":1},"query_cache":{"memory_size_in_bytes":0,"total_count":1026231,"hit_count":0,"miss_count":1026231,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":4000,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":9,"memory_in_bytes":207649,"terms_memory_in_bytes":172645,"stored_fields_memory_in_bytes":2816,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":576,"doc_values_memory_in_bytes":31612,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":512000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":448},"translog":{"operations":0,"size_in_bytes":43},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":0}},"total":{"docs":{"count":549,"deleted":51},"store":{"size_in_bytes":1506213,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":96121,"query_time_in_millis":23951,"query_current":0,"fetch_total":56852,"fetch_time_in_millis":412,"fetch_current":0,"scroll_total":57645,"scroll_time_in_millis":21836678,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":62914560},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":9,"total_time_in_millis":7},"query_cache":{"memory_size_in_bytes":0,"total_count":1319456,"hit_count":0,"miss_count":1319456,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":12000,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":27,"memory_in_bytes":622947,"terms_memory_in_bytes":517935,"stored_fields_memory_in_bytes":8448,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":1728,"doc_values_memory_in_bytes":94836,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":1536000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":1344},"translog":{"operations":0,"size_in_bytes":129},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":0}}},"staging-index-abae8b30ac9b11e692000401f8d88101":{"primaries":{"docs":{"count":3380529,"deleted":3933327},"store":{"size_in_bytes":33440806277,"throttle_time_in_millis":0},"indexing":{"index_total":268202,"index_time_in_millis":633378,"index_current":0,"index_failed":2872,"delete_total":1532097,"delete_time_in_millis":1188767,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":4023376,"query_time_in_millis":22292158,"query_current":0,"fetch_total":104561,"fetch_time_in_millis":102309,"fetch_current":0,"scroll_total":3785741,"scroll_time_in_millis":135520280,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":6281,"total_time_in_millis":2127780,"total_docs":6174999,"total_size_in_bytes":32117039635,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":353053,"total_auto_throttle_in_bytes":77922937},"refresh":{"total":12837504,"total_time_in_millis":15868814},"flush":{"total":6,"total_time_in_millis":1249},"warmer":{"current":0,"total":1207996,"total_time_in_millis":1498351},"query_cache":{"memory_size_in_bytes":1394464,"total_count":769649426,"hit_count":19578914,"miss_count":750070512,"cache_size":361,"cache_count":430,"evictions":69},"fielddata":{"memory_size_in_bytes":183169448,"evictions":256},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":114,"memory_in_bytes":64551663,"terms_memory_in_bytes":58254759,"stored_fields_memory_in_bytes":3515752,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":341376,"doc_values_memory_in_bytes":2439776,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":2270226677,"version_map_memory_in_bytes":13120,"fixed_bit_set_memory_in_bytes":1250496},"translog":{"operations":15536,"size_in_bytes":58959935},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":1252062}},"total":{"docs":{"count":10141581,"deleted":12375979},"store":{"size_in_bytes":103677358586,"throttle_time_in_millis":0},"indexing":{"index_total":704616,"index_time_in_millis":1617882,"index_current":0,"index_failed":3944,"delete_total":4039276,"delete_time_in_millis":3618205,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":10488714,"query_time_in_millis":53479748,"query_current":0,"fetch_total":303421,"fetch_time_in_millis":331277,"fetch_current":0,"scroll_total":9881986,"scroll_time_in_millis":347854826,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":17544,"total_time_in_millis":5096696,"total_docs":14870504,"total_size_in_bytes":76860878427,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":692133,"total_auto_throttle_in_bytes":247273579},"refresh":{"total":33845528,"total_time_in_millis":43360007},"flush":{"total":17,"total_time_in_millis":4123},"warmer":{"current":0,"total":3143966,"total_time_in_millis":3735839},"query_cache":{"memory_size_in_bytes":4504736,"total_count":2074387607,"hit_count":53543807,"miss_count":2020843800,"cache_size":1117,"cache_count":1397,"evictions":280},"fielddata":{"memory_size_in_bytes":442250576,"evictions":20938},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":368,"memory_in_bytes":202083785,"terms_memory_in_bytes":182197033,"stored_fields_memory_in_bytes":10893992,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":1143040,"doc_values_memory_in_bytes":7849720,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":6030607643,"version_map_memory_in_bytes":39360,"fixed_bit_set_memory_in_bytes":3608072},"translog":{"operations":46608,"size_in_bytes":176879805},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":3150004}}},"staging-fd1125e03cb711e6878f0401f8d88c01":{"primaries":{"docs":{"count":0,"deleted":0},"store":{"size_in_bytes":795,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":1,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":43748,"query_time_in_millis":1481,"query_current":0,"fetch_total":0,"fetch_time_in_millis":0,"fetch_current":0,"scroll_total":0,"scroll_time_in_millis":0,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":104857600},"refresh":{"total":3,"total_time_in_millis":0},"flush":{"total":3,"total_time_in_millis":2},"warmer":{"current":0,"total":15,"total_time_in_millis":0},"query_cache":{"memory_size_in_bytes":0,"total_count":0,"hit_count":0,"miss_count":0,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":0,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":0,"memory_in_bytes":0,"terms_memory_in_bytes":0,"stored_fields_memory_in_bytes":0,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":0,"doc_values_memory_in_bytes":0,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":2560000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":0},"translog":{"operations":1,"size_in_bytes":288},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":0}},"total":{"docs":{"count":0,"deleted":0},"store":{"size_in_bytes":1590,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":1,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":94715,"query_time_in_millis":3083,"query_current":0,"fetch_total":0,"fetch_time_in_millis":0,"fetch_current":0,"scroll_total":0,"scroll_time_in_millis":0,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":209715200},"refresh":{"total":8,"total_time_in_millis":20},"flush":{"total":8,"total_time_in_millis":2},"warmer":{"current":0,"total":35,"total_time_in_millis":0},"query_cache":{"memory_size_in_bytes":0,"total_count":0,"hit_count":0,"miss_count":0,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":0,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":0,"memory_in_bytes":0,"terms_memory_in_bytes":0,"stored_fields_memory_in_bytes":0,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":0,"doc_values_memory_in_bytes":0,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":5120000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":0},"translog":{"operations":2,"size_in_bytes":576},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":0}}},"master-index-5e527960c34211e6b3ff0401f8d88c01":{"primaries":{"docs":{"count":25711181,"deleted":5831134},"store":{"size_in_bytes":22790292273,"throttle_time_in_millis":0},"indexing":{"index_total":266947,"index_time_in_millis":1376260,"index_current":0,"index_failed":645,"delete_total":246,"delete_time_in_millis":116,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":2356738,"query_time_in_millis":5201863,"query_current":0,"fetch_total":302718,"fetch_time_in_millis":66067,"fetch_current":0,"scroll_total":2184248,"scroll_time_in_millis":140858791,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":23995,"total_time_in_millis":7761829,"total_docs":78577110,"total_size_in_bytes":43626639627,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":72064,"total_auto_throttle_in_bytes":89181599},"refresh":{"total":1199611,"total_time_in_millis":9551684},"flush":{"total":18,"total_time_in_millis":1683},"warmer":{"current":0,"total":467142,"total_time_in_millis":2205513},"query_cache":{"memory_size_in_bytes":12514048,"total_count":50757548,"hit_count":4636922,"miss_count":46120626,"cache_size":1065,"cache_count":1353,"evictions":288},"fielddata":{"memory_size_in_bytes":238649276,"evictions":840},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":136,"memory_in_bytes":65410005,"terms_memory_in_bytes":57753677,"stored_fields_memory_in_bytes":2466896,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":577088,"doc_values_memory_in_bytes":4612344,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":2560000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":11845344},"translog":{"operations":0,"size_in_bytes":215},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":951090}},"total":{"docs":{"count":77133543,"deleted":17518435},"store":{"size_in_bytes":68699342907,"throttle_time_in_millis":0},"indexing":{"index_total":982652,"index_time_in_millis":5725149,"index_current":0,"index_failed":2564,"delete_total":32711,"delete_time_in_millis":18477,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":7610871,"query_time_in_millis":15376887,"query_current":0,"fetch_total":928828,"fetch_time_in_millis":191655,"fetch_current":0,"scroll_total":7061452,"scroll_time_in_millis":1210616870,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":85314,"total_time_in_millis":29639486,"total_docs":255618475,"total_size_in_bytes":153642068390,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":409015,"total_auto_throttle_in_bytes":252098607},"refresh":{"total":4366927,"total_time_in_millis":38432551},"flush":{"total":70,"total_time_in_millis":9098},"warmer":{"current":0,"total":1648241,"total_time_in_millis":6784461},"query_cache":{"memory_size_in_bytes":34908432,"total_count":164970529,"hit_count":14414831,"miss_count":150555698,"cache_size":3059,"cache_count":3889,"evictions":830},"fielddata":{"memory_size_in_bytes":724148636,"evictions":3546},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":403,"memory_in_bytes":198143504,"terms_memory_in_bytes":175067060,"stored_fields_memory_in_bytes":7405056,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":1727936,"doc_values_memory_in_bytes":13943452,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":7680000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":35545080},"translog":{"operations":0,"size_in_bytes":645},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":1754606}}},"staging-index-cf5e90403d5e11e68ac00401f8d88501":{"primaries":{"docs":{"count":168810,"deleted":82147},"store":{"size_in_bytes":566050761,"throttle_time_in_millis":0},"indexing":{"index_total":124,"index_time_in_millis":3566,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":13637974,"query_time_in_millis":45451105,"query_current":0,"fetch_total":2621,"fetch_time_in_millis":15135,"fetch_current":0,"scroll_total":10461514,"scroll_time_in_millis":1444586605,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":2,"total_time_in_millis":1748,"total_docs":1431,"total_size_in_bytes":9378909,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":104857600},"refresh":{"total":21,"total_time_in_millis":1816},"flush":{"total":4,"total_time_in_millis":88},"warmer":{"current":0,"total":50,"total_time_in_millis":974},"query_cache":{"memory_size_in_bytes":268472,"total_count":3287022195,"hit_count":228518935,"miss_count":3058503260,"cache_size":534,"cache_count":9090,"evictions":8556},"fielddata":{"memory_size_in_bytes":989024,"evictions":2523},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":48,"memory_in_bytes":33945961,"terms_memory_in_bytes":29598481,"stored_fields_memory_in_bytes":197784,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":16640,"doc_values_memory_in_bytes":4133056,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":459374591,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":34720},"translog":{"operations":0,"size_in_bytes":215},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":34902}},"total":{"docs":{"count":506430,"deleted":246441},"store":{"size_in_bytes":1698152283,"throttle_time_in_millis":0},"indexing":{"index_total":124,"index_time_in_millis":3566,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":15364125,"query_time_in_millis":51480349,"query_current":0,"fetch_total":2927,"fetch_time_in_millis":17469,"fetch_current":0,"scroll_total":11775674,"scroll_time_in_millis":1557948021,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":2,"total_time_in_millis":1748,"total_docs":1431,"total_size_in_bytes":9378909,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":314572800},"refresh":{"total":21,"total_time_in_millis":1816},"flush":{"total":4,"total_time_in_millis":88},"warmer":{"current":0,"total":80,"total_time_in_millis":1458},"query_cache":{"memory_size_in_bytes":756600,"total_count":3803140845,"hit_count":256830245,"miss_count":3546310600,"cache_size":1403,"cache_count":10356,"evictions":8953},"fielddata":{"memory_size_in_bytes":3017456,"evictions":2716},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":144,"memory_in_bytes":101837883,"terms_memory_in_bytes":88795443,"stored_fields_memory_in_bytes":593352,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":49920,"doc_values_memory_in_bytes":12399168,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":2317239909,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":104160},"translog":{"operations":0,"size_in_bytes":645},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":75437}}},"master-index-025e2270c5cd11e6b9610401f8d88501":{"primaries":{"docs":{"count":2,"deleted":0},"store":{"size_in_bytes":17401,"throttle_time_in_millis":0},"indexing":{"index_total":1,"index_time_in_millis":15,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":3418318,"query_time_in_millis":347265,"query_current":0,"fetch_total":3,"fetch_time_in_millis":7,"fetch_current":0,"scroll_total":1751820,"scroll_time_in_millis":852707347,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":104857600},"refresh":{"total":8,"total_time_in_millis":39},"flush":{"total":1,"total_time_in_millis":20},"warmer":{"current":0,"total":19,"total_time_in_millis":24},"query_cache":{"memory_size_in_bytes":0,"total_count":3062816,"hit_count":0,"miss_count":3062816,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":860,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":2,"memory_in_bytes":10704,"terms_memory_in_bytes":9768,"stored_fields_memory_in_bytes":624,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":128,"doc_values_memory_in_bytes":184,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":286925346,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":96},"translog":{"operations":0,"size_in_bytes":215},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":0}},"total":{"docs":{"count":6,"deleted":0},"store":{"size_in_bytes":52203,"throttle_time_in_millis":0},"indexing":{"index_total":1,"index_time_in_millis":15,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":4002764,"query_time_in_millis":383959,"query_current":0,"fetch_total":3,"fetch_time_in_millis":7,"fetch_current":0,"scroll_total":2095492,"scroll_time_in_millis":992671012,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":314572800},"refresh":{"total":8,"total_time_in_millis":39},"flush":{"total":1,"total_time_in_millis":20},"warmer":{"current":0,"total":49,"total_time_in_millis":26},"query_cache":{"memory_size_in_bytes":0,"total_count":3395006,"hit_count":0,"miss_count":3395006,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":2272,"evictions":1},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":6,"memory_in_bytes":32112,"terms_memory_in_bytes":29304,"stored_fields_memory_in_bytes":1872,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":384,"doc_values_memory_in_bytes":552,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":292045346,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":288},"translog":{"operations":0,"size_in_bytes":645},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":0}}},"staging-index-5e527960c34211e6b3ff0401f8d88c01":{"primaries":{"docs":{"count":1562134,"deleted":1016226},"store":{"size_in_bytes":3956833611,"throttle_time_in_millis":0},"indexing":{"index_total":7296574,"index_time_in_millis":20276445,"index_current":0,"index_failed":104,"delete_total":1796595,"delete_time_in_millis":730682,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":69583843,"query_time_in_millis":143011111,"query_current":0,"fetch_total":10645178,"fetch_time_in_millis":1814131,"fetch_current":0,"scroll_total":68470129,"scroll_time_in_millis":1674592010,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":128194,"total_time_in_millis":60645639,"total_docs":92854976,"total_size_in_bytes":267061642374,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":1216933,"total_auto_throttle_in_bytes":87222458},"refresh":{"total":28458399,"total_time_in_millis":928283687},"flush":{"total":1366,"total_time_in_millis":216491},"warmer":{"current":0,"total":3402776,"total_time_in_millis":271116618},"query_cache":{"memory_size_in_bytes":1108608,"total_count":3973859534,"hit_count":477833739,"miss_count":3496025795,"cache_size":1196,"cache_count":13271,"evictions":12075},"fielddata":{"memory_size_in_bytes":14726948,"evictions":7326},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":81,"memory_in_bytes":38609375,"terms_memory_in_bytes":15605039,"stored_fields_memory_in_bytes":747552,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":96192,"doc_values_memory_in_bytes":22160592,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":2075208580,"version_map_memory_in_bytes":188,"fixed_bit_set_memory_in_bytes":648800},"translog":{"operations":334,"size_in_bytes":707565},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":161298}},"total":{"docs":{"count":4686385,"deleted":3051571},"store":{"size_in_bytes":11892413495,"throttle_time_in_millis":0},"indexing":{"index_total":8097472,"index_time_in_millis":21399014,"index_current":0,"index_failed":5914,"delete_total":1983684,"delete_time_in_millis":780344,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":96980641,"query_time_in_millis":179542865,"query_current":0,"fetch_total":15879937,"fetch_time_in_millis":2539973,"fetch_current":0,"scroll_total":95621022,"scroll_time_in_millis":2155451992,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":152845,"total_time_in_millis":64965436,"total_docs":98316849,"total_size_in_bytes":296511980135,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":1217223,"total_auto_throttle_in_bytes":295031156},"refresh":{"total":33886180,"total_time_in_millis":1060845135},"flush":{"total":1407,"total_time_in_millis":223134},"warmer":{"current":0,"total":4044483,"total_time_in_millis":322247961},"query_cache":{"memory_size_in_bytes":3216032,"total_count":5170871280,"hit_count":679142593,"miss_count":4491728687,"cache_size":3327,"cache_count":15752,"evictions":12425},"fielddata":{"memory_size_in_bytes":38580452,"evictions":24495},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":258,"memory_in_bytes":116507580,"terms_memory_in_bytes":47365568,"stored_fields_memory_in_bytes":2249320,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":304000,"doc_values_memory_in_bytes":66588692,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":6225625740,"version_map_memory_in_bytes":940,"fixed_bit_set_memory_in_bytes":1948288},"translog":{"operations":1126,"size_in_bytes":2482079},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":329427}}},"master-index-abae8b30ac9b11e692000401f8d88101":{"primaries":{"docs":{"count":828814318,"deleted":173988848},"store":{"size_in_bytes":865210001734,"throttle_time_in_millis":0},"indexing":{"index_total":6839260,"index_time_in_millis":39250331,"index_current":0,"index_failed":177240,"delete_total":1582868,"delete_time_in_millis":713680,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":12092590,"query_time_in_millis":85258432,"query_current":0,"fetch_total":958001,"fetch_time_in_millis":1850742,"fetch_current":0,"scroll_total":11847052,"scroll_time_in_millis":488454761,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":497724,"total_time_in_millis":149310812,"total_docs":585239288,"total_size_in_bytes":926062915967,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":26773794,"total_auto_throttle_in_bytes":26214400},"refresh":{"total":32813607,"total_time_in_millis":361217218},"flush":{"total":213,"total_time_in_millis":348775},"warmer":{"current":0,"total":9071581,"total_time_in_millis":12573348},"query_cache":{"memory_size_in_bytes":369597608,"total_count":308386639,"hit_count":43447337,"miss_count":264939302,"cache_size":1666,"cache_count":2233,"evictions":567},"fielddata":{"memory_size_in_bytes":11883673360,"evictions":12039},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":190,"memory_in_bytes":969951548,"terms_memory_in_bytes":879584140,"stored_fields_memory_in_bytes":76461824,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":1361536,"doc_values_memory_in_bytes":12544048,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":1453386464,"version_map_memory_in_bytes":21780,"fixed_bit_set_memory_in_bytes":651573896},"translog":{"operations":1136,"size_in_bytes":3430211},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":2,"current_as_target":0,"throttle_time_in_millis":22300271}},"total":{"docs":{"count":2154971538,"deleted":424369033},"store":{"size_in_bytes":2234293816275,"throttle_time_in_millis":0},"indexing":{"index_total":14921881,"index_time_in_millis":77544477,"index_current":0,"index_failed":567049,"delete_total":3452830,"delete_time_in_millis":1445350,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":26021952,"query_time_in_millis":217232000,"query_current":0,"fetch_total":2016008,"fetch_time_in_millis":4102942,"fetch_current":0,"scroll_total":25509650,"scroll_time_in_millis":1055633031,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":1041576,"total_time_in_millis":320025196,"total_docs":1251024664,"total_size_in_bytes":1973241524097,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":58886913,"total_auto_throttle_in_bytes":72697928},"refresh":{"total":71582565,"total_time_in_millis":716498732},"flush":{"total":467,"total_time_in_millis":779976},"warmer":{"current":0,"total":18890944,"total_time_in_millis":27317771},"query_cache":{"memory_size_in_bytes":1003925184,"total_count":666807549,"hit_count":91624491,"miss_count":575183058,"cache_size":3846,"cache_count":4700,"evictions":854},"fielddata":{"memory_size_in_bytes":24853282272,"evictions":31337},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":508,"memory_in_bytes":2494902332,"terms_memory_in_bytes":2261557516,"stored_fields_memory_in_bytes":196879224,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":3550592,"doc_values_memory_in_bytes":32915000,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":4725079897,"version_map_memory_in_bytes":68580,"fixed_bit_set_memory_in_bytes":1686894744},"translog":{"operations":3443,"size_in_bytes":10353321},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":2,"current_as_target":0,"throttle_time_in_millis":44530565}}},"master-index-cf5e90403d5e11e68ac00401f8d88501":{"primaries":{"docs":{"count":2908303,"deleted":1496253},"store":{"size_in_bytes":2904630328,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":455932,"query_time_in_millis":431479,"query_current":0,"fetch_total":131750,"fetch_time_in_millis":50979,"fetch_current":0,"scroll_total":266830,"scroll_time_in_millis":107036376,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":104857600},"refresh":{"total":1,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":15,"total_time_in_millis":142},"query_cache":{"memory_size_in_bytes":2341880,"total_count":13263261,"hit_count":2185214,"miss_count":11078047,"cache_size":1086,"cache_count":1189,"evictions":103},"fielddata":{"memory_size_in_bytes":5917852,"evictions":113},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":80,"memory_in_bytes":15907807,"terms_memory_in_bytes":13649071,"stored_fields_memory_in_bytes":460328,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":76224,"doc_values_memory_in_bytes":1722184,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":1928885862,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":1610720},"translog":{"operations":0,"size_in_bytes":215},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":182437}},"total":{"docs":{"count":8724909,"deleted":4488759},"store":{"size_in_bytes":8713890986,"throttle_time_in_millis":0},"indexing":{"index_total":10,"index_time_in_millis":84,"index_current":0,"index_failed":0,"delete_total":2,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":10352302,"query_time_in_millis":10745410,"query_current":0,"fetch_total":2796776,"fetch_time_in_millis":1087630,"fetch_current":0,"scroll_total":6980954,"scroll_time_in_millis":1259221859,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":314572800},"refresh":{"total":55,"total_time_in_millis":382},"flush":{"total":10,"total_time_in_millis":338},"warmer":{"current":0,"total":87,"total_time_in_millis":636},"query_cache":{"memory_size_in_bytes":7053128,"total_count":296751989,"hit_count":39601139,"miss_count":257150850,"cache_size":3242,"cache_count":6441,"evictions":3199},"fielddata":{"memory_size_in_bytes":40403564,"evictions":740},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":240,"memory_in_bytes":47723421,"terms_memory_in_bytes":40947213,"stored_fields_memory_in_bytes":1380984,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":228672,"doc_values_memory_in_bytes":5166552,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":4841110567,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":4832160},"translog":{"operations":0,"size_in_bytes":645},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":341173}}},"scroll":{"primaries":{"docs":{"count":0,"deleted":0},"store":{"size_in_bytes":795,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":6846283,"query_time_in_millis":345971,"query_current":0,"fetch_total":0,"fetch_time_in_millis":0,"fetch_current":0,"scroll_total":0,"scroll_time_in_millis":0,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":104857600},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":15,"total_time_in_millis":10},"query_cache":{"memory_size_in_bytes":0,"total_count":0,"hit_count":0,"miss_count":0,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":0,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":0,"memory_in_bytes":0,"terms_memory_in_bytes":0,"stored_fields_memory_in_bytes":0,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":0,"doc_values_memory_in_bytes":0,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":2560000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":0},"translog":{"operations":0,"size_in_bytes":215},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":0}},"total":{"docs":{"count":0,"deleted":0},"store":{"size_in_bytes":1590,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":7697517,"query_time_in_millis":393129,"query_current":0,"fetch_total":0,"fetch_time_in_millis":0,"fetch_current":0,"scroll_total":0,"scroll_time_in_millis":0,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":209715200},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":30,"total_time_in_millis":10},"query_cache":{"memory_size_in_bytes":0,"total_count":0,"hit_count":0,"miss_count":0,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":0,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":0,"memory_in_bytes":0,"terms_memory_in_bytes":0,"stored_fields_memory_in_bytes":0,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":0,"doc_values_memory_in_bytes":0,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":346460815,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":0},"translog":{"operations":0,"size_in_bytes":430},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":0}}},"staging-index-025e2270c5cd11e6b9610401f8d88501":{"primaries":{"docs":{"count":0,"deleted":0},"store":{"size_in_bytes":795,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":5982565,"query_time_in_millis":533834,"query_current":0,"fetch_total":0,"fetch_time_in_millis":0,"fetch_current":0,"scroll_total":4650238,"scroll_time_in_millis":611456690,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":104857600},"refresh":{"total":1,"total_time_in_millis":10},"flush":{"total":1,"total_time_in_millis":0},"warmer":{"current":0,"total":15,"total_time_in_millis":0},"query_cache":{"memory_size_in_bytes":0,"total_count":0,"hit_count":0,"miss_count":0,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":0,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":0,"memory_in_bytes":0,"terms_memory_in_bytes":0,"stored_fields_memory_in_bytes":0,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":0,"doc_values_memory_in_bytes":0,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":2560000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":0},"translog":{"operations":0,"size_in_bytes":215},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":0}},"total":{"docs":{"count":0,"deleted":0},"store":{"size_in_bytes":2385,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":10595865,"query_time_in_millis":1051835,"query_current":0,"fetch_total":0,"fetch_time_in_millis":0,"fetch_current":0,"scroll_total":8299033,"scroll_time_in_millis":1092148539,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":314572800},"refresh":{"total":2,"total_time_in_millis":14},"flush":{"total":2,"total_time_in_millis":1},"warmer":{"current":0,"total":46,"total_time_in_millis":0},"query_cache":{"memory_size_in_bytes":0,"total_count":0,"hit_count":0,"miss_count":0,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":0,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":0,"memory_in_bytes":0,"terms_memory_in_bytes":0,"stored_fields_memory_in_bytes":0,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":0,"doc_values_memory_in_bytes":0,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":678152601,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":0},"translog":{"operations":0,"size_in_bytes":645},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":0}}},"master-index-3366bf206f2a11e694f80401f8d88c01":{"primaries":{"docs":{"count":429979,"deleted":302380},"store":{"size_in_bytes":390170878,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":113723,"query_time_in_millis":235613,"query_current":0,"fetch_total":64561,"fetch_time_in_millis":67619,"fetch_current":0,"scroll_total":65611,"scroll_time_in_millis":29666772,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":20971520},"refresh":{"total":2,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":3,"total_time_in_millis":12},"query_cache":{"memory_size_in_bytes":342504,"total_count":4017270,"hit_count":496723,"miss_count":3520547,"cache_size":162,"cache_count":191,"evictions":29},"fielddata":{"memory_size_in_bytes":1478904,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":19,"memory_in_bytes":2482181,"terms_memory_in_bytes":2095945,"stored_fields_memory_in_bytes":89824,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":15616,"doc_values_memory_in_bytes":280796,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":512000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":92408},"translog":{"operations":0,"size_in_bytes":43},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":11280}},"total":{"docs":{"count":1289937,"deleted":907140},"store":{"size_in_bytes":1170512634,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":133848,"query_time_in_millis":248355,"query_current":0,"fetch_total":75770,"fetch_time_in_millis":71373,"fetch_current":0,"scroll_total":76942,"scroll_time_in_millis":32886715,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":62914560},"refresh":{"total":2,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":9,"total_time_in_millis":29},"query_cache":{"memory_size_in_bytes":1245904,"total_count":4743244,"hit_count":579963,"miss_count":4163281,"cache_size":459,"cache_count":488,"evictions":29},"fielddata":{"memory_size_in_bytes":2959280,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":57,"memory_in_bytes":7446543,"terms_memory_in_bytes":6287835,"stored_fields_memory_in_bytes":269472,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":46848,"doc_values_memory_in_bytes":842388,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":1074253824,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":277224},"translog":{"operations":0,"size_in_bytes":129},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":57027}}},"master-index-e4010da4110ba377d100f050cb4440db":{"primaries":{"docs":{"count":156624,"deleted":55458},"store":{"size_in_bytes":240242214,"throttle_time_in_millis":0},"indexing":{"index_total":119444,"index_time_in_millis":634827,"index_current":0,"index_failed":0,"delete_total":126,"delete_time_in_millis":29,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":5487107,"query_time_in_millis":4754212,"query_current":0,"fetch_total":1506638,"fetch_time_in_millis":447347,"fetch_current":0,"scroll_total":3717777,"scroll_time_in_millis":656940091,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":6547,"total_time_in_millis":2468290,"total_docs":9933606,"total_size_in_bytes":12796136703,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":104857600},"refresh":{"total":210941,"total_time_in_millis":3240349},"flush":{"total":54,"total_time_in_millis":2082},"warmer":{"current":0,"total":114865,"total_time_in_millis":306963},"query_cache":{"memory_size_in_bytes":138736,"total_count":82567987,"hit_count":13348434,"miss_count":69219553,"cache_size":527,"cache_count":27651,"evictions":27124},"fielddata":{"memory_size_in_bytes":1604320,"evictions":214},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":36,"memory_in_bytes":3965197,"terms_memory_in_bytes":3214429,"stored_fields_memory_in_bytes":58784,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":51584,"doc_values_memory_in_bytes":640400,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":530593928,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":102416},"translog":{"operations":0,"size_in_bytes":215},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":17266}},"total":{"docs":{"count":469872,"deleted":166119},"store":{"size_in_bytes":720178849,"throttle_time_in_millis":0},"indexing":{"index_total":238815,"index_time_in_millis":1139593,"index_current":0,"index_failed":78,"delete_total":252,"delete_time_in_millis":59,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":14906522,"query_time_in_millis":11101782,"query_current":0,"fetch_total":3953849,"fetch_time_in_millis":1222396,"fetch_current":0,"scroll_total":9933943,"scroll_time_in_millis":1795973426,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":12604,"total_time_in_millis":4383397,"total_docs":21358375,"total_size_in_bytes":26609870545,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":314572800},"refresh":{"total":422076,"total_time_in_millis":5648820},"flush":{"total":110,"total_time_in_millis":3568},"warmer":{"current":0,"total":221614,"total_time_in_millis":530336},"query_cache":{"memory_size_in_bytes":428800,"total_count":198912122,"hit_count":41684306,"miss_count":157227816,"cache_size":1519,"cache_count":57532,"evictions":56013},"fielddata":{"memory_size_in_bytes":4743280,"evictions":310},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":108,"memory_in_bytes":11869879,"terms_memory_in_bytes":9622247,"stored_fields_memory_in_bytes":176464,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":153280,"doc_values_memory_in_bytes":1917888,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":1673175312,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":307168},"translog":{"operations":0,"size_in_bytes":645},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":32345}}},"staging-index-cf7388b0542411e68c440401f8d88501":{"primaries":{"docs":{"count":456,"deleted":0},"store":{"size_in_bytes":2666826,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":167264,"query_time_in_millis":49024,"query_current":0,"fetch_total":25,"fetch_time_in_millis":9,"fetch_current":0,"scroll_total":137578,"scroll_time_in_millis":10986805,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":20971520},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":3,"total_time_in_millis":3},"query_cache":{"memory_size_in_bytes":0,"total_count":4921385,"hit_count":0,"miss_count":4921385,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":3208,"evictions":2},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":1,"memory_in_bytes":795959,"terms_memory_in_bytes":778011,"stored_fields_memory_in_bytes":656,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":64,"doc_values_memory_in_bytes":17228,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":512000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":104},"translog":{"operations":0,"size_in_bytes":43},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":43}},"total":{"docs":{"count":1368,"deleted":0},"store":{"size_in_bytes":8000478,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":497134,"query_time_in_millis":119304,"query_current":0,"fetch_total":83,"fetch_time_in_millis":30,"fetch_current":0,"scroll_total":401091,"scroll_time_in_millis":34167067,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":62914560},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":9,"total_time_in_millis":5},"query_cache":{"memory_size_in_bytes":0,"total_count":14214653,"hit_count":0,"miss_count":14214653,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":9624,"evictions":485},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":3,"memory_in_bytes":2387877,"terms_memory_in_bytes":2334033,"stored_fields_memory_in_bytes":1968,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":192,"doc_values_memory_in_bytes":51684,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":1536000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":312},"translog":{"operations":0,"size_in_bytes":129},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":43}}},"staging-index-3fa847206b9911e6b61d0401f8d88101":{"primaries":{"docs":{"count":2,"deleted":0},"store":{"size_in_bytes":18437,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":168430,"query_time_in_millis":28735,"query_current":0,"fetch_total":22,"fetch_time_in_millis":1,"fetch_current":0,"scroll_total":138757,"scroll_time_in_millis":11328217,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":20971520},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":3,"total_time_in_millis":0},"query_cache":{"memory_size_in_bytes":0,"total_count":4837386,"hit_count":0,"miss_count":4837386,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":884,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":1,"memory_in_bytes":12620,"terms_memory_in_bytes":11696,"stored_fields_memory_in_bytes":312,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":64,"doc_values_memory_in_bytes":548,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":512000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":0},"translog":{"operations":0,"size_in_bytes":43},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":0}},"total":{"docs":{"count":6,"deleted":0},"store":{"size_in_bytes":55313,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":210478,"query_time_in_millis":35793,"query_current":0,"fetch_total":33,"fetch_time_in_millis":1,"fetch_current":0,"scroll_total":172010,"scroll_time_in_millis":13945656,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":62914560},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":9,"total_time_in_millis":0},"query_cache":{"memory_size_in_bytes":0,"total_count":6024644,"hit_count":0,"miss_count":6024644,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":2652,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":3,"memory_in_bytes":37860,"terms_memory_in_bytes":35088,"stored_fields_memory_in_bytes":936,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":192,"doc_values_memory_in_bytes":1644,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":1536000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":0},"translog":{"operations":0,"size_in_bytes":129},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":0}}},"master-index-f1e6b200c8e611e6aae30401f8d88101":{"primaries":{"docs":{"count":1,"deleted":0},"store":{"size_in_bytes":11330,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":796906,"query_time_in_millis":56206,"query_current":0,"fetch_total":0,"fetch_time_in_millis":0,"fetch_current":0,"scroll_total":557,"scroll_time_in_millis":3873,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":104857600},"refresh":{"total":2,"total_time_in_millis":6},"flush":{"total":1,"total_time_in_millis":8},"warmer":{"current":0,"total":15,"total_time_in_millis":4},"query_cache":{"memory_size_in_bytes":0,"total_count":89868,"hit_count":0,"miss_count":89868,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":284,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":1,"memory_in_bytes":5834,"terms_memory_in_bytes":5366,"stored_fields_memory_in_bytes":312,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":64,"doc_values_memory_in_bytes":92,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":2560000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":48},"translog":{"operations":0,"size_in_bytes":215},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":0}},"total":{"docs":{"count":3,"deleted":0},"store":{"size_in_bytes":33990,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":1657089,"query_time_in_millis":120657,"query_current":0,"fetch_total":3,"fetch_time_in_millis":0,"fetch_current":0,"scroll_total":1356,"scroll_time_in_millis":8941,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":314572800},"refresh":{"total":4,"total_time_in_millis":10},"flush":{"total":2,"total_time_in_millis":9},"warmer":{"current":0,"total":46,"total_time_in_millis":5},"query_cache":{"memory_size_in_bytes":0,"total_count":281647,"hit_count":0,"miss_count":281647,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":852,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":3,"memory_in_bytes":17502,"terms_memory_in_bytes":16098,"stored_fields_memory_in_bytes":936,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":192,"doc_values_memory_in_bytes":276,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":7680000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":144},"translog":{"operations":0,"size_in_bytes":645},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":0}}},"staging-index-e4010da4110ba377d100f050cb4440db":{"primaries":{"docs":{"count":33737,"deleted":4082},"store":{"size_in_bytes":131905968,"throttle_time_in_millis":0},"indexing":{"index_total":3,"index_time_in_millis":302,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":12792622,"query_time_in_millis":31496839,"query_current":0,"fetch_total":2441,"fetch_time_in_millis":3479,"fetch_current":0,"scroll_total":9746844,"scroll_time_in_millis":1378468667,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":104857600},"refresh":{"total":4,"total_time_in_millis":238},"flush":{"total":2,"total_time_in_millis":61},"warmer":{"current":0,"total":19,"total_time_in_millis":120},"query_cache":{"memory_size_in_bytes":0,"total_count":1892816387,"hit_count":0,"miss_count":1892816387,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":181788,"evictions":90},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":22,"memory_in_bytes":10844893,"terms_memory_in_bytes":9153973,"stored_fields_memory_in_bytes":43216,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":6656,"doc_values_memory_in_bytes":1641048,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":2560000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":7208},"translog":{"operations":0,"size_in_bytes":215},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":3646}},"total":{"docs":{"count":101211,"deleted":12124},"store":{"size_in_bytes":395415721,"throttle_time_in_millis":0},"indexing":{"index_total":5,"index_time_in_millis":314,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":20551873,"query_time_in_millis":50047059,"query_current":0,"fetch_total":3900,"fetch_time_in_millis":3929,"fetch_current":0,"scroll_total":15739263,"scroll_time_in_millis":2161507369,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":314572800},"refresh":{"total":8,"total_time_in_millis":295},"flush":{"total":4,"total_time_in_millis":102},"warmer":{"current":0,"total":54,"total_time_in_millis":358},"query_cache":{"memory_size_in_bytes":0,"total_count":3347132656,"hit_count":0,"miss_count":3347132656,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":536212,"evictions":1118},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":66,"memory_in_bytes":32568634,"terms_memory_in_bytes":27526218,"stored_fields_memory_in_bytes":129312,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":19968,"doc_values_memory_in_bytes":4893136,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":576410692,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":21600},"translog":{"operations":0,"size_in_bytes":645},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":14251}}},"staging-index-d3ae95b0d12811e69edf0401f8d88501":{"primaries":{"docs":{"count":39,"deleted":0},"store":{"size_in_bytes":211293,"throttle_time_in_millis":0},"indexing":{"index_total":5,"index_time_in_millis":76,"index_current":0,"index_failed":0,"delete_total":4,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":1626936,"query_time_in_millis":209943,"query_current":0,"fetch_total":32,"fetch_time_in_millis":7,"fetch_current":0,"scroll_total":1150896,"scroll_time_in_millis":117606132,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":104857600},"refresh":{"total":74,"total_time_in_millis":122},"flush":{"total":4,"total_time_in_millis":175},"warmer":{"current":0,"total":35,"total_time_in_millis":8},"query_cache":{"memory_size_in_bytes":0,"total_count":8094797,"hit_count":0,"miss_count":8094797,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":3072,"evictions":31},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":3,"memory_in_bytes":134751,"terms_memory_in_bytes":131827,"stored_fields_memory_in_bytes":936,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":192,"doc_values_memory_in_bytes":1796,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":2560000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":144},"translog":{"operations":0,"size_in_bytes":215},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":0}},"total":{"docs":{"count":117,"deleted":0},"store":{"size_in_bytes":633879,"throttle_time_in_millis":0},"indexing":{"index_total":17,"index_time_in_millis":321,"index_current":0,"index_failed":0,"delete_total":13,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":4534106,"query_time_in_millis":605378,"query_current":0,"fetch_total":119,"fetch_time_in_millis":51,"fetch_current":0,"scroll_total":3324956,"scroll_time_in_millis":322547126,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":314572800},"refresh":{"total":241,"total_time_in_millis":590},"flush":{"total":13,"total_time_in_millis":720},"warmer":{"current":0,"total":115,"total_time_in_millis":31},"query_cache":{"memory_size_in_bytes":0,"total_count":27925253,"hit_count":0,"miss_count":27925253,"cache_size":0,"cache_count":0,"evictions":0},"fielddata":{"memory_size_in_bytes":9216,"evictions":519},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":9,"memory_in_bytes":404253,"terms_memory_in_bytes":395481,"stored_fields_memory_in_bytes":2808,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":576,"doc_values_memory_in_bytes":5388,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":7680000,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":432},"translog":{"operations":0,"size_in_bytes":645},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":0}}},"master-index-8cd6e43115e9416eb23609486fa053e3":{"primaries":{"docs":{"count":21499468,"deleted":145868},"store":{"size_in_bytes":19614353935,"throttle_time_in_millis":0},"indexing":{"index_total":1435097,"index_time_in_millis":7188744,"index_current":0,"index_failed":0,"delete_total":352815,"delete_time_in_millis":162353,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":5311320,"query_time_in_millis":11810321,"query_current":0,"fetch_total":1243270,"fetch_time_in_millis":1862567,"fetch_current":0,"scroll_total":4742327,"scroll_time_in_millis":485592444,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":88829,"total_time_in_millis":22399303,"total_docs":113758583,"total_size_in_bytes":153478021174,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":1158650,"total_auto_throttle_in_bytes":89128960},"refresh":{"total":8229691,"total_time_in_millis":48323290},"flush":{"total":111,"total_time_in_millis":15311},"warmer":{"current":0,"total":1518189,"total_time_in_millis":2771979},"query_cache":{"memory_size_in_bytes":7136216,"total_count":133331794,"hit_count":21637966,"miss_count":111693828,"cache_size":1747,"cache_count":5740,"evictions":3993},"fielddata":{"memory_size_in_bytes":201007428,"evictions":1942},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":143,"memory_in_bytes":63009012,"terms_memory_in_bytes":57362016,"stored_fields_memory_in_bytes":3398352,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":368576,"doc_values_memory_in_bytes":1880068,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":1880190483,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":10842640},"translog":{"operations":561,"size_in_bytes":654689},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":378546}},"total":{"docs":{"count":64498404,"deleted":448155},"store":{"size_in_bytes":58871846337,"throttle_time_in_millis":0},"indexing":{"index_total":2876053,"index_time_in_millis":16188428,"index_current":0,"index_failed":0,"delete_total":705126,"delete_time_in_millis":386362,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":19046563,"query_time_in_millis":29880274,"query_current":0,"fetch_total":5500157,"fetch_time_in_millis":5001742,"fetch_current":0,"scroll_total":16763922,"scroll_time_in_millis":1364913364,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":170229,"total_time_in_millis":49329172,"total_docs":211377341,"total_size_in_bytes":289736382185,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":2041804,"total_auto_throttle_in_bytes":283115520},"refresh":{"total":16506794,"total_time_in_millis":101911492},"flush":{"total":341,"total_time_in_millis":39216},"warmer":{"current":0,"total":2806788,"total_time_in_millis":5731272},"query_cache":{"memory_size_in_bytes":20208504,"total_count":355398686,"hit_count":45308402,"miss_count":310090284,"cache_size":4912,"cache_count":12504,"evictions":7592},"fielddata":{"memory_size_in_bytes":592341824,"evictions":5274},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":427,"memory_in_bytes":188941486,"terms_memory_in_bytes":171943770,"stored_fields_memory_in_bytes":10197376,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":1109056,"doc_values_memory_in_bytes":5691284,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":6225625740,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":32533216},"translog":{"operations":1683,"size_in_bytes":1964067},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":1052601}}},"master-index-839920f07e6b11e6b71d0401f8d88101":{"primaries":{"docs":{"count":3799561,"deleted":744330},"store":{"size_in_bytes":6791411551,"throttle_time_in_millis":0},"indexing":{"index_total":0,"index_time_in_millis":0,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":10116,"query_time_in_millis":13228,"query_current":0,"fetch_total":5542,"fetch_time_in_millis":593,"fetch_current":0,"scroll_total":5581,"scroll_time_in_millis":1686210,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":20971520},"refresh":{"total":0,"total_time_in_millis":0},"flush":{"total":0,"total_time_in_millis":0},"warmer":{"current":0,"total":3,"total_time_in_millis":175},"query_cache":{"memory_size_in_bytes":1281520,"total_count":412304,"hit_count":21437,"miss_count":390867,"cache_size":78,"cache_count":78,"evictions":0},"fielddata":{"memory_size_in_bytes":103199468,"evictions":0},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":22,"memory_in_bytes":15451932,"terms_memory_in_bytes":13875356,"stored_fields_memory_in_bytes":857192,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":76224,"doc_values_memory_in_bytes":643160,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":536870912,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":1690040},"translog":{"operations":0,"size_in_bytes":43},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":284907}},"total":{"docs":{"count":11398683,"deleted":2232990},"store":{"size_in_bytes":20374234653,"throttle_time_in_millis":0},"indexing":{"index_total":5,"index_time_in_millis":9,"index_current":0,"index_failed":0,"delete_total":0,"delete_time_in_millis":0,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":115035,"query_time_in_millis":734408,"query_current":0,"fetch_total":67779,"fetch_time_in_millis":25882,"fetch_current":0,"scroll_total":67888,"scroll_time_in_millis":25650899,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":0,"total_time_in_millis":0,"total_docs":0,"total_size_in_bytes":0,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":0,"total_auto_throttle_in_bytes":62914560},"refresh":{"total":12,"total_time_in_millis":74},"flush":{"total":2,"total_time_in_millis":31},"warmer":{"current":0,"total":23,"total_time_in_millis":562},"query_cache":{"memory_size_in_bytes":4272144,"total_count":4535815,"hit_count":260958,"miss_count":4274857,"cache_size":246,"cache_count":334,"evictions":88},"fielddata":{"memory_size_in_bytes":310106728,"evictions":1481},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":66,"memory_in_bytes":46355796,"terms_memory_in_bytes":41626068,"stored_fields_memory_in_bytes":2571576,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":228672,"doc_values_memory_in_bytes":1929480,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":1074253824,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":5070120},"translog":{"operations":0,"size_in_bytes":129},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":679582}}},"master-index-b74f5a703d5e11e68ac00401f8d88501":{"primaries":{"docs":{"count":2258375,"deleted":603224},"store":{"size_in_bytes":1614755018,"throttle_time_in_millis":0},"indexing":{"index_total":44638,"index_time_in_millis":508463,"index_current":0,"index_failed":3,"delete_total":753,"delete_time_in_millis":229,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":5198037,"query_time_in_millis":7397850,"query_current":0,"fetch_total":1363938,"fetch_time_in_millis":321463,"fetch_current":0,"scroll_total":3567887,"scroll_time_in_millis":605125271,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":3438,"total_time_in_millis":1477989,"total_docs":5507482,"total_size_in_bytes":6568470775,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":623,"total_auto_throttle_in_bytes":101217914},"refresh":{"total":221443,"total_time_in_millis":4035318},"flush":{"total":32,"total_time_in_millis":1266},"warmer":{"current":0,"total":59630,"total_time_in_millis":104320},"query_cache":{"memory_size_in_bytes":1440320,"total_count":124559593,"hit_count":14977749,"miss_count":109581844,"cache_size":1051,"cache_count":3951,"evictions":2900},"fielddata":{"memory_size_in_bytes":9303960,"evictions":48},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":83,"memory_in_bytes":14227224,"terms_memory_in_bytes":12199052,"stored_fields_memory_in_bytes":218768,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":242048,"doc_values_memory_in_bytes":1567356,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":343900815,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":1064096},"translog":{"operations":0,"size_in_bytes":215},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":63595}},"total":{"docs":{"count":6775125,"deleted":1928982},"store":{"size_in_bytes":4884244385,"throttle_time_in_millis":0},"indexing":{"index_total":90359,"index_time_in_millis":825119,"index_current":0,"index_failed":3,"delete_total":1451,"delete_time_in_millis":292,"delete_current":0,"noop_update_total":0,"is_throttled":false,"throttle_time_in_millis":0},"get":{"total":0,"time_in_millis":0,"exists_total":0,"exists_time_in_millis":0,"missing_total":0,"missing_time_in_millis":0,"current":0},"search":{"open_contexts":0,"query_total":11427255,"query_time_in_millis":14536639,"query_current":0,"fetch_total":2921285,"fetch_time_in_millis":556590,"fetch_current":0,"scroll_total":7638287,"scroll_time_in_millis":1504945921,"scroll_current":0},"merges":{"current":0,"current_docs":0,"current_size_in_bytes":0,"total":6948,"total_time_in_millis":2627261,"total_docs":10533156,"total_size_in_bytes":12975152937,"total_stopped_time_in_millis":0,"total_throttled_time_in_millis":909,"total_auto_throttle_in_bytes":307293428},"refresh":{"total":442502,"total_time_in_millis":6730065},"flush":{"total":68,"total_time_in_millis":2159},"warmer":{"current":0,"total":122394,"total_time_in_millis":175773},"query_cache":{"memory_size_in_bytes":4252336,"total_count":271536151,"hit_count":32936892,"miss_count":238599259,"cache_size":3173,"cache_count":10348,"evictions":7175},"fielddata":{"memory_size_in_bytes":22792140,"evictions":1052},"percolate":{"total":0,"time_in_millis":0,"current":0,"memory_size_in_bytes":-1,"memory_size":"-1b","queries":0},"completion":{"size_in_bytes":0},"segments":{"count":248,"memory_in_bytes":43543486,"terms_memory_in_bytes":37349626,"stored_fields_memory_in_bytes":659080,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":742144,"doc_values_memory_in_bytes":4792636,"index_writer_memory_in_bytes":0,"index_writer_max_memory_in_bytes":2282788398,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":3228720},"translog":{"operations":0,"size_in_bytes":645},"suggest":{"total":0,"time_in_millis":0,"current":0},"request_cache":{"memory_size_in_bytes":0,"evictions":0,"hit_count":0,"miss_count":0},"recovery":{"current_as_source":0,"current_as_target":0,"throttle_time_in_millis":202143}}}}}root@prod-es-25:~#
#+END_EXAMPLE
** TODO For DB engine upgrade: POC for couchbase and elasticsearch
** TODO elasticsearch cancel snapshot
** TODO How to safely restart an elasticsearch instance within ES cluster
http://stackoverflow.com/questions/22978812/elastic-search-correct-way-to-restart-a-cluster-without-unassigned-shards-issue
https://www.elastic.co/guide/en/elasticsearch/reference/current/restart-upgrade.html

This works by:

Disabling shard allocation
Restarting one node (cluster goes yellow)
Wait until it rejoins the cluster
Re-enable shard allocation
Wait until shards are reallocated (cluster goes green)
Repeat on other nodes.
** TODO Run Chef deployment and restart ES cluster node-by-node
** TODO ES share relocation time interval
** TODO ES Cluster Reroute: https://www.elastic.co/guide/en/elasticsearch/reference/2.3/cluster-reroute.html#cluster-reroute
** TODO improve querycluster to detect elasticsearch.yml out-of-sync issue
Kung Wang [12:47 PM]
since you have nice clusterquery, when we have it integrated with elasticsearch.yml change, this doubt should be gone
** TODO elasticsearch link: https://thoughts.t37.net/designing-the-perfect-elasticsearch-cluster-the-almost-definitive-guide-e614eabc1a87
** TODO elasticsearch: http.max_content_length: 100mb
https://dongbo0737.github.io/2017/06/06/elasticsearch-config/
** TODO [#A] Understand ES cluster health why turns into yellow quite suddenly
http://bematech-do-jenkins.carol.ai:18080/job/RunCommandOnServers/98/console
*** es-8
#+BEGIN_EXAMPLE
RecoverFilesRecoveryException[Failed to transfer [0] files with total size of [0b]]; nested: IllegalStateException[try to recover [staging-index-8a18aa800e5911e785f24a8136534b63][9] from primary shard with sync id but number of docs differ: 1218964 (bematech-do-es-13.localdomain, primary) vs 1219061(bematech-do-es-08.localdomain)];
Caused by: [staging-index-8a18aa800e5911e785f24a8136534b63][[staging-index-8a18aa800e5911e785f24a8136534b63][9]] RecoveryEngineException[Phase[1] phase1 failed]; nested: RecoverFilesRecoveryException[Failed to transfer [0] files with total size of [0b]]; nested: IllegalStateException[try to recover [staging-index-8a18aa800e5911e785f24a8136534b63][9] from primary shard with sync id but number of docs differ: 1218964 (bematech-do-es-13.localdomain, primary) vs 1219061(bematech-do-es-08.localdomain)];
        at org.elasticsearch.indices.recovery.RecoverySourceHandler.recoverToTarget(RecoverySourceHandler.java:135)
        at org.elasticsearch.indices.recovery.RecoverySource.recover(RecoverySource.java:126)
        at org.elasticsearch.indices.recovery.RecoverySource.access$200(RecoverySource.java:52)
        at org.elasticsearch.indices.recovery.RecoverySource$StartRecoveryTransportRequestHandler.messageReceived(RecoverySource.java:135)
        at org.elasticsearch.indices.recovery.RecoverySource$StartRecoveryTransportRequestHandler.messageReceived(RecoverySource.java:132)
        at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
        at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:75)
        at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:300)
        at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: [staging-index-8a18aa800e5911e785f24a8136534b63][[staging-index-8a18aa800e5911e785f24a8136534b63][9]] RecoverFilesRecoveryException[Failed to transfer [0] files with total size of [0b]]; nested: IllegalStateException[try to recover [staging-index-8a18aa800e5911e785f24a8136534b63][9] from primary shard with sync id but number of docs differ: 1218964 (bematech-do-es-13.localdomain, primary) vs 1219061(bematech-do-es-08.localdomain)];
        at org.elasticsearch.indices.recovery.RecoverySourceHandler.phase1(RecoverySourceHandler.java:453)
        at org.elasticsearch.indices.recovery.RecoverySourceHandler.recoverToTarget(RecoverySourceHandler.java:133)
        ... 11 more
Caused by: java.lang.IllegalStateException: try to recover [staging-index-8a18aa800e5911e785f24a8136534b63][9] from primary shard with sync id but number of docs differ: 1218964 (bematech-do-es-13.localdomain, primary) vs 1219061(bematech-do-es-08.localdomain)
        at org.elasticsearch.indices.recovery.RecoverySourceHandler.phase1(RecoverySourceHandler.java:197)
        ... 12 more
[2017-08-19 04:03:00,900][INFO ][monitor.jvm              ] [bematech-do-es-08.localdomain] [gc][young][520275][450905] duration [1.4s], collections [2]/[1.9s], total [1.4s]/[7.6h], memory [8.4gb]->[7.8gb]/[11.9gb], all_pools {[young] [664.8mb]->[88.2kb]/[665.6mb]}{[survivor] [57.1mb]->[37.2mb]/[83.1mb]}{[old] [7.7gb]->[7.7gb]/[11.1gb]}

#+END_EXAMPLE
*** es-19

#+BEGIN_EXAMPLE
[2017-08-19 03:40:59,065][DEBUG][action.bulk              ] [bematech-do-es-19.localdomain] failed to execute [BulkShardRequest to [staging-index-abae8b30ac9b11e692000401f8d88101-new3] containing [21] requests] on [[staging-index-abae8b30ac9b11e692000401f8d88101-new3][0]]
[staging-index-abae8b30ac9b11e692000401f8d88101-new3][[staging-index-abae8b30ac9b11e692000401f8d88101-new3][0]] IllegalIndexShardStateException[CurrentState[STARTED] shard is not a primary]
        at org.elasticsearch.index.shard.IndexShard.prepareIndexOnPrimary(IndexShard.java:557)
        at org.elasticsearch.action.index.TransportIndexAction.prepareIndexOperationOnPrimary(TransportIndexAction.java:212)
        at org.elasticsearch.action.index.TransportIndexAction.executeIndexRequestOnPrimary(TransportIndexAction.java:224)
        at org.elasticsearch.action.bulk.TransportShardBulkAction.shardIndexOperation(TransportShardBulkAction.java:326)
        at org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:119)
        at org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:68)
        at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.doRun(TransportReplicationAction.java:639)
        at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
        at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:279)
        at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:271)
        at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:75)
        at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:376)
        at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
[2017-08-19 03:40:59,627][DEBUG][action.admin.indices.stats] [bematech-do-es-19.localdomain] failed to execute [indices:monitor/stats] on node [Sge-vtuNTQOcXdKoh1MeTw]
NodeDisconnectedException[[bematech-do-es-08.localdomain][138.68.30.61:9300][indices:monitor/stats[n]] disconnected]
[2017-08-19 03:41:57,832][INFO ][cluster.service          ] [bematech-do-es-19.localdomain] added {{bematech-do-es-08.localdomain}{Sge-vtuNTQOcXdKoh1MeTw}{138.68.30.61}{138.68.30.61:9300}{max_local_storage_nodes=1},}, reason: zen-disco-receive(from master [{bematech-do-es-01.localdomain}{-WUom2x0Tfaz9odSy-q14g}{138.197.215.132}{138.197.215.132:9300}{max_local_storage_nodes=1}])
#+END_EXAMPLE
** TODO monitor Elasticsearch GC events
** HALF elasticsearch heap size
Bruno Volpato [5:52 PM]
https://www.elastic.co/guide/en/elasticsearch/guide/current/heap-sizing.html
The standard recommendation is to give 50% of the available memory to Elasticsearch heap, while leaving the other 50% free. It won't go unused; Lucene will happily gobble up whatever is left over.
** TODO [#A] Indexing performance degrading over time              :IMPORTANT:
https://discuss.elastic.co/t/indexing-performance-degrading-over-time/40229
** TODO [#A] elasticsearch: Java How to reduce full java gc        :IMPORTANT:
https://stackoverflow.com/questions/5092134/whats-the-difference-between-generational-and-incremental-garbage-collection

#+BEGIN_EXAMPLE
Bruno Volpato
[12:03 AM]
Full GC avg time 23 seconds


Bruno Volpato
[12:03 AM]
uploaded this image: Pasted image at 2017-08-20, 10:03 PM
Add Comment



Bruno Volpato
[12:03 AM]
will start the other workers and see how it goes


Denny Zhang
[12:05 AM]
What we can tell from this 4 full gc? (edited)


Bruno Volpato
[12:06 AM]
http://gceasy.io/my-gc-report.jsp?p=c2hhcmVkLzIwMTcvMDgvMjEvLS1nYy5sb2ctLTUtMC0yOA==


[12:07]
5.36tb were allocated, but 27gb of RAM was able to get promoted to the old generation space


[12:07]
but when GC runs, it reclaims all of them


[12:07]
so it means that the data is not there forever, but long enough to make it ti the old.


new messages
[12:09]
I would suggest to increase young generation space
#+END_EXAMPLE
** TODO elasticsearch disk issue: 15% available disk is not good enough
denny zhang [9:10 PM]
One interesting observation.

Minutes ago, 23.239.4.174(es04) only has 4% available disk. Now it has 15%+ available disk.

This indicates out of disk issue might happen suddenly in ES nodes.
15% free disk is not safe enough

45.33.43.184/check_disk_rootfs is CRITICAL:
DISK CRITICAL used :  / 1.69% free

denny zhang [9:48 PM]
Very critical low disk for es06(45.33.43.184)

[9:50]
Just checked, it has 15% free disk. 5 Minutes ago, we only have 1.69% free disk

Copy @bruno & @kungwang


Nagios BOT [9:51 PM]
45.33.43.184/check_disk_rootfs is WARNING:
DISK WARNING used :  / 14.88% free

denny zhang [9:52 PM]
Looks like the data rebalance is taking lots of disk for intermediate actions.

So even with 15% free disk, we're not safe enough.

Maybe we should cut the index into even smaller shards.


Nagios BOT [10:22 PM]
173.255.243.91/check_disk_rootfs is WARNING:
DISK WARNING used :  / 7.37% free

denny zhang [10:26 PM]
Recently we've got lots of low disk warnings for ES nodes in explore env, and low memory warnings for CB nodes in prod env.

Any improvements we can make in application design, to save resource? Otherwise, we might need to add more nodes very soon. (edited)


Nagios BOT [10:27 PM]
173.255.243.91/check_disk_rootfs is CRITICAL:
DISK CRITICAL used :  / 2.71% free

[10:28]
173.230.152.155/check_disk_rootfs is WARNING:
DISK WARNING used :  / 14.66% free

denny zhang [10:30 PM]
OK, 2.71% free disk for es01(173.255.243.91).

I'd like to add one more ES node tomorrow morning, before we can make any other improvement including application code. Sounds good?
** TODO elasticsearch status yellow initializing_shards
** TODO Scale ES cluster: https://www.slideshare.net/kucrafal/scaling-massive-elastic-search-clusters-rafa-ku-sematext
** TODO [#A] elasticsearch monitoring performance
curl -s 'http://107.170.212.76:9200/_search' --data '{"query":{"match_all":{}},"aggs":{"entityTypes":{"terms":{"field":"mdmApplicationId"}}}}' | jq '.took'

root@prod-es-2:~# curl -s 'http://107.170.212.76:9200/_search' --data '{"query":{"match_all":{}},"aggs":{"entityTypes":{"terms":{"field":"mdmApplicationId"}}}}' | jq '.took'
8276


Maybe we can also enforce nagios check for elasticsearch slow query.

What do you think, Bruno?

Bruno Volpato [9:17 AM]
it can vary depending on the environment

[9:17]
and depend on the place that data is

[9:17]
in this case, it's because there's a lot of data in this tenant, in the staging area

[9:17]
once it gets processed, this query will be faster for sure

[9:17]
so it's a good indicator for now, but not in a long-term

denny zhang [9:19 AM]
Like NASDAQ Composite, we choose a small set of data.

Then call search API, if some takes too long(say 5 seconds), send out alerts.

Would this be helpful and for general purpose?

Bruno Volpato [9:20 AM]
yes

denny zhang [9:21 AM]
We want to be better on top of this kind of issue.

Any suggestion to make the testcase more reasonable?

Bruno Volpato [9:21 AM]
but the query needs to be random (edited)

[9:21]
otherwise, Elasticsearch will optimize for your query

denny zhang [9:22 AM]
yes, make sense

Bruno Volpato [9:22 AM]
they move things around depending on the queries, just like a hybrid hard-drive

denny zhang [9:22 AM]
Do you know how we can get a random set of ES data?

[9:22]
Then we search them one by one.


denny zhang [9:22 AM]
Do you know how we can get a random set of ES data?

[9:22]
Then we search them one by one.

Bruno Volpato [9:24 AM]
I think you can use small numbers to search

[9:24]
something between 100..200

[9:24]
http://prodes1:9200/_search?q=150

denny zhang [9:24 AM]
Copy that.

Bruno Volpato [9:24 AM]
you can look at the "took" field

denny zhang [9:24 AM]
yes, something like
curl -s 'http://107.170.212.76:9200/_search' --data '{"query":{"match_all":{}},"aggs":{"entityTypes":{"terms":{"field":"mdmApplicationId"}}}}' | jq '.took'

[9:25]
The trick you used. :slightly_smiling_face:
** TODO How to protect elasticsearch with username and password?
# If your Elasticsearch is protected with basic auth, this is the user credentials
# used by the Kibana server to perform maintence on the kibana_index at statup. Your Kibana
# users will still need to authenticate with Elasticsearch (which is proxied thorugh
# the Kibana server)
# kibana_elasticsearch_username: user
# kibana_elasticsearch_password: pass
** TODO [#A] read elasticsearch links
http://stackoverflow.com/questions/17319760/logstash-converting-date-to-valid-joda-time-timestamp
http://stackoverflow.com/questions/32337881/grok-what-is-the-difference-between-grok-pattern-timestamp-and-date-filter-of-l
https://discuss.elastic.co/t/converting-string-to-date/26748/5
http://blog.eagerelk.com/how-to-configure-the-date-logstash-filter/
https://www.elastic.co/blog/little-logstash-lessons-part-using-grok-mutate-type-data
https://discuss.elastic.co/t/grok-date-and-time-format/46816
http://stackoverflow.com/questions/32278292/time-field-for-netscaler-logstash-grok-filter
** TODO why elasticsearch process doesn't crash by Xmx Xms
]133;D;0]1337;RemoteHost=root@prod-es-6]1337;CurrentDir=/root]133;Aroot@prod-es-6:~# ]133;Btop -n 1 -p 11855
top -n 1 -p 11855
]133;C;top - 02:54:24 up 83 days, 17:47,  2 users,  load average: 0.02, 0.02, 0.05
Tasks:   1 total,   0 running,   1 sleeping,   0 stopped,   0 zombie
%Cpu(s):  2.1 us,  0.4 sy,  0.0 ni, 97.4 id,  0.1 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem:  32948520 total, 24087720 used,  8860800 free,   181212 buffers
KiB Swap:        0 total,        0 used,        0 free.  4307148 cached Mem

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
11855 elastic+  20   0 97.832g 0.017t 580756 S   0.0 55.9  39277:56 java
** TODO [#A] read elasticsearch re-indexing with no downtime: https://speakerdeck.com/elastic/elastic-silicon-valley-meetup-zero-downtime-re-indexing-of-elasticsearch-at-signalfx
** TODO elasticsearch shards
http://cpratt.co/how-many-shards-should-elasticsearch-indexes-have/

https://www.elastic.co/guide/en/elasticsearch/reference/current/glossary.html
https://qbox.io/blog/optimizing-elasticsearch-how-many-shards-per-index
http://blog.trifork.com/2014/01/07/elasticsearch-how-many-shards/
** TODO Monitoring Elasticsearch from inside Emacs: https://twitter.com/vedang/status/725424306000273408
** TODO elasticsearch cluster backup
689 GB

1. 1 TB disk (which node it should be mounted to)
2. elasticsearch cluster need to be upgraded
#+BEGIN_EXAMPLE
I'm working on Elasticsearch cluster backup. We can plan the change late next week.

So far two things I need to highlight in advance:
1. I need to apply 1.5TB disk
   Total size of all elasticsearch data folder is 689GB. Considering to the data duplication, my guess for total unique raw data is 400GB. If we want to keep latest 3 days backup. It's about 1.2 TB. Let's say the data grows day by day, so we need 1.5TB disk at least.

2. Need to restart elasticsearch cluster
  To use elasticsearch snapshot feature, we need to specify data.path parameter in elasticsearch.yml then restart service.

[3:46]
All critical information and procedure about backup/restore will be properly updated in github wiki.

I'm trying to automate the steps in chef. However to get data secured earlier in prod env, some manual setup may be required for now.
#+END_EXAMPLE
** TODO [#A] elasticsearch error: [_uid] would be larger than configured breaker
today I see ES server warning message, and our MDM code stopped.

[2016-09-27 13:13:45,127][WARN ][indices.breaker.fielddata] [fielddata] New used memory 934290516 [891mb] for data of [_uid] would be larger than configured breaker: 934163251 [890.8mb], breaking

The root cause is the field data guard, and it pretty much stops the world. Here is the details:

https://www.elastic.co/guide/en/elasticsearch/guide/current/_limiting_memory_usage.html

After I put this into elasticsearch.yml file, now it will evict field data, but sometimes the performance will be bad.

indices.fielddata.cache.size:  20%

[9:30]
but at least we don't hit safe guard and whole application stops

#+BEGIN_EXAMPLE
root@aio:/var/log/elasticsearch# tail -f mdm.log
[2016-09-27 13:13:45,127][WARN ][indices.breaker.fielddata] [fielddata] New used memory 934290516 [891mb] for data of [_uid] would be larger than configured breaker: 934163251 [890.8mb], breaking
[2016-09-27 13:13:55,303][WARN ][indices.breaker.fielddata] [fielddata] New used memory 934290516 [891mb] for data of [_uid] would be larger than configured breaker: 934163251 [890.8mb], breaking
[2016-09-27 13:13:56,261][WARN ][indices.breaker.fielddata] [fielddata] New used memory 934273015 [890.9mb] for data of [mdmId] would be larger than configured breaker: 934163251 [890.8mb], breaking
[2016-09-27 13:14:05,426][WARN ][indices.breaker.fielddata] [fielddata] New used memory 937056412 [893.6mb] for data of [_uid] would be larger than configured breaker: 934163251 [890.8mb], breaking
[2016-09-27 13:14:10,855][WARN ][indices.breaker.fielddata] [fielddata] New used memory 934273015 [890.9mb] for data of [mdmId] would be larger than configured breaker: 934163251 [890.8mb], breaking
[2016-09-27 13:14:15,549][WARN ][indices.breaker.fielddata] [fielddata] New used memory 937056412 [893.6mb] for data of [_uid] would be larger than configured breaker: 934163251 [890.8mb], breaking
[2016-09-27 13:14:25,673][WARN ][indices.breaker.fielddata] [fielddata] New used memory 937056412 [893.6mb] for data of [_uid] would be larger than configured breaker: 934163251 [890.8mb], breaking
[2016-09-27 13:14:35,806][WARN ][indices.breaker.fielddata] [fielddata] New used memory 937056412 [893.6mb] for data of [_uid] would be larger than configured breaker: 934163251 [890.8mb], breaking
[2016-09-27 13:14:45,945][WARN ][indices.breaker.fielddata] [fielddata] New used memory 937056412 [893.6mb] for data of [_uid] would be larger than configured breaker: 934163251 [890.8mb], breaking
[2016-09-27 13:14:56,069][WARN ][indices.breaker.fielddata] [fielddata] New used memory 937056412 [893.6mb] for data of [_uid] would be larger than configured breaker: 934163251 [890.8mb], breaking
[2016-09-27 13:15:06,193][WARN ][indices.breaker.fielddata] [fielddata] New used memory 937056412 [893.6mb] for data of [_uid] would be larger than configured breaker: 934163251 [890.8mb], breaking
[2016-09-27 13:15:16,319][WARN ][indices.breaker.fielddata] [fielddata] New used memory 937056412 [893.6mb] for data of [_uid] would be larger than configured breaker: 934163251 [890.8mb], breaking
[2016-09-27 13:15:26,443][WARN ][indices.breaker.fielddata] [fielddata] New used memory 937056412 [893.6mb] for data of [_uid] would be larger than configured breaker: 934163251 [890.8mb], breaking
[2016-09-27 13:15:36,568][WARN ][indices.breaker.fielddata] [fielddata] New used memory 937056412 [893.6mb] for data of [_uid] would be larger than configured breaker: 934163251 [890.8mb], breaking
#+END_EXAMPLE
** TODO elasticsearch report: https://www.elastic.co/downloads/reporting
** TODO monitor elasticsearch deployment: https://www.elastic.co/downloads
** TODO Alerting for Elasticsearch: https://www.elastic.co/downloads
** TODO elasticsearch unicast address: will it change?
** TODO [#A] How elasticsearch recognize logstash data in ELK
http://blog.terminal.com/elk-elegant-logs-analysis-part-ii/
** TODO elasticsearch how to change number of shards for existing indices
** TODO elasticsearch fail to create repository: path.repo not being recognized
https://discuss.elastic.co/t/path-repo-is-empty/25166/4
https://github.com/elastic/elasticsearch/issues/12349

Ok. Finally I found there was a problem...

In Ubuntu the elasticsearch directory configured directly in init script /etc/init.d/elasticsearch and then laucnhed via DAEMON_OPTS like :

DAEMON_OPTS="-d -p $PID_FILE --default.config=$CONF_FILE --default.path.home=$ES_HOME --default.path.logs=$LOG_DIR --default.path.data=$DATA_DIR --default.path.work=$WORK_DIR --default.path.conf=$CONF_DIR"
So for the moment I could fix the problem adding :

REPO_DIR=/backup/es_backup_basic
and

DAEMON_OPTS="-d -p $PID_FILE --default.config=$CONF_FILE --default.path.home=$ES_HOME --default.path.logs=$LOG_DIR --default.path.data=$DATA_DIR --default.path.work=$WORK_DIR --default.path.conf=$CONF_DIR--default.path.repo=$REPO_DIR "
It solved the problem... even it's not normal for me that ES does not get sense of /etc/elasticsearch/elasticsearch.yml settings.
** #  --8<-------------------------- separator ------------------------>8--
** TODO elasticsearch mavel: Monitor and Manage your Elasticsearch cluster
http://chrissimpson.co.uk/elasticsearch-marvel-monitor-and-manage-your-cluster.html
http://www.elasticsearch.org/blog/building-marvel/
** HALF elasticsearch create index
https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-create-index.html
** TODO monitor elasticsearch suspicious memory activity
https://www.elastic.co/blog/found-understanding-memory-pressure-indicator
https://www.elastic.co/guide/en/elasticsearch/guide/current/_monitoring_individual_nodes.html
** TODO When is less busy of your system
#+BEGIN_EXAMPLE
William Monti [3:25 PM]
@denny.zhang i will coordinate with you so we can monitor it
what time do we usually see a decrease in traffic?


Denny Zhang
[3:29 PM]
That's a good question, William.

Let's try after 6PDT this time.

I will get the accurate measurement next time.
#+END_EXAMPLE
** TODO Get the slow queries
Bruno Volpato
[6:29 PM]
with the new logs, this will return the last queries that took a long time to process, in ascending order:


[6:29]
`tail -n 100000 mdm-app.log | grep "Perf-Search" | cut -d')' -f2- | sort -n -k 2`


[6:29]
(weird bash skills, but I promise it works) (edited)


Denny Zhang
[6:30 PM]
LOL

I think it's familiar to me.


[6:30]
Let me give it a try
** TODO application ES performance downgrade

** TODO ES relocating performance downgrade
#+BEGIN_EXAMPLE
Denny Zhang
[7:03 AM]
I have one interesting observation.

Whenever ES cluster calculate how to relocates some shards, "list shards" api will hang for a while.
Probably other ES operation will hang as well.

For example, below command took 37 seconds to return.
```root@bematech-do-es-10:~# curl $es_ip:9200/_cat/shards?v | grep -v STARTED
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  4  361k    4 16300    0     0    166      0  0:37:11  0:01:37  0:35:34  3644index                                               shard prirep state          docs    store ip              node
master-index-abae8b30ac9b11e692000401f8d88101-new3  19    r      RELOCATING                   165.227.5.192   bematech-do-es-03.localdomain -> 138.197.215.132 _goKs3R1Q5mTe06faT5IUg bematech-do-es-01.localdomain
master-index-abae8b30ac9b11e692000401f8d88101-new3  0     r      RELOCATING 29225589   39.2gb 165.227.21.77   bematech-do-es-06.localdomain -> 138.197.215.132 _goKs3R1Q5mTe06faT5IUg bematech-do-es-01.localdomain
```
(edited)


[7:06]
For 1st entry, ES cluster is calculating how to relocating.
For 2nd entry, ES cluster is already running the relocating.
#+END_EXAMPLE
** TODO Get shard allocation list across the nodes
** TODO elasticsearch get notification for the node removal events
[2017-08-22 16:48:06,553][INFO ][cluster.service          ] [bematech-do-es-07.localdomain] removed {{bematech-do-es-01.localdomain}{_goKs3R1Q5mTe06faT5IUg}{138.197.215.132}{138.197.215.132:9300}{max_local_storage_nodes=1},}, reason: zen-disco-receive(from master [{bematech-do-es-18.localdomain}{2ScQBOZqQVCOKOdztMtHjA}{165.227.25.149}{165.227.25.149:9300}{max_local_storage_nodes=1}])
[2017-08-22 16:48:44,825][INFO ][monitor.jvm              ] [bematech-do-es-07.localdomain] [gc][young][124363][8112] duration [704ms], collections [1]/[1.6s], total [704ms]/[50.3m], memory [11.2gb]->[8.2gb]/[15.6gb], all_pools {[young] [2.9gb]->[34.6mb]/[3.2gb]}{[survivor] [136.9mb]->[118.5mb]/[409.5mb]}{[old] [8.1gb]->[8.1gb]/[12gb]}
[2017-08-22 16:49:37,195][INFO ][cluster.service          ] [bematech-do-es-07.localdomain] added {{bematech-do-es-01.localdomain}{_goKs3R1Q5mTe06faT5IUg}{138.197.215.132}{138.197.215.132:9300}{max_local_storage_nodes=1},}, reason: zen-disco-receive(from master [{bematech-do-es-18.localdomain}{2ScQBOZqQVCOKOdztMtHjA}{165.227.25.149}{165.227.25.149:9300}{max_local_storage_nodes=1}])
** TODO elasticsearch get node stats
https://www.elastic.co/guide/en/elasticsearch/reference/2.3/cluster-nodes-stats.html
curl $es_ip:9200/_nodes/stats | jq '.'
** TODO Elasticsearch get performance indicator from node stats
#+BEGIN_EXAMPLE
root@bematech-do-es-08:~# curl -XGET $es_ip:9200/_nodes/stats/indices/search?pretty
root@bematech-do-es-08:~# curl -XGET $es_ip:9200/_nodes/stats/indices/search?pretty
{
  "cluster_name" : "mdm",
  "nodes" : {
    "uAFA2r2CQeSFb4YVNUxAUA" : {
      "timestamp" : 1503506246862,
      "name" : "bematech-do-app-3node",
      "transport_address" : "138.68.241.116:9301",
      "host" : "138.68.241.116",
      "ip" : [ "138.68.241.116:9301", "NONE" ],
      "attributes" : {
        "data" : "false",
        "master" : "false"
      },
      "indices" : {
        "search" : {
          "open_contexts" : 0,
          "query_total" : 0,
          "query_time_in_millis" : 0,
          "query_current" : 0,
          "fetch_total" : 0,
          "fetch_time_in_millis" : 0,
          "fetch_current" : 0,
          "scroll_total" : 0,
          "scroll_time_in_millis" : 0,
          "scroll_current" : 0
        }
      }
    },
    "SrY2diUXTNiHR--I0FzXPw" : {
      "timestamp" : 1503506246865,
      "name" : "bematech-do-es-03.localdomain",
      "transport_address" : "165.227.5.192:9300",
      "host" : "165.227.5.192",
      "ip" : [ "165.227.5.192:9300", "NONE" ],
      "attributes" : {
        "max_local_storage_nodes" : "1"
      },
      "indices" : {
        "search" : {
          "open_contexts" : 42,
          "query_total" : 39586989,
          "query_time_in_millis" : 346257425,
          "query_current" : 0,
          "fetch_total" : 455309,
          "fetch_time_in_millis" : 6214308,
          "fetch_current" : 0,
          "scroll_total" : 19274767,
          "scroll_time_in_millis" : 13922269459,
          "scroll_current" : 43
        }
      }
    },
    "1JBU9etUSIW17Hq0f_tgbA" : {
      "timestamp" : 1503506246861,
      "name" : "bematech-do-app-1node",
      "transport_address" : "138.68.41.110:9301",
      "host" : "138.68.41.110",
      "ip" : [ "138.68.41.110:9301", "NONE" ],
      "attributes" : {
        "data" : "false",
        "master" : "false"
      },
      "indices" : {
        "search" : {
          "open_contexts" : 0,
          "query_total" : 0,
          "query_time_in_millis" : 0,
          "query_current" : 0,
          "fetch_total" : 0,
          "fetch_time_in_millis" : 0,
          "fetch_current" : 0,
          "scroll_total" : 0,
          "scroll_time_in_millis" : 0,
          "scroll_current" : 0
        }
      }
    },
    "OAjzdp4MSHOaWq3Hge-sPQ" : {
      "timestamp" : 1503506246601,
      "name" : "bematech-do-es-15.localdomain",
      "transport_address" : "138.68.230.220:9300",
      "host" : "138.68.230.220",
      "ip" : [ "138.68.230.220:9300", "NONE" ],
      "attributes" : {
        "max_local_storage_nodes" : "1"
      },
      "indices" : {
        "search" : {
          "open_contexts" : 46,
          "query_total" : 37553614,
          "query_time_in_millis" : 965478169,
          "query_current" : 0,
          "fetch_total" : 319450,
          "fetch_time_in_millis" : 20859478,
          "fetch_current" : 0,
          "scroll_total" : 16316277,
          "scroll_time_in_millis" : 10421258313,
          "scroll_current" : 71
        }
      }
    },
    "mrhCiAPvRxekqyhVPTq5LQ" : {
      "timestamp" : 1503506246872,
      "name" : "bematech-do-es-11.localdomain",
      "transport_address" : "138.197.221.161:9300",
      "host" : "138.197.221.161",
      "ip" : [ "138.197.221.161:9300", "NONE" ],
      "attributes" : {
        "max_local_storage_nodes" : "1"
      },
      "indices" : {
        "search" : {
          "open_contexts" : 17,
          "query_total" : 894783,
          "query_time_in_millis" : 908117,
          "query_current" : 0,
          "fetch_total" : 6799,
          "fetch_time_in_millis" : 7875,
          "fetch_current" : 0,
          "scroll_total" : 221099,
          "scroll_time_in_millis" : 99157508,
          "scroll_current" : 17
        }
      }
    },
    "vZAakGIRQF6ZEfwp89AFsQ" : {
      "timestamp" : 1503506246915,
      "name" : "bematech-do-es-16.localdomain",
      "transport_address" : "165.227.13.42:9300",
      "host" : "165.227.13.42",
      "ip" : [ "165.227.13.42:9300", "NONE" ],
      "attributes" : {
        "max_local_storage_nodes" : "1"
      },
      "indices" : {
        "search" : {
          "open_contexts" : 40,
          "query_total" : 42958559,
          "query_time_in_millis" : 202487070,
          "query_current" : 0,
          "fetch_total" : 369395,
          "fetch_time_in_millis" : 2570057,
          "fetch_current" : 0,
          "scroll_total" : 18319118,
          "scroll_time_in_millis" : 13391474511,
          "scroll_current" : 42
        }
      }
    },
    "6CePE_vbRvKYu4PCICzRAw" : {
      "timestamp" : 1503506246858,
      "name" : "bematech-do-es-06.localdomain",
      "transport_address" : "165.227.21.77:9300",
      "host" : "165.227.21.77",
      "ip" : [ "165.227.21.77:9300", "NONE" ],
      "attributes" : {
        "max_local_storage_nodes" : "1"
      },
      "indices" : {
        "search" : {
          "open_contexts" : 39,
          "query_total" : 31930276,
          "query_time_in_millis" : 279050572,
          "query_current" : 0,
          "fetch_total" : 379409,
          "fetch_time_in_millis" : 4507514,
          "fetch_current" : 0,
          "scroll_total" : 16545868,
          "scroll_time_in_millis" : 11078032478,
          "scroll_current" : 39
        }
      }
    },
    "gH6TQzceT3ezVe_JzJV9RQ" : {
      "timestamp" : 1503506247319,
      "name" : "bematech-do-es-13.localdomain",
      "transport_address" : "165.227.27.184:9300",
      "host" : "165.227.27.184",
      "ip" : [ "165.227.27.184:9300", "NONE" ],
      "attributes" : {
        "max_local_storage_nodes" : "1"
      },
      "indices" : {
        "search" : {
          "open_contexts" : 42,
          "query_total" : 68962491,
          "query_time_in_millis" : 864259411,
          "query_current" : 1,
          "fetch_total" : 526570,
          "fetch_time_in_millis" : 24664489,
          "fetch_current" : 0,
          "scroll_total" : 26275540,
          "scroll_time_in_millis" : 21426717785,
          "scroll_current" : 44
        }
      }
    },
    "4gyYmBDXTXK6BY_ujUQGTA" : {
      "timestamp" : 1503506246860,
      "name" : "bematech-do-es-08.localdomain",
      "transport_address" : "bematech-do-es-08/138.68.30.61:9300",
      "host" : "138.68.30.61",
      "ip" : [ "bematech-do-es-08/138.68.30.61:9300", "NONE" ],
      "attributes" : {
        "max_local_storage_nodes" : "1"
      },
      "indices" : {
        "search" : {
          "open_contexts" : 35,
          "query_total" : 22983481,
          "query_time_in_millis" : 323583240,
          "query_current" : 0,
          "fetch_total" : 439571,
          "fetch_time_in_millis" : 7055402,
          "fetch_current" : 0,
          "scroll_total" : 10936954,
          "scroll_time_in_millis" : 7331714867,
          "scroll_current" : 146
        }
      }
    },
    "rdhoF7S2SGe75kttBx4_Og" : {
      "timestamp" : 1503506246788,
      "name" : "bematech-do-es-14.localdomain",
      "transport_address" : "138.68.23.132:9300",
      "host" : "138.68.23.132",
      "ip" : [ "138.68.23.132:9300", "NONE" ],
      "attributes" : {
        "max_local_storage_nodes" : "1"
      },
      "indices" : {
        "search" : {
          "open_contexts" : 39,
          "query_total" : 43045894,
          "query_time_in_millis" : 90346437,
          "query_current" : 0,
          "fetch_total" : 393563,
          "fetch_time_in_millis" : 1167903,
          "fetch_current" : 0,
          "scroll_total" : 18387245,
          "scroll_time_in_millis" : 11901572721,
          "scroll_current" : 41
        }
      }
    },
    "pYRD7spAStWkMf7Eo5wa9A" : {
      "timestamp" : 1503506246552,
      "name" : "bematech-do-es-09.localdomain",
      "transport_address" : "138.197.194.166:9300",
      "host" : "138.197.194.166",
      "ip" : [ "138.197.194.166:9300", "NONE" ],
      "attributes" : {
        "max_local_storage_nodes" : "1"
      },
      "indices" : {
        "search" : {
          "open_contexts" : 7,
          "query_total" : 3491355,
          "query_time_in_millis" : 5925502,
          "query_current" : 0,
          "fetch_total" : 197840,
          "fetch_time_in_millis" : 65662,
          "fetch_current" : 0,
          "scroll_total" : 2483867,
          "scroll_time_in_millis" : 1069771252,
          "scroll_current" : 7
        }
      }
    },
    "2ScQBOZqQVCOKOdztMtHjA" : {
      "timestamp" : 1503506246920,
      "name" : "bematech-do-es-18.localdomain",
      "transport_address" : "165.227.25.149:9300",
      "host" : "165.227.25.149",
      "ip" : [ "165.227.25.149:9300", "NONE" ],
      "attributes" : {
        "max_local_storage_nodes" : "1"
      },
      "indices" : {
        "search" : {
          "open_contexts" : 31,
          "query_total" : 633920710,
          "query_time_in_millis" : 1827747460,
          "query_current" : 1,
          "fetch_total" : 15069651,
          "fetch_time_in_millis" : 20355429,
          "fetch_current" : 1,
          "scroll_total" : 546577093,
          "scroll_time_in_millis" : 114321501378,
          "scroll_current" : 144
        }
      }
    },
    "r183O7anSLOoB-8tkk2pSw" : {
      "timestamp" : 1503506246861,
      "name" : "bematech-do-app-2node",
      "transport_address" : "138.68.241.113:9301",
      "host" : "138.68.241.113",
      "ip" : [ "138.68.241.113:9301", "NONE" ],
      "attributes" : {
        "data" : "false",
        "master" : "false"
      },
      "indices" : {
        "search" : {
          "open_contexts" : 0,
          "query_total" : 0,
          "query_time_in_millis" : 0,
          "query_current" : 0,
          "fetch_total" : 0,
          "fetch_time_in_millis" : 0,
          "fetch_current" : 0,
          "scroll_total" : 0,
          "scroll_time_in_millis" : 0,
          "scroll_current" : 0
        }
      }
    },
    "eCteNDCeTk2uXlDCz5JZxg" : {
      "timestamp" : 1503506246856,
      "name" : "bematech-do-es-05.localdomain",
      "transport_address" : "138.68.46.170:9300",
      "host" : "138.68.46.170",
      "ip" : [ "138.68.46.170:9300", "NONE" ],
      "attributes" : {
        "max_local_storage_nodes" : "1"
      },
      "indices" : {
        "search" : {
          "open_contexts" : 44,
          "query_total" : 36143925,
          "query_time_in_millis" : 39840581,
          "query_current" : 0,
          "fetch_total" : 414279,
          "fetch_time_in_millis" : 654827,
          "fetch_current" : 0,
          "scroll_total" : 17074125,
          "scroll_time_in_millis" : 11206508673,
          "scroll_current" : 47
        }
      }
    },
    "ArXwkkoAQUKcxdY5N8x4DQ" : {
      "timestamp" : 1503506246862,
      "name" : "bematech-do-es-10.localdomain",
      "transport_address" : "138.197.221.191:9300",
      "host" : "138.197.221.191",
      "ip" : [ "138.197.221.191:9300", "NONE" ],
      "attributes" : {
        "max_local_storage_nodes" : "1"
      },
      "indices" : {
        "search" : {
          "open_contexts" : 29,
          "query_total" : 9975763,
          "query_time_in_millis" : 16994417,
          "query_current" : 0,
          "fetch_total" : 99928,
          "fetch_time_in_millis" : 286328,
          "fetch_current" : 0,
          "scroll_total" : 5122455,
          "scroll_time_in_millis" : 2865946575,
          "scroll_current" : 29
        }
      }
    },
    "ppQNYbLgRLKJOrP7CbIclA" : {
      "timestamp" : 1503506246858,
      "name" : "bematech-do-es-02.localdomain",
      "transport_address" : "138.68.50.117:9300",
      "host" : "138.68.50.117",
      "ip" : [ "138.68.50.117:9300", "NONE" ],
      "attributes" : {
        "max_local_storage_nodes" : "1"
      },
      "indices" : {
        "search" : {
          "open_contexts" : 45,
          "query_total" : 39824550,
          "query_time_in_millis" : 123391843,
          "query_current" : 0,
          "fetch_total" : 434944,
          "fetch_time_in_millis" : 1761767,
          "fetch_current" : 0,
          "scroll_total" : 19096817,
          "scroll_time_in_millis" : 13706982678,
          "scroll_current" : 49
        }
      }
    },
    "fdBNqXd2Rk-ZStTolqCNjw" : {
      "timestamp" : 1503506246868,
      "name" : "bematech-do-es-17.localdomain",
      "transport_address" : "165.227.31.102:9300",
      "host" : "165.227.31.102",
      "ip" : [ "165.227.31.102:9300", "NONE" ],
      "attributes" : {
        "max_local_storage_nodes" : "1"
      },
      "indices" : {
        "search" : {
          "open_contexts" : 42,
          "query_total" : 42143785,
          "query_time_in_millis" : 134601867,
          "query_current" : 0,
          "fetch_total" : 804181,
          "fetch_time_in_millis" : 1744755,
          "fetch_current" : 0,
          "scroll_total" : 17679750,
          "scroll_time_in_millis" : 11443721229,
          "scroll_current" : 47
        }
      }
    },
    "LYqEFqS1TY-qOuPQ9uX9GA" : {
      "timestamp" : 1503506246865,
      "name" : "bematech-do-es-19.localdomain",
      "transport_address" : "138.197.205.85:9300",
      "host" : "138.197.205.85",
      "ip" : [ "138.197.205.85:9300", "NONE" ],
      "attributes" : {
        "max_local_storage_nodes" : "1"
      },
      "indices" : {
        "search" : {
          "open_contexts" : 38,
          "query_total" : 421308940,
          "query_time_in_millis" : 2468698639,
          "query_current" : 1,
          "fetch_total" : 6451454,
          "fetch_time_in_millis" : 28228855,
          "fetch_current" : 0,
          "scroll_total" : 322346848,
          "scroll_time_in_millis" : 81228521290,
          "scroll_current" : 104
        }
      }
    },
    "VA8KBulRQymfG8LR5DACnQ" : {
      "timestamp" : 1503506246888,
      "name" : "bematech-do-es-04.localdomain",
      "transport_address" : "165.227.17.43:9300",
      "host" : "165.227.17.43",
      "ip" : [ "165.227.17.43:9300", "NONE" ],
      "attributes" : {
        "max_local_storage_nodes" : "1"
      },
      "indices" : {
        "search" : {
          "open_contexts" : 39,
          "query_total" : 34512042,
          "query_time_in_millis" : 286227718,
          "query_current" : 0,
          "fetch_total" : 361385,
          "fetch_time_in_millis" : 5825682,
          "fetch_current" : 0,
          "scroll_total" : 15731508,
          "scroll_time_in_millis" : 12596026072,
          "scroll_current" : 133
        }
      }
    },
    "elqF0TY7R4Cbb5-DZJih2g" : {
      "timestamp" : 1503506246860,
      "name" : "bematech-do-es-07.localdomain",
      "transport_address" : "165.227.21.128:9300",
      "host" : "165.227.21.128",
      "ip" : [ "165.227.21.128:9300", "NONE" ],
      "attributes" : {
        "max_local_storage_nodes" : "1"
      },
      "indices" : {
        "search" : {
          "open_contexts" : 20,
          "query_total" : 21824048,
          "query_time_in_millis" : 112076886,
          "query_current" : 0,
          "fetch_total" : 259607,
          "fetch_time_in_millis" : 2842147,
          "fetch_current" : 0,
          "scroll_total" : 11701174,
          "scroll_time_in_millis" : 8909266300,
          "scroll_current" : 191
        }
      }
    },
    "xHDsICIhSiOf93CY2uDAKA" : {
      "timestamp" : 1503506246865,
      "name" : "bematech-do-es-12.localdomain",
      "transport_address" : "138.197.200.214:9300",
      "host" : "138.197.200.214",
      "ip" : [ "138.197.200.214:9300", "NONE" ],
      "attributes" : {
        "max_local_storage_nodes" : "1"
      },
      "indices" : {
        "search" : {
          "open_contexts" : 43,
          "query_total" : 159153507,
          "query_time_in_millis" : 416696803,
          "query_current" : 1,
          "fetch_total" : 1934510,
          "fetch_time_in_millis" : 5356326,
          "fetch_current" : 0,
          "scroll_total" : 101694822,
          "scroll_time_in_millis" : 43636915009,
          "scroll_current" : 64
        }
      }
    },
    "_goKs3R1Q5mTe06faT5IUg" : {
      "timestamp" : 1503506246865,
      "name" : "bematech-do-es-01.localdomain",
      "transport_address" : "138.197.215.132:9300",
      "host" : "138.197.215.132",
      "ip" : [ "138.197.215.132:9300", "NONE" ],
      "attributes" : {
        "max_local_storage_nodes" : "1"
      },
      "indices" : {
        "search" : {
          "open_contexts" : 21,
          "query_total" : 23250823,
          "query_time_in_millis" : 104496351,
          "query_current" : 0,
          "fetch_total" : 423032,
          "fetch_time_in_millis" : 1504146,
          "fetch_current" : 0,
          "scroll_total" : 10404775,
          "scroll_time_in_millis" : 7718803287,
          "scroll_current" : 265
        }
      }
    }
  }
}
#+END_EXAMPLE

** #  --8<-------------------------- separator ------------------------>8--
** TODO Why ES run into yellow again this morning?
** TODO ES Performance indicators
*** Shard count and shard size
*** We can't have many mappings
#+BEGIN_EXAMPLE
``````


[11:59]
https://www.elastic.co/guide/en/elasticsearch/guide/current/mapping.html#_type_takeaways


Bruno Volpato
[12:00 PM]
so the best way would be, for different schemas of data, we should have different indexes.
1 reply Today at 12:12 PM View thread


Bruno Volpato
[12:00 PM]
we kind of know that we can't have many mappings, but our feeling was that the schema for Bematech for example is not big. he is more experienced and said it is


[12:01]
so I think we will explore some separations soon. it will also be nice for reindexing, but I believe monitoring will be more difficult, @denny.zhang


[12:02]
more indexes for each tenant


Denny Zhang
[12:03 PM]
Should be feasible, Bruno. And yes, let's re-index first.



Nagios APP [12:06 PM]
bematech-do-app-1/check_mdm_server_err_rate is C
#+END_EXAMPLE
*** for different schemas of data, we should have different indexes.
*** too many type for the index
** TODO ES performance learning
Mitu Singh [11:01 PM]
https://www.elastic.co/guide/en/elasticsearch/reference/current/general-recommendations.html


[11:03]
```Avoid types
Types might sound like a good way to store multiple tenants in a single index. They are not: given that types store everything in a single index, having multiple types that have different fields in a single index will also cause problems due to sparsity as described above. If your types do not have very similar mappings, you might want to consider moving them to a dedicated index.```
(edited)


[11:06]
https://www.elastic.co/guide/en/elasticsearch/guide/current/mapping.html


[11:06]
```Types are not as well suited for entirely different types of data. If your two types have mutually exclusive sets of fields, that means half your index is going to contain "empty" values (the fields will be sparse), which will eventually cause performance problems. In these cases, it's much better to utilize two independent indices.```
** TODO elasticsearch reading
https://www.elastic.co/blog/found-sizing-elasticsearch
** TODO [#A] env cluster doesn't have firewall enabled
** TODO Check es forcemerge
http://do-es-001.carol.ai:9200/_cat/segments?v
** TODO lower the priority of busy ES nodes
#+BEGIN_EXAMPLE
4:03]
what you suggested @wmonti


[4:05]
@denny.zhang https://www.elastic.co/guide/en/elasticsearch/guide/current/retiring-data.html


Denny Zhang
[4:05 PM]
Yes?


Bruno Volpato
[4:05 PM]
the box_type seems to be a good deal, we can assign tags (for example, "slow") to some nodes and prevent them from getting more allocations


[4:06]
https://www.elastic.co/guide/en/elasticsearch/reference/2.4/shard-allocation-filtering.html


[4:07]
whenever we see a trend in high load for the node, we can exclude it from further allocations


Denny Zhang [4:08 PM]
Kung, sent this link before. Is this suggested from the ES expert? (edited)


new messages
Bruno Volpato
[4:08 PM]
no, just bringing ideas from what I'm reading, we are still to hear feedback from the guy


[4:08]
will try to schedule a meeting for today
#+END_EXAMPLE

** TODO Detect ES disconnect timeout
#+BEGIN_EXAMPLE
[2017-08-23 01:48:35,567][INFO ][cluster.service          ] [bematech-do-es-10.localdomain] removed {{bematech-do-es-01.localdomain}{_goKs3R1Q5mTe06faT5IUg}{138.197.215.132}{138.197.215.132:9300}{max_local_storage_nodes=1},}, reason: zen-disco-receive(from master [{bematech-do-es-18.localdomain}{2ScQBOZqQVCOKOdztMtHjA}{165.227.25.149}{165.227.25.149:9300}{max_local_storage_nodes=1}])
[2017-08-23 01:48:35,809][DEBUG][action.admin.indices.stats] [bematech-do-es-10.localdomain] failed to execute [indices:monitor/stats] on node [_goKs3R1Q5mTe06faT5IUg]
NodeDisconnectedException[[bematech-do-es-01.localdomain][138.197.215.132:9300][indices:monitor/stats[n]] disconnected]
[2017-08-23 01:48:57,408][INFO ][cluster.service          ] [bematech-do-es-10.localdomain] added {{bematech-do-es-01.localdomain}{_goKs3R1Q5mTe06faT5IUg}{138.197.215.132}{138.197.215.132:9300}{max_local_storage_nodes=1},}, reason: zen-disco-receive(from master [{bematech-do-es-18.localdomain}{2ScQBOZqQVCOKOdztMtHjA}{165.227.25.149}{165.227.25.149:9300}{max_local_storage_nodes=1}])
#+END_EXAMPLE
** HALF Question: ES cluster is initizing one specific shard, I can see the disk usage of shard folder keeps growing. But it's growing too slow. What I can check deeper?
** TODO [#A] Why ES runs into yellow
#+BEGIN_EXAMPLE
[2017-08-22 13:32:29,549][WARN ][discovery.zen.publish    ] [bematech-do-es-18.localdomain] timed out waiting for all nodes to process published state [87045] (timeout [30s], pending nodes: [{bematech-do-es-08.localdomain}{4gyYmBDXTXK6BY_ujUQGTA}{138.68.30.61}{138.68.30.61:9300}{max_local_storage_nodes=1}])
[2017-08-22 13:32:29,797][WARN ][cluster.service          ] [bematech-do-es-18.localdomain] cluster state update task [shard-started ([staging-index-8a18aa800e5911e785f24a8136534b63][3], node[4gyYmBDXTXK6BY_ujUQGTA], [R], v[2042], s[INITIALIZING], a[id=2rssevfNR8yq3RfPJ9MMbw], unassigned_info[[reason=NODE_LEFT], at[2017-08-22T13:17:16.521Z], details[node_left[4gyYmBDXTXK6BY_ujUQGTA]]], expected_shard_size[1653214250]), reason [after recovery (replica) from node [{bematech-do-es-18.localdomain}{2ScQBOZqQVCOKOdztMtHjA}{165.227.25.149}{165.227.25.149:9300}{max_local_storage_nodes=1}]]] took 30.3s above the warn threshold of 30s
[2017-08-22 13:32:59,858][WARN ][discovery.zen.publish    ] [bematech-do-es-18.localdomain] timed out waiting for all nodes to process published state [87046] (timeout [30s], pending nodes: [{bematech-do-es-08.localdomain}{4gyYmBDXTXK6BY_ujUQGTA}{138.68.30.61}{138.68.30.61:9300}{max_local_storage_nodes=1}])
[2017-08-22 13:33:00,030][WARN ][cluster.service          ] [bematech-do-es-18.localdomain] cluster state update task [shard-started ([master-index-8e2d11502c5511e79481a2f42be00f79][6], node[4gyYmBDXTXK6BY_ujUQGTA], [R], v[43], s[INITIALIZING], a[id=tcgFLO24S0CMyw6C8Gf65g], unassigned_info[[reason=NODE_LEFT], at[2017-08-22T13:17:16.521Z], details[node_left[4gyYmBDXTXK6BY_ujUQGTA]]], expected_shard_size[925201716]), reason [after recovery (replica) from node [{bematech-do-es-16.localdomain}{vZAakGIRQF6ZEfwp89AFsQ}{165.227.13.42}{165.227.13.42:9300}{max_local_storage_nodes=1}]]] took 30.2s above the warn threshold of 30s
[2017-08-22 13:34:28,448][WARN ][discovery.zen.publish    ] [bematech-do-es-18.localdomain] timed out waiting for all nodes to process published state [87047] (timeout [30s], pending nodes: [{bematech-do-es-08.localdomain}{4gyYmBDXTXK6BY_ujUQGTA}{138.68.30.61}{138.68.30.61:9300}{max_local_storage_nodes=1}])
[2017-08-22 13:34:28,633][WARN ][cluster.service          ] [bematech-do-es-18.localdomain] cluster state update task [shard-started ([master-index-abae8b30ac9b11e692000401f8d88101-new3][6], node[_goKs3R1Q5mTe06faT5IUg], relocating [elqF0TY7R4Cbb5-DZJih2g], [R], v[92], s[INITIALIZING], a[id=V-8V3OxjTDmLY6nHW9ylpA, rId=wSafkTlnSTGsFfB1mEfUTA], expected_shard_size[34379126275]), reason [after recovery (replica) from node [{bematech-do-es-16.localdomain}{vZAakGIRQF6ZEfwp89AFsQ}{165.227.13.42}{165.227.13.42:9300}{max_local_storage_nodes=1}]]] took 30.3s above the warn threshold of 30s
#+END_EXAMPLE

** TODO [#A] Restart ES instances take hours: https://t37.net/elasticsearch-cluster-rolling-restart-at-the-speed-of-light-with-rack-awareness.html
** TODO [#A] why es unassigned_shards grows?
*** <2017-08-21 01:11 UTC +8>
#+BEGIN_EXAMPLE
root@bematech-do-es-07:~# date; curl $es_ip:9200/_cat/shards?v | grep -v STARTED; curl $es_ip:9200/_cluster/health?pretty
root@bematech-do-es-07:~# date; curl $es_ip:9200/_cat/shards?v | grep -v STARTED; curl $es_ip:9200/_cluster/health?pretty
Mon Aug 21 06:10:40 UTC 2017
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  4  360k    4 16300    0     0   2684      0  0:02:17  0:00:06  0:02:11  3347index                                               shard prirep state            docs   store ip              node
staging-index-685778901e1c11e79595a2f42be00f79      6     r      UNASSIGNED
staging-index-685778901e1c11e79595a2f42be00f79      5     r      UNASSIGNED
staging-index-685778901e1c11e79595a2f42be00f79      4     r      UNASSIGNED
staging-index-8e2d11502c5511e79481a2f42be00f79      2     r      INITIALIZING                  165.227.21.128  bematech-do-es-07.localdomain
master-index-839920f07e6b11e6b71d0401f8d88101-new3  15    r      UNASSIGNED
master-index-839920f07e6b11e6b71d0401f8d88101-new3  17    r      UNASSIGNED
master-index-839920f07e6b11e6b71d0401f8d88101-new3  5     r      UNASSIGNED
master-index-839920f07e6b11e6b71d0401f8d88101-new3  16    r      UNASSIGNED
master-index-839920f07e6b11e6b71d0401f8d88101-new3  7     r      UNASSIGNED
master-index-839920f07e6b11e6b71d0401f8d88101-new3  14    r      UNASSIGNED
master-index-d5381d00202611e792b4a2f42be00f79       5     r      UNASSIGNED
master-index-d5381d00202611e792b4a2f42be00f79       7     r      UNASSIGNED
master-index-d5381d00202611e792b4a2f42be00f79       9     r      UNASSIGNED
master-index-d5381d00202611e792b4a2f42be00f79       0     r      UNASSIGNED
master-index-8a18aa800e5911e785f24a8136534b63       8     r      UNASSIGNED
master-index-8a18aa800e5911e785f24a8136534b63       9     r      UNASSIGNED
master-index-8a18aa800e5911e785f24a8136534b63       17    r      UNASSIGNED
master-index-8a18aa800e5911e785f24a8136534b63       17    r      UNASSIGNED
master-index-8a18aa800e5911e785f24a8136534b63       6     r      UNASSIGNED
master-index-8a18aa800e5911e785f24a8136534b63       19    r      UNASSIGNED
master-index-8cd6e43115e9416eb23609486fa053e3-new3  4     r      UNASSIGNED
master-index-8cd6e43115e9416eb23609486fa053e3-new3  2     r      UNASSIGNED
staging-index-8cd6e43115e9416eb23609486fa053e3-new3 4     r      UNASSIGNED
staging-index-8cd6e43115e9416eb23609486fa053e3-new3 3     r      UNASSIGNED
master-index-abae8b30ac9b11e692000401f8d88101-new3  48    r      UNASSIGNED
master-index-abae8b30ac9b11e692000401f8d88101-new3  48    r      UNASSIGNED
master-index-abae8b30ac9b11e692000401f8d88101-new3  9     r      UNASSIGNED
master-index-abae8b30ac9b11e692000401f8d88101-new3  6     r      UNASSIGNED
master-index-abae8b30ac9b11e692000401f8d88101-new3  42    r      UNASSIGNED
master-index-abae8b30ac9b11e692000401f8d88101-new3  15    r      INITIALIZING                  138.68.46.170   bematech-do-es-05.localdomain
master-index-abae8b30ac9b11e692000401f8d88101-new3  7     r      INITIALIZING                  165.227.31.102  bematech-do-es-17.localdomain
master-index-abae8b30ac9b11e692000401f8d88101-new3  39    r      UNASSIGNED
master-index-abae8b30ac9b11e692000401f8d88101-new3  18    r      INITIALIZING                  138.68.230.220  bematech-do-es-15.localdomain
master-index-abae8b30ac9b11e692000401f8d88101-new3  18    r      INITIALIZING                  165.227.25.149  bematech-do-es-18.localdomain
master-index-abae8b30ac9b11e692000401f8d88101-new3  37    r      UNASSIGNED
master-index-abae8b30ac9b11e692000401f8d88101-new3  37    r      UNASSIGNED
master-index-abae8b30ac9b11e692000401f8d88101-new3  4     r      INITIALIZING                  138.68.30.61    bematech-do-es-08.localdomain
master-index-abae8b30ac9b11e692000401f8d88101-new3  1     r      RELOCATING   28917702  35.7gb 165.227.13.42   bematech-do-es-16.localdomain -> 165.227.21.77 6CePE_vbRvKYu4PCICzRAw bematech-do-es-06.localdomain
master-index-abae8b30ac9b11e692000401f8d88101-new3  16    r      INITIALIZING                  138.197.215.132 bematech-do-es-01.localdomain
master-index-abae8b30ac9b11e692000401f8d88101-new3  22    r      INITIALIZING                  138.68.50.117   bematech-do-es-02.localdomain
master-index-abae8b30ac9b11e692000401f8d88101-new3  40    r      UNASSIGNED
master-index-abae8b30ac9b11e692000401f8d88101-new3  41    r      UNASSIGNED
master-index-abae8b30ac9b11e692000401f8d88101-new3  28    r      UNASSIGNED
master-index-abae8b30ac9b11e692000401f8d88101-new3  24    r      INITIALIZING                  165.227.21.77   bematech-do-es-06.localdomain
master-index-abae8b30ac9b11e692000401f8d88101-new3  49    r      UNASSIGNED
master-index-abae8b30ac9b11e692000401f8d88101-new3  36    r      UNASSIGNED
master-index-abae8b30ac9b11e692000401f8d88101-new3  36    r      UNASSIGNED
master-index-abae8b30ac9b11e692000401f8d88101-new3  8     r      INITIALIZING                  138.197.205.85  bematech-do-es-19.localdomain
master-index-abae8b30ac9b11e692000401f8d88101-new3  0     r      INITIALIZING                  165.227.13.42   bematech-do-es-16.localdomain
staging-index-d5381d00202611e792b4a2f42be00f79      1     r      UNASSIGNED
staging-index-d5381d00202611e792b4a2f42be00f79      4     r      UNASSIGNED
staging-index-d5381d00202611e792b4a2f42be00f79      4     r      UNASSIGNED
staging-index-d5381d00202611e792b4a2f42be00f79      7     r      UNASSIGNED
staging-index-8a18aa800e5911e785f24a8136534b63      13    r      UNASSIGNED
staging-index-8a18aa800e5911e785f24a8136534b63      19    r      UNASSIGNED
staging-index-8a18aa800e5911e785f24a8136534b63      8     r      UNASSIGNED
staging-index-8a18aa800e5911e785f24a8136534b63      1     r      UNASSIGNED
staging-index-8a18aa800e5911e785f24a8136534b63      18    r      UNASSIGNED
staging-index-8a18aa800e5911e785f24a8136534b63      10    r      UNASSIGNED
master-index-8e2d11502c5511e79481a2f42be00f79       8     r      UNASSIGNED
master-index-8e2d11502c5511e79481a2f42be00f79       7     r      INITIALIZING                  138.197.221.191 bematech-do-es-10.localdomain
master-index-8e2d11502c5511e79481a2f42be00f79       5     r      UNASSIGNED
master-index-1154b0b041d211e7b7c04a8136534b63       8     r      INITIALIZING                  165.227.17.43   bematech-do-es-04.localdomain
master-index-1154b0b041d211e7b7c04a8136534b63       6     r      INITIALIZING                  165.227.21.128  bematech-do-es-07.localdomain
master-index-1154b0b041d211e7b7c04a8136534b63       1     r      INITIALIZING                  165.227.17.43   bematech-do-es-04.localdomain
staging-index-1154b0b041d211e7b7c04a8136534b63      8     r      UNASSIGNED
staging-index-1154b0b041d211e7b7c04a8136534b63      9     r      INITIALIZING                  165.227.5.192   bematech-do-es-03.localdomain
master-index-685778901e1c11e79595a2f42be00f79       8     r      UNASSIGNED
master-index-685778901e1c11e79595a2f42be00f79       7     r      UNASSIGNED
master-index-b74f5a703d5e11e68ac00401f8d88501       3     r      UNASSIGNED
master-index-b74f5a703d5e11e68ac00401f8d88501       2     r      UNASSIGNED
staging-index-839920f07e6b11e6b71d0401f8d88101-new3 8     r      UNASSIGNED
staging-index-839920f07e6b11e6b71d0401f8d88101-new3 17    r      UNASSIGNED
staging-index-839920f07e6b11e6b71d0401f8d88101-new3 19    r      UNASSIGNED
staging-index-839920f07e6b11e6b71d0401f8d88101-new3 18    r      UNASSIGNED
staging-index-839920f07e6b11e6b71d0401f8d88101-new3 16    r      UNASSIGNED
staging-index-839920f07e6b11e6b71d0401f8d88101-new3 0     r      UNASSIGNED
master-index-e4010da4110ba377d100f050cb4440db-new3  2     r      UNASSIGNED
master-index-e4010da4110ba377d100f050cb4440db-new3  0     r      UNASSIGNED
staging-index-b74f5a703d5e11e68ac00401f8d88501      2     r      UNASSIGNED
master-index-d3ae95b0d12811e69edf0401f8d88501       1     r      UNASSIGNED
staging-index-abae8b30ac9b11e692000401f8d88101-new3 4     r      INITIALIZING                  138.68.230.220  bematech-do-es-15.localdomain
staging-index-abae8b30ac9b11e692000401f8d88101-new3 4     r      INITIALIZING                  138.197.194.166 bematech-do-es-09.localdomain
staging-index-da1c1280ac9b11e68e250401f8d88501      4     r      UNASSIGNED
staging-index-da1c1280ac9b11e68e250401f8d88501      3     r      UNASSIGNED
master-index-da1c1280ac9b11e68e250401f8d88501       3     r      UNASSIGNED
master-index-da1c1280ac9b11e68e250401f8d88501       0     r      UNASSIGNED
staging-index-e4010da4110ba377d100f050cb4440db-new3 2     r      UNASSIGNED
100  360k  100  360k    0     0  60528      0  0:00:06  0:00:06 --:--:-- 94822
master-index-03b541d0208111e7bbb0a2f42be00f79       8     r      UNASSIGNED
master-index-03b541d0208111e7bbb0a2f42be00f79       8     r      UNASSIGNED
master-index-dbb9e10026ce11e7aa220e4789ade3a3-new3  4     r      UNASSIGNED
master-index-dbb9e10026ce11e7aa220e4789ade3a3-new3  2     r      UNASSIGNED
master-index-dbb9e10026ce11e7aa220e4789ade3a3-new3  8     r      UNASSIGNED
staging-index-03b541d0208111e7bbb0a2f42be00f79      3     r      UNASSIGNED
staging-index-03b541d0208111e7bbb0a2f42be00f79      5     r      UNASSIGNED
staging-index-d3ae95b0d12811e69edf0401f8d88501      3     r      UNASSIGNED
staging-index-dbb9e10026ce11e7aa220e4789ade3a3-new3 9     r      UNASSIGNED
staging-index-dbb9e10026ce11e7aa220e4789ade3a3-new3 9     r      UNASSIGNED
staging-index-dbb9e10026ce11e7aa220e4789ade3a3-new3 5     r      UNASSIGNED
{
  "cluster_name" : "mdm",
  "status" : "yellow",
  "timed_out" : false,
  "number_of_nodes" : 22,
  "number_of_data_nodes" : 19,
  "active_primary_shards" : 591,
  "active_shards" : 1640,
  "relocating_shards" : 1,
  "initializing_shards" : 18,
  "unassigned_shards" : 80,
  "delayed_unassigned_shards" : 0,
  "number_of_pending_tasks" : 0,
  "number_of_in_flight_fetch" : 0,
  "task_max_waiting_in_queue_millis" : 0,
  "active_shards_percent_as_number" : 94.36133486766398
}
#+END_EXAMPLE

** TODO Elasticsearch Circuit Breaker
https://www.elastic.co/guide/en/elasticsearch/reference/2.3/circuit-breaker.html#request-circuit-breaker
https://github.com/elastic/elasticsearch/issues/20250
https://github.com/elastic/elasticsearch/issues/2929
So shortly speaking, sometimes it is better to fail a query instead of getting OOM, because when OOM appears JVM becomes not responsive.

Elasticsearch contains multiple circuit breakers used to prevent operations from causing an OutOfMemoryError.
** TODO elasticsearch show shards with certain fields
** TODO elasticsearch Limiting Memory Usage
https://www.elastic.co/guide/en/elasticsearch/guide/current/_limiting_memory_usage.html#circuit-breaker
** TODO elasticsearch: keep a close watch on how much memory is being used by fielddata
https://www.elastic.co/guide/en/elasticsearch/guide/current/_limiting_memory_usage.html#circuit-breaker

** TODO [#A] Linode network issue: fails elasticsearch cluster(explorees8, then explorees6)
45.33.48.11:2702

explorees7/check_elasticsearch_health is CRITICAL:
ERROR: elasticsearch health is not green, by checking 45.33.56.57:9200/_cluster/health

Nagios BOT [10:04 PM]
explorecb5/check_memory is WARNING:
MEMORY WARNING : Mem used: 44.40%, Swap used: 80.22%

[10:04]
explorecb5/check_swap_usage is WARNING:
SWAP WARNING - 20% free (50 MB out of 255 MB)

[10:04]
explorees7/check_disk_rootfs is OK

[10:06]
explorees8/check_elasticsearch_health is CRITICAL:
ERROR: elasticsearch health is not green, by checking 192.81.130.120:9200/_cluster/health

[10:06]
explorees8/check_elasticsearch_cpu is OK

denny zhang [10:07 PM]
Confirmed: ES cluster issue comes from explorees8.

Network issue of this node.
** TODO Elasticsearch cluster disk issue

Bruno Volpato [9:44 AM]
why the IO error?! I see all around 10% free

denny zhang [9:45 AM]
Here is my observation.

[9:45]
Some ES nodes disk usage is 80%-85%. It's pretty large. Right?

[9:46]
Then the available disk suddenly drops to lower than 5%.

After several minutes, lots of free disk again.

Bruno Volpato [9:46 AM]
found the errors on explorees4

[9:46]
 ```[2016-12-11 23:05:10,542][WARN ][indices.cluster          ] [explorees4] [[master-index-463da170a11811e6b9ecf23c912c9525][9]] marking and sending shard failed due to [engine failure, reason [already closed by tragic event on the translog]]
java.io.IOException: No space left on device
    at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
    at sun.nio.ch.FileDispatcherImpl.write(FileDispatcherImpl.java:60)
    at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
    at sun.nio.ch.IOUtil.write(IOUtil.java:65)
    at sun.nio.ch.FileChannelImpl.write(FileChannelImpl.java:210)
    at org.elasticsearch.common.io.Channels.writeToChannel(Channels.java:208)
    at org.elasticsearch.index.translog.BufferingTranslogWriter.flush(BufferingTranslogWriter.java:84)
    at org.elasticsearch.index.translog.BufferingTranslogWriter.sync(BufferingTranslogWriter.java:125)
    at org.elasticsearch.index.translog.TranslogWriter.syncUpTo(TranslogWriter.java:288)
    at org.elasticsearch.index.translog.Translog.ensureSynced(Translog.java:672)
    at org.elasticsearch.index.shard.IndexShard.sync(IndexShard.java:1627)
    at org.elasticsearch.action.support.replication.TransportReplicationAction.processAfterWrite(TransportReplicationAction.java:1035)
    at org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:295)
    at org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:68)
    at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.doRun(TransportReplicationAction.java:639)
    at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
    at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:279)
    at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:271)
    at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:75)
    at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:376)
    at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
    at java.lang.Thread.run(Thread.java:745)```

[9:47]
df -h says 39% free, so not sure why it happened

denny zhang [9:47 AM]
Yeah, do you see the same thing, I described above?

[9:47]
It's pretty scaring, when I first noticed that.

Bruno Volpato [9:48 AM]
I'm assuming it has to do with a previous error where a node disconnected from master

[9:48]
then it tried to assign replicas to the nodes, making them full really fast


Bruno Volpato [9:48 AM]
I'm assuming it has to do with a previous error where a node disconnected from master

[9:48]
then it tried to assign replicas to the nodes, making them full really fast

denny zhang [9:49 AM]
Good point. This is a plausible reason.

Bruno Volpato [9:50 AM]
maybe when we have the environment setup and we don't have too much room for rebalancing, we can disable auto-rebalance to avoid this kind of problem when a node goes off

[9:51]
ES has the threshold and will avoid replica assign if it's below the low disk watermark, but maybe when we have big replicas, they don't consider that it will fill the disk by just moving one piece (not sure)

denny zhang [9:52 AM]
I think auto rebalancing is good. We should be able to handle SPOF.

We might need to reserve more free disk for the possible one node disconnected or node down.


Nagios BOT [9:53 AM]
explorecb2/check_disk_rootfs is OK

denny zhang [9:54 AM]
When the problematic node is back to normal, data would shift back. Then we don't need to worry about one node has this or that issues.

After all, any node will have issue. Hacky way would make things more complicated.

What do you think, Bruno?
** TODO es low disk watermark

denny zhang [9:54 AM]
When the problematic node is back to normal, data would shift back. Then we don't need to worry about one node has this or that issues.

After all, any node will have issue. Hacky way would make things more complicated.

What do you think, Bruno?

Bruno Volpato [9:58 AM]
yes, auto-rebalance is good, but if it means that we always need to work with more resources that we really need just to support auto-rebalancing in case some node crashes

[9:58]
most of the times it will auto-recover, but in this case it probably started to move replicas around and caused problems to other nodes

[9:59]
maybe we should change the low disk watermark

[9:59]
today is 85%. after 85% it doesn't receive more replicas

denny zhang [9:59 AM]
Agree with low disk watermark

** TODO Automate elasticsearch re-indexing
#+BEGIN_EXAMPLE
Kung Wang
[11:32 AM]
@denny.zhang , during the early Monday meeting with Vicente. He mentioned that if we can do this reshard automatically.


[11:32]
what do you think?


[11:32]
can we setup some rules and create script for it? (edited)


[11:32]
for example


[11:35]
1. check current cut, double the cut
2. based on size of index, create another X number of machines
3. exclude routing for newly created machine.
4. start reindex to new machines
5. create alias and switch index
6. start 2nd reindex to catch up
7. shutdown old index
8, ...


[11:35]
we can run those scripts manually couple times, if we all feel comfortable, then we can put them into auto mode. can we ?

Denny Zhang
[11:36 AM]
Yes, technical speaking, it's feasible.

We can start to automate steps as much as possible.


Kung Wang
[11:36 AM]
we do not need to do it now, but if we can have script ready, we can run it manual for next Bematech or other tenant reindex


Denny Zhang
[11:36 AM]
Sometimes we need not only to re-indexing but also changing the mapping/settings.
#+END_EXAMPLE

** TODO elasticsearch get index document count
#+BEGIN_EXAMPLE
root@bematech-do-es-01:~/elasticsearch-cli-tool# date; curl $es_ip:9200/_cat/indices?v | grep abae8b30ac9b11e692000401f8d88101
Fri Sep 15 18:39:24 UTC 2017
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:--  0:00:04 --:--:--     0green  open   master-index-abae8b30ac9b11e692000401f8d88101-new3   50   2 1575289432    121012575      5.4tb          1.8tb
green  open   master-index-abae8b30ac9b11e692000401f8d88101-new2  100   2  472650269         2540      3.1tb            1tb
       close  staging-index-abae8b30ac9b11e692000401f8d88101-new3
green  open   staging-index-abae8b30ac9b11e692000401f8d88101-new2  50   2   79179948       199281      1.3tb        450.7gb
100 16250  100 16250    0     0   3362      0  0:00:04  0:00:04 --:--:--  4485
root@bematech-do-es-01:~/elasticsearch-cli-tool#
root@bematech-do-es-01:~/elasticsearch-cli-tool#
root@bematech-do-es-01:~/elasticsearch-cli-tool#
root@bematech-do-es-01:~/elasticsearch-cli-tool# curl http://$es_ip:9200/master-index-abae8b30ac9b11e692000401f8d88101-new3/_count
{"count":160263059,"_shards":{"total":50,"successful":50,"failed":0}}root@bematech-do-es-01:~/elasticsearch-cli-tool#
root@bematech-do-es-01:~/elasticsearch-cli-tool# curl http://$es_ip:9200/master-index-abae8b30ac9b11e692000401f8d88101-new2/_count
{"count":159776728,"_shards":{"total":100,"successful":100,"failed":0}}root@bematech-do-es-01:~/elasticsearch-cli-tool#
#+END_EXAMPLE

** TODO Detect elasticsearch hot threading
** TODO elasticsearch detect I/O
** TODO Detect elasticsearch segments activities
** TODO [#A] elasticsearch: indices.store.throttle.max_bytes_per_sec
https://www.elastic.co/guide/en/elasticsearch/guide/current/indexing-performance.html
https://discuss.elastic.co/t/indices-store-throttle-max-bytes-per-sec-config-setting-and-2-2/44771
https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-search-speed.html
** TODO elasticsearch: index.refresh_interval
** TODO google: six ways to crash elasticsearch
** TODO merge index.merge.scheduler.max_thread_count: 1
https://www.elastic.co/guide/en/elasticsearch/guide/current/indexing-performance.html
** TODO [#A] Blog: Why my ES cluster is slow and unbalanced?
*** DONE Get alerts of ES slow query, and exceptions for log check
   CLOSED: [2017-08-18 Fri 16:23]
*** DONE Monitor shard size, especially big shards. And enough replica
   CLOSED: [2017-08-18 Fri 16:24]
*** TODO How we can collect history data
*** TODO Nagios: get alerts for machine CPU is much higher
*** #  --8<-------------------------- separator ------------------------>8--
*** shards are not balanced: shard count
*** heap size: use more memory: heap.percent
root@bematech-do-es-19:/etc/nagios/nrpe.d# curl $es_ip:9200/_cat/nodes?v | grep -v app-
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  1980  100  1980    0     0    215      0  0:00:09  0:00:09 --:--:--   495
host            ip              heap.percent ram.percent load node.role master name
165.227.25.149  165.227.25.149            59          99 0.61 d         m      bematech-do-es-18.localdomain
138.68.50.117   138.68.50.117             67          99 2.23 d         m      bematech-do-es-02.localdomain
165.227.21.128  165.227.21.128            57          97 0.80 d         m      bematech-do-es-07.localdomain
165.227.27.184  165.227.27.184            63          99 3.07 d         m      bematech-do-es-13.localdomain
165.227.21.77   165.227.21.77             69          99 1.97 d         m      bematech-do-es-06.localdomain
138.197.221.161 138.197.221.161           71          83 0.61 d         m      bematech-do-es-11.localdomain
138.68.30.61    138.68.30.61              57          99 5.63 d         m      bematech-do-es-08.localdomain
138.197.200.214 138.197.200.214           67          87 0.41 d         m      bematech-do-es-12.localdomain
138.68.46.170   138.68.46.170             64          99 0.42 d         m      bematech-do-es-05.localdomain
165.227.5.192   165.227.5.192             52          89 0.82 d         m      bematech-do-es-03.localdomain
138.197.221.191 138.197.221.191           62          95 0.26 d         m      bematech-do-es-10.localdomain
138.197.194.166 138.197.194.166           66          99 0.75 d         m      bematech-do-es-09.localdomain
138.197.205.85  138.197.205.85            59          99 0.57 d         m      bematech-do-es-19.localdomain
138.197.215.132 138.197.215.132           66          99 0.99 d         *      bematech-do-es-01.localdomain
165.227.17.43   165.227.17.43             61          83 1.34 d         m      bematech-do-es-04.localdomain
*** #  --8<-------------------------- separator ------------------------>8--
*** TODO Missing Data visualization for how DB grows
*** TODO Better On top of slowness
*** TODO How force-merge impact our elasticsearch performance
*** #  --8<-------------------------- separator ------------------------>8--
*** TODO [#A] avoid heavily-weight query: system will burn out
*** TODO [#A] noisy tenants issue SLA
*** TODO [#A] small shards, noisy tenants: 2 ES-cluster, rehearsal for DB management
** TODO elasticsearch k8s cluster: fail to start
#+BEGIN_EXAMPLE
[2017-12-08 04:56:55,307][INFO ][discovery                ] [Bird-Brain] myesdb/Fd4kjjaKTsWPBPVFoFlFsQ
[2017-12-08 04:56:57,011][WARN ][io.fabric8.elasticsearch.discovery.k8s.K8sUnicastHostsProvider] [Bird-Brain] Exception caught during discovery javax.ws.rs.WebApplicationException : HTTP 404 endpoints "elasticsearch-discovery" not found
javax.ws.rs.WebApplicationException: HTTP 404 endpoints "elasticsearch-discovery" not found
        at io.fabric8.kubernetes.api.ExceptionResponseMapper.fromResponse(ExceptionResponseMapper.java:25)
        at io.fabric8.kubernetes.api.ExceptionResponseMapper.fromResponse(ExceptionResponseMapper.java:16)
        at org.apache.cxf.jaxrs.client.ClientProxyImpl.checkResponse(ClientProxyImpl.java:302)
        at org.apache.cxf.jaxrs.client.ClientProxyImpl.handleResponse(ClientProxyImpl.java:725)
        at org.apache.cxf.jaxrs.client.ClientProxyImpl.doChainedInvocation(ClientProxyImpl.java:683)
        at org.apache.cxf.jaxrs.client.ClientProxyImpl.invoke(ClientProxyImpl.java:224)
        at com.sun.proxy.$Proxy29.endpointsForService(Unknown Source)
        at io.fabric8.elasticsearch.discovery.k8s.K8sUnicastHostsProvider.getNodesFromKubernetesSelector(K8sUnicastHostsProvider.java:123)
        at io.fabric8.elasticsearch.discovery.k8s.K8sUnicastHostsProvider.buildDynamicNodes(K8sUnicastHostsProvider.java:106)
        at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:313)
        at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:219)
        at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:146)
        at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:124)
        at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:1007)
        at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:361)
        at org.elasticsearch.discovery.zen.ZenDiscovery.access$6100(ZenDiscovery.java:86)
        at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1384)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
[2017-12-08 04:56:58,559][WARN ][io.fabric8.elasticsearch.discovery.k8s.K8sUnicastHostsProvider] [Bird-Brain] Exception caught during discovery javax.ws.rs.WebApplicationException : HTTP 404 endpoints "elasticse
arch-discovery" not found
javax.ws.rs.WebApplicationException: HTTP 404 endpoints "elasticsearch-discovery" not found
        at io.fabric8.kubernetes.api.ExceptionResponseMapper.fromResponse(ExceptionResponseMapper.java:25)
        at io.fabric8.kubernetes.api.ExceptionResponseMapper.fromResponse(ExceptionResponseMapper.java:16)
        at org.apache.cxf.jaxrs.client.ClientProxyImpl.checkResponse(ClientProxyImpl.java:302)
        at org.apache.cxf.jaxrs.client.ClientProxyImpl.handleResponse(ClientProxyImpl.java:725)
        at org.apache.cxf.jaxrs.client.ClientProxyImpl.doChainedInvocation(ClientProxyImpl.java:683)
        at org.apache.cxf.jaxrs.client.ClientProxyImpl.invoke(ClientProxyImpl.java:224)
        at com.sun.proxy.$Proxy29.endpointsForService(Unknown Source)
        at io.fabric8.elasticsearch.discovery.k8s.K8sUnicastHostsProvider.getNodesFromKubernetesSelector(K8sUnicastHostsProvider.java:123)
        at io.fabric8.elasticsearch.discovery.k8s.K8sUnicastHostsProvider.buildDynamicNodes(K8sUnicastHostsProvider.java:106)
        at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:313)
        at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2.doRun(UnicastZenPing.java:228)
        at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:36)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
#+END_EXAMPLE
** TODO elasticsearch folder /data/log: won't be created
** HALF elasticsearch error
bematech-do-es-16/check_elasticsearch_log is OK
bematech-do-es-07/check_elasticsearch_log is WARNING:
WARNING - (1 warnings) - [staging-index-b7c160f0e0ac11e79f15dec7170128a9-new3][[staging-index-b7c160f0e0ac11e79f15dec7170128a9-new3][6]] EngineClosedException[CurrentState[CLOSED] Closed]
** TODO get elasticsearch pending tasks
#+BEGIN_EXAMPLE
root@bematech-do-es-16:~# curl $es_ip:9200/_cluster/health?pretty
{
  "cluster_name" : "mdm",
  "status" : "red",
  "timed_out" : false,
  "number_of_nodes" : 20,
  "number_of_data_nodes" : 15,
  "active_primary_shards" : 485,
  "active_shards" : 1441,
  "relocating_shards" : 2,
  "initializing_shards" : 4,
  "unassigned_shards" : 8,
  "delayed_unassigned_shards" : 0,
  "number_of_pending_tasks" : 5,
  "number_of_in_flight_fetch" : 0,
  "task_max_waiting_in_queue_millis" : 19809,
  "active_shards_percent_as_number" : 99.17412250516173
}
#+END_EXAMPLE
** TODO elasticsearch cluster is not using disk capacity efficiently
#+BEGIN_EXAMPLE
DevOps-Robot APP [3:46 PM] Only visible to you
OK, got it
On the way


[3:46]
Node count: 36. Total Usage. RAM: 56.04%(536.77gb/957.88gb), Disk: 50.98%(11085.80gb/21747.46gb).

       [couchbase] Node count: 10. RAM: 79.77%(250.64gb/314.20gb), Disk: 75.10%(2364.66gb/3148.78gb).
        [elasticsearch] Node count: 17. RAM: 44.16%(235.90gb/534.14gb), Disk: 46.71%(6545.10gb/14012.95gb).
        [elasticsearch_audit] Node count: 1. RAM: 50.48%(7.91gb/15.67gb), Disk: 24.55%(38.64gb/157.37gb).
        [mdmui] Node count: 2. RAM: 42.47%(13.31gb/31.34gb), Disk: 29.10%(91.58gb/314.74gb).
        [mdmworker] Node count: 3. RAM: 58.09%(27.31gb/47.01gb), Disk: 45.27%(436.59gb/964.32gb).
Host: bematech-do-app-1
IP Address: 138.68.41.110.
RAM Usage: 41.80%(6.55gb/15.67gb).
Disk Usage: / 31.48%(49.54gb/157.37gb).
CPU load: 0.07 0.10 0.09 3/556 3443.

Host: bematech-do-app-2
IP Address: 138.68.241.113.
RAM Usage: 43.14%(6.76gb/15.67gb).
Disk Usage: / 26.71%(42.04gb/157.37gb).
CPU load: 0.13 0.19 0.26 2/579 22155.

Host: bematech-do-app-3
IP Address: 138.68.241.116.
RAM Usage: 49.39%(7.74gb/15.67gb).
Disk Usage: / 25.06%(39.44gb/157.37gb).
CPU load: 0.23 0.66 0.91 1/925 22271.

Host: bematech-do-app-4
IP Address: 138.68.21.61.
RAM Usage: 50.80%(7.96gb/15.67gb).
Disk Usage: / 19.60%(30.87gb/157.46gb).
CPU load: 3.73 3.50 2.60 5/1690 20971.

Host: bematech-do-app-5
IP Address: 138.68.63.208.
RAM Usage: 74.09%(11.61gb/15.67gb).
Disk Usage: / 21.43%(33.75gb/157.46gb), /data2 67.58%(332.53gb/492.03gb).
CPU load: 2.64 1.83 1.52 1/575 20410.

Host: bematech-do-audit-1
IP Address: 138.68.236.218.
RAM Usage: 50.48%(7.91gb/15.67gb).
Disk Usage: / 24.55%(38.64gb/157.37gb).
CPU load: 0.02 0.01 0.00 1/334 3095.

Host: bematech-do-cb-01
IP Address: 165.227.8.194.
RAM Usage: 93.22%(29.29gb/31.42gb).
Disk Usage: / 70.51%(222.02gb/314.87gb).
CPU load: 7.02 5.27 5.64 4/448 10017.

Host: bematech-do-cb-02
IP Address: 138.197.215.93.
RAM Usage: 75.43%(23.70gb/31.42gb).
Disk Usage: / 78.06%(245.80gb/314.87gb).
CPU load: 1.87 1.12 1.04 4/449 19422.

Host: bematech-do-cb-03
IP Address: 165.227.0.146.
RAM Usage: 72.82%(22.88gb/31.42gb).
Disk Usage: / 70.51%(222.03gb/314.87gb).
CPU load: 0.71 0.91 1.01 5/444 489.

Host: bematech-do-cb-04
IP Address: 165.227.8.77.
RAM Usage: 73.27%(23.02gb/31.42gb).
Disk Usage: / 77.12%(242.84gb/314.87gb).
CPU load: 1.26 1.02 0.87 1/447 848.

Host: bematech-do-cb-05
IP Address: 165.227.8.192.
RAM Usage: 70.46%(22.14gb/31.42gb).
Disk Usage: / 71.64%(225.58gb/314.87gb).
CPU load: 1.57 1.56 1.49 2/433 27105.

Host: bematech-do-cb-06
IP Address: 165.227.0.173.
RAM Usage: 74.19%(23.31gb/31.42gb).
Disk Usage: / 81.24%(255.81gb/314.87gb).
CPU load: 5.05 4.27 4.09 1/454 8615.

Host: bematech-do-cb-07
IP Address: 165.227.8.188.
RAM Usage: 94.88%(29.81gb/31.42gb).
Disk Usage: / 69.70%(219.47gb/314.87gb).
CPU load: 2.50 2.95 2.97 2/452 7805.

Host: bematech-do-cb-08
IP Address: 165.227.8.57.
RAM Usage: 94.81%(29.79gb/31.42gb).
Disk Usage: / 75.92%(239.04gb/314.87gb).
CPU load: 4.06 3.59 3.79 4/445 3362.

Host: bematech-do-cb-09
IP Address: 165.227.8.68.
RAM Usage: 73.90%(23.22gb/31.42gb).
Disk Usage: / 78.75%(247.97gb/314.87gb).
CPU load: 2.57 2.15 2.00 9/446 6816.

Host: bematech-do-cb-10
IP Address: 138.68.232.241.
RAM Usage: 74.73%(23.48gb/31.42gb).
Disk Usage: / 77.50%(244.10gb/314.95gb).
CPU load: 0.86 1.19 1.33 2/431 15622.

Host: bematech-do-es-10
IP Address: 138.68.10.163.
RAM Usage: 47.80%(15.02gb/31.42gb).
Disk Usage: / 36.35%(114.47gb/314.87gb), /data/elasticsearch2 45.17%(222.23gb/492.03gb).
CPU load: 3.26 3.16 2.75 3/426 8021.

Host: bematech-do-es-11
IP Address: 138.68.48.175.
RAM Usage: 45.35%(14.25gb/31.42gb).
Disk Usage: / 34.53%(108.71gb/314.87gb), /mnt/es-extra-volume 48.49%(238.59gb/492.03gb).
CPU load: 2.24 2.32 2.29 3/413 1343.

Host: bematech-do-es-12
IP Address: 138.68.234.181.
RAM Usage: 44.21%(13.89gb/31.42gb).
Disk Usage: / 0.96%(3.01gb/314.87gb), /data/elasticsearch2 0.01%(0.07gb/492.03gb).
CPU load: 0.00 0.00 0.00 2/387 13220.

Host: bematech-do-es-13
IP Address: 138.197.221.94.
RAM Usage: 42.33%(13.30gb/31.42gb).
Disk Usage: / 58.00%(182.67gb/314.95gb), /data/elasticsearch2 29.69%(146.06gb/492.03gb).
CPU load: 2.92 3.02 3.18 5/382 12570.

Host: bematech-do-es-14
IP Address: 138.197.202.203.
RAM Usage: 41.60%(13.07gb/31.42gb).
Disk Usage: / 34.75%(109.43gb/314.95gb), /data/elasticsearch2 51.45%(253.14gb/492.03gb).
CPU load: 2.75 2.85 2.93 3/386 20841.

Host: bematech-do-es-15
IP Address: 138.197.218.77.
RAM Usage: 41.34%(12.99gb/31.42gb).
Disk Usage: / 67.22%(211.71gb/314.95gb), /data/elasticsearch2 66.38%(326.61gb/492.03gb).
CPU load: 12.67 12.40 11.91 5/385 29462.

Host: bematech-do-es-16
IP Address: 165.227.25.58.
RAM Usage: 37.62%(11.82gb/31.42gb).
Disk Usage: / 69.40%(218.57gb/314.95gb), /data/elasticsearch2 62.45%(307.29gb/492.03gb).
CPU load: 1.88 1.92 1.88 3/379 9081.

Host: bematech-do-es-17
IP Address: 165.227.21.253.
RAM Usage: 38.13%(11.98gb/31.42gb).
Disk Usage: / 78.69%(247.82gb/314.95gb), /data/elasticsearch2 81.77%(402.35gb/492.03gb).
CPU load: 1.77 1.96 2.13 3/382 3733.

Host: bematech-do-es-18
IP Address: 165.227.25.149.
RAM Usage: 39.82%(12.51gb/31.42gb).
Disk Usage: / 82.45%(259.67gb/314.95gb), /data/elasticsearch2 64.65%(445.37gb/688.89gb).
CPU load: 11.88 17.23 15.65 10/378 13409.

Host: bematech-do-es-2
IP Address: 138.68.247.36.
RAM Usage: 49.33%(15.50gb/31.42gb).
Disk Usage: / 42.32%(133.25gb/314.87gb), /mnt/es-extra-volume 42.98%(211.45gb/492.03gb), /usr/share/elasticsearch/repo 65.79%(64.68gb/98.31gb).
CPU load: 1.68 2.29 2.53 2/439 18561.

Host: bematech-do-es-3
IP Address: 138.68.61.4.
RAM Usage: 44.94%(14.12gb/31.42gb).
Disk Usage: / 34.71%(109.28gb/314.87gb), /data/elasticsearch2 46.40%(228.28gb/492.03gb).
CPU load: 8.28 7.32 7.06 12/413 28946.

Host: bematech-do-es-4
IP Address: 138.68.239.172.
RAM Usage: 46.82%(14.71gb/31.42gb).
Disk Usage: / 36.12%(113.73gb/314.87gb), /mnt/es-extra-volume 42.89%(211.05gb/492.03gb).
CPU load: 4.07 3.92 3.66 3/414 8946.

Host: bematech-do-es-5
IP Address: 138.68.224.86.
RAM Usage: 43.89%(13.79gb/31.42gb).
Disk Usage: / 45.66%(143.78gb/314.87gb), /mnt/es-extra-volume 38.62%(190.02gb/492.03gb).
CPU load: 5.75 2.66 2.24 2/412 10509.

Host: bematech-do-es-6
IP Address: 138.197.217.22.
RAM Usage: 47.14%(14.81gb/31.42gb).
Disk Usage: / 37.62%(118.45gb/314.87gb), /mnt/es-extra-volume 43.21%(212.60gb/492.03gb).
CPU load: 2.36 2.10 2.25 3/410 14923.

Host: bematech-do-es-7
IP Address: 138.197.208.58.
RAM Usage: 46.56%(14.63gb/31.42gb).
Disk Usage: / 36.40%(114.60gb/314.87gb), /data/elasticsearch2 44.72%(220.06gb/492.03gb).
CPU load: 3.49 3.19 2.91 2/431 31901.

Host: bematech-do-es-8
IP Address: 138.197.194.166.
RAM Usage: 47.87%(15.04gb/31.42gb).
Disk Usage: / 33.67%(106.02gb/314.87gb), /mnt/es-extra-volume 44.61%(219.47gb/492.03gb).
CPU load: 1.22 1.78 1.87 2/411 22248.

Host: bematech-do-es-9
IP Address: 138.197.199.94.
RAM Usage: 46.05%(14.47gb/31.42gb).
Disk Usage: / 15.94%(50.18gb/314.87gb), /mnt/es-extra-volume 61.06%(300.42gb/492.03gb).
CPU load: 2.40 2.51 2.39 3/413 3987.

Host: bematech-do-jenkins
IP Address: 138.197.192.172.
RAM Usage: 18.46%(1.44gb/7.80gb).
Disk Usage: / 6.91%(5.43gb/78.62gb), /opt/couchbase 54.14%(1598.55gb/2952.80gb).
CPU load: 0.08 0.03 0.01 1/326 18673.

Host: bematech-do-lb-1
IP Address: 138.68.254.56.
RAM Usage: 3.11%(0.12gb/3.86gb).
Disk Usage: / 4.46%(2.63gb/58.94gb).
CPU load: 0.05 0.03 0.00 1/136 12737.

Host: bematech-do-lb-2
IP Address: 138.68.254.215.
RAM Usage: 3.63%(0.14gb/3.86gb).
Disk Usage: / 4.45%(2.62gb/58.94gb).
CPU load: 0.00 0.00 0.00 2/136 19983.
#+END_EXAMPLE
** TODO Running an Elasticsearch cluster with Docker: https://stefanprodan.com//2016/elasticsearch-cluster-with-docker/
** TODO elasticsearch: node.max_local_storage_nodes: 1
** TODO get how many shards each Elasticsearch node has
** TODO es master: why list nodes api is inconsistent               :noexport:
** TODO elasticsearch master: can deploy only one instancer in one vm :noexport:
** TODO es log file: bin/elasticsearch -Epath.data=data1 -Epath.logs=log1
** TODO install es shard
** TODO understand es node api
root@prod-es-16:/data/elasticsearch# curl $es_ip:9200/_cat/nodes?v | grep "es-"
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  2280  100  2280    0     0   1805      0  0:00:01  0:00:01 --:--:--  1806
198.199.95.111  198.199.95.111            68          88 3.57 d         m      prod-es-9
159.203.219.53  159.203.219.53            72          85 1.44 d         m      prod-es-4
107.170.218.112 107.170.218.112            3          86 0.91 d         m      prod-es-17
107.170.253.222 107.170.253.222           56          87 0.07 d         m      prod-es-15
104.236.187.173 104.236.187.173           72          99 3.22 d         m      prod-es-10
159.203.216.25  159.203.216.25            40          98 1.25 d         m      prod-es-1
192.241.211.99  192.241.211.99            56          99 3.60 d         m      prod-es-3
192.241.206.113 192.241.206.113           66          87 1.97 d         m      prod-es-13
192.241.203.166 192.241.203.166           71          99 0.83 d         m      prod-es-8
107.170.212.76  107.170.212.76            53          97 1.66 d         *      prod-es-2
107.170.237.239 107.170.237.239           55          98 2.82 d         m      prod-es-7
192.241.228.149 192.241.228.149           29          99 1.75 d         m      prod-es-12
107.170.216.152 107.170.216.152           45          99 1.51 d         m      prod-es-14
138.68.3.169    138.68.3.169              66          94 1.56 d         m      prod-es-16
107.170.252.123 107.170.252.123           39          95 2.32 d         m      prod-es-11
159.203.192.146 159.203.192.146           44          99 2.40 d         m      prod-es-6
159.203.211.150 159.203.211.150           41          97 1.55 d         m      prod-es-5
** TODO check detail status of es shard initilizing
#+BEGIN_EXAMPLE
root@prod-es-18:/data/elasticsearch# curl $es_ip:9200/_cat/shards?v | grep -v STARTED
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0index                                          shard prirep state             docs   store ip              node
master-index-abae8b30ac9b11e692000401f8d88101  3     r      INITIALIZING                   107.170.223.238 prod-es-18
100 52360  100 52360    0     0  18517      0  0:00:02  0:00:02 --:--:-- 18514
root@prod-es-16:/data/elasticsearch#
Every 2.0s: df -h /                                     Tue Jan 10 21:13:06 2017

Filesystem      Size  Used Avail Use% Mounted on
/dev/vda1       315G  117G  186G  39% /
#+END_EXAMPLE
** TODO [#A] why disk of es nodes drops?
es-2, es-5, es-6, es-8 running into almost no disk.

Any tips to check why this is happening? I don't see shards relocating to them.

So what action cause their disk capacities drop dramatically?

new messages
Kung Wang [6:59 PM]
don't know yet, let's investigate. let me check es-5

denny zhang [7:27 PM]
Checked all es nodes whose free disk is under 5%.

They all hold shards of *-index-8cd6e43115e9416eb23609486fa053e3 indices.

If we check current shards list for those nodes, the shard is not found.
http://prodjenkins.fluigdata.com:18080/job/RunCommandOnServers/190/console

Take es-5 for example

> root@prod-es-5:~# ls -lth /usr/share/elasticsearch/mdm/nodes/0/indices | grep abae8b30ac9b11e692000401f8d88101
> drwxr-xr-x 4 elasticsearch elasticsearch 4.0K Dec  8 20:52 staging-index-abae8b30ac9b11e692000401f8d88101
> drwxr-xr-x 4 elasticsearch elasticsearch 4.0K Dec  6 21:10 master-index-abae8b30ac9b11e692000401f8d88101
> root@prod-es-5:~# curl 159.203.211.150:9200/_cat/shards?v | grep es-5 | grep abae8b30ac9b11e692000401f8d88101

Looks like es-cluster is waiting other nodes to take the ownership for old shard of es-5.

When it's ready in other nodes, it will remove this directory in es-5 and reclaim the disk.

** TODO [#A] DevOps Puzzle: what ES re-index commands fail in the middle?
** TODO [#A] ES OOM issue: why it happened quite suddenly
Denny Zhang [5:16 PM]
One thing I quite don't understand.

We have OS memory check every 5 minutes. Usually ES runs into OOM, but we never get OS memory warning.

So it means ES suddenly reclaim huge block of memory. Then OS kill it.

Any thoughts about this? It was suddenly assigned take a big shard? (edited)

Bruno Volpato [5:16 PM]
good point

[5:16]
or some giant query

[5:17]
if that's the case, the circuit breaker may help

Denny Zhang [5:17 PM]
If shard allocation, it means we mislead ES cluster somehow. -> configuration issue

If giant query, could we limit that at application level? Or send some warning? I understand, if it's hard to achieve.

Just want to understand why.
** TODO index.merge.policy.expunge_deletes_allowed

 Note : there is a index.merge.policy.expunge_deletes_allowed settings in elasticsearch.yml that we can set. The definition of it is:
+When expungeDeletes is called, we only merge away a segment if its delete percentage is over this threshold. Default is 10. If you run the forceMerge and found index size does not change, it maybe contains deletes less than 10% of all documents, that's why nothing is triggered. If we want to make forceMerge always in effect even just one document is deleted, set this to 0. But the impact is, since merge index is indeed creating another segment and dump all segments into new one, it's a costly operation, and if only do for one deleted document, it is not worth it.

** TODO [#A] ES rebalancing doesn't work, after stop one ES instance
*** prod-es-03
[2017-04-02 03:30:04,748][WARN ][discovery.zen.ping.unicast] [prod-es-03] failed to send ping to [{prod-es-18}{5psmoEaSRBaGpIzDdJQlLw}{138.197.217.98}{138.197.217.98:9300}{max_local_storage_nodes=1}]
RemoteTransportException[[prod-es-18][138.197.217.98:9300][internal:discovery/zen/unicast]]; nested: IllegalStateException[received ping request while not started];
Caused by: java.lang.IllegalStateException: received ping request while not started
        at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.handlePingRequest(UnicastZenPing.java:497)
        at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.access$2400(UnicastZenPing.java:83)
        at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$UnicastPingRequestHandler.messageReceived(UnicastZenPing.java:522)
        at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$UnicastPingRequestHandler.messageReceived(UnicastZenPing.java:518)
        at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
        at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:75)
        at org.elasticsearch.transport.netty.MessageChannelHandler.handleRequest(MessageChannelHandler.java:245)
        at org.elasticsearch.transport.netty.MessageChannelHandler.messageReceived(MessageChannelHandler.java:114)
        at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)
        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
        at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
        at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296)
        at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:462)
        at org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:443)
        at org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:303)
        at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)
        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
        at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
        at org.elasticsearch.common.netty.OpenChannelsHandler.handleUpstream(OpenChannelsHandler.java:75)
        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)
        at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268)
        at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)
        at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)
        at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)
        at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
        at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)
        at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)
        at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
        at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
[2017-04-02 03:30:10,437][INFO ][cluster.service          ] [prod-es-03] detected_master {prod-es-02}{AZBG5fD4SuujYUu2yUMczA}{138.68.5.55}{138.68.5.55:9300}{max_local_storage_nodes=1}, reason: zen-disco-receive(from master [{prod-es-02}{AZBG5fD4SuujYUu2yUMczA}{138.68.5.55}{138.68.5.55:9300}{max_local_storage_nodes=1}])
*** prod-es-02
[2017-04-02 03:30:08,693][INFO ][discovery.zen            ] [prod-es-02] master_left [{prod-es-18}{5psmoEaSRBaGpIzDdJQlLw}{138.197.217.98}{138.197.217.98:9300}{max_local_storage_nodes=1}], reason [shut_down]
[2017-04-02 03:30:08,707][WARN ][discovery.zen            ] [prod-es-02] master left (reason = shut_down), current nodes: {{prod-app-02node}{FHFCb2DoQiWGdLy4VdHV3g}{138.197.199.11}{138.197.199.11:9301}{data=false, master=false},{prod-app-01node}{lAnQcfbvQFK8JDfpad9Hag}{138.197.193.53}{138.197.193.53:9301}{data=false, master=false},{prod-es-03}{VZpcSkTzSTmHx62iKnj_rw}{138.68.41.211}{138.68.41.211:9300}{max_local_storage_nodes=1},{prod-app-03node}{OiDJ_MOhTwmh_IL0BCzXQQ}{138.197.199.169}{138.197.199.169:9301}{data=false, master=false},{prod-es-02}{AZBG5fD4SuujYUu2yUMczA}{138.68.5.55}{prod-es-02/138.68.5.55:9300}{max_local_storage_nodes=1},{prod-es-16}{ocu0P8FuS2WWgac62fHdbw}{138.68.3.169}{138.68.3.169:9300}{max_local_storage_nodes=1},{prod-es-01}{gD732uP8SaOnI9JhOGpR0w}{138.68.250.138}{138.68.250.138:9300}{max_local_storage_nodes=1},{prod-es-17}{Oq5EDwVBRMOpnyEMFxNblQ}{138.197.216.23}{138.197.216.23:9300}{max_local_storage_nodes=1},}
[2017-04-02 03:30:08,734][INFO ][cluster.service          ] [prod-es-02] removed {{prod-es-18}{5psmoEaSRBaGpIzDdJQlLw}{138.197.217.98}{138.197.217.98:9300}{max_local_storage_nodes=1},}, reason: zen-disco-master_failed ({prod-es-18}{5psmoEaSRBaGpIzDdJQlLw}{138.197.217.98}{138.197.217.98:9300}{max_local_storage_nodes=1})
[2017-04-02 03:30:14,356][INFO ][cluster.routing.allocation] [prod-es-02] Cluster health status changed from [GREEN] to [YELLOW] (reason: [nodes joined]).
[2017-04-02 03:30:14,399][INFO ][cluster.service          ] [prod-es-02] new_master {prod-es-02}{AZBG5fD4SuujYUu2yUMczA}{138.68.5.55}{prod-es-02/138.68.5.55:9300}{max_local_storage_nodes=1}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2017-04-02 03:30:14,570][DEBUG][action.admin.indices.alias.get] [prod-es-02] no known master node, scheduling a retry
[2017-04-02 03:30:14,570][DEBUG][action.admin.indices.alias.get] [prod-es-02] no known master node, scheduling a retry
[2017-04-02 03:30:14,648][DEBUG][action.admin.indices.alias.get] [prod-es-02] no known master node, scheduling a retry
[2017-04-02 03:30:14,650][DEBUG][action.admin.indices.alias.get] [prod-es-02] no known master node, scheduling a retry
[2017-04-02 03:30:14,735][DEBUG][action.admin.indices.alias.get] [prod-es-02] no known master node, scheduling a retry
[2017-04-02 03:30:15,040][DEBUG][action.admin.indices.alias.get] [prod-es-02] no known master node, scheduling a retry
[2017-04-02 03:30:15,040][DEBUG][action.admin.indices.alias.get] [prod-es-02] no known master node, scheduling a retry
[2017-04-02 03:30:15,042][DEBUG][action.admin.indices.alias.get] [prod-es-02] no known master node, scheduling a retry
[2017-04-02 03:30:15,131][DEBUG][action.admin.cluster.health] [prod-es-02] no known master node, scheduling a retry
[2017-04-02 03:30:16,047][DEBUG][action.admin.cluster.state] [prod-es-02] no known master node, scheduling a retry
[2017-04-02 03:30:16,123][DEBUG][action.admin.indices.alias.get] [prod-es-02] no known master node, scheduling a retry
[2017-04-02 03:30:16,125][DEBUG][action.admin.indices.alias.get] [prod-es-02] no known master node, scheduling a retry
[2017-04-02 03:30:19,334][INFO ][cluster.routing          ] [prod-es-02] delaying allocation for [125] unassigned shards, next check in [1m]
*** prod-es-01
[2017-04-02 03:30:08,149][INFO ][discovery.zen            ] [prod-es-01] master_left [{prod-es-18}{5psmoEaSRBaGpIzDdJQlLw}{138.197.217.98}{138.197.217.98:9300}{max_local_storage_nodes=1}], reason [transport disconnected]
[2017-04-02 03:30:08,149][DEBUG][action.admin.indices.stats] [prod-es-01] failed to execute [indices:monitor/stats] on node [5psmoEaSRBaGpIzDdJQlLw]
NodeDisconnectedException[[prod-es-18][138.197.217.98:9300][indices:monitor/stats[n]] disconnected]
[2017-04-02 03:30:08,156][WARN ][discovery.zen            ] [prod-es-01] master left (reason = transport disconnected), current nodes: {{prod-es-03}{VZpcSkTzSTmHx62iKnj_rw}{138.68.41.211}{138.68.41.211:9300}{max_local_storage_nodes=1},{prod-app-01node}{lAnQcfbvQFK8JDfpad9Hag}{138.197.193.53}{138.197.193.53:9301}{data=false, master=false},{prod-es-16}{ocu0P8FuS2WWgac62fHdbw}{138.68.3.169}{138.68.3.169:9300}{max_local_storage_nodes=1},{prod-app-03node}{OiDJ_MOhTwmh_IL0BCzXQQ}{138.197.199.169}{138.197.199.169:9301}{data=false, master=false},{prod-es-01}{gD732uP8SaOnI9JhOGpR0w}{138.68.250.138}{prod-es-01/138.68.250.138:9300}{max_local_storage_nodes=1},{prod-es-17}{Oq5EDwVBRMOpnyEMFxNblQ}{138.197.216.23}{138.197.216.23:9300}{max_local_storage_nodes=1},{prod-app-02node}{FHFCb2DoQiWGdLy4VdHV3g}{138.197.199.11}{138.197.199.11:9301}{data=false, master=false},{prod-es-02}{AZBG5fD4SuujYUu2yUMczA}{138.68.5.55}{138.68.5.55:9300}{max_local_storage_nodes=1},}
[2017-04-02 03:30:08,160][INFO ][cluster.service          ] [prod-es-01] removed {{prod-es-18}{5psmoEaSRBaGpIzDdJQlLw}{138.197.217.98}{138.197.217.98:9300}{max_local_storage_nodes=1},}, reason: zen-disco-master_failed ({prod-es-18}{5psmoEaSRBaGpIzDdJQlLw}{138.197.217.98}{138.197.217.98:9300}{max_local_storage_nodes=1})
[2017-04-02 03:30:11,780][DEBUG][action.admin.cluster.state] [prod-es-01] no known master node, scheduling a retry
[2017-04-02 03:30:13,852][INFO ][cluster.service          ] [prod-es-01] detected_master {prod-es-02}{AZBG5fD4SuujYUu2yUMczA}{138.68.5.55}{138.68.5.55:9300}{max_local_storage_nodes=1}, reason: zen-disco-receive(from master [{prod-es-02}{AZBG5fD4SuujYUu2yUMczA}{138.68.5.55}{138.68.5.55:9300}{max_local_storage_nodes=1}])
[2017-04-02 03:30:13,871][DEBUG][action.index             ] [prod-es-01] failed to execute [index {[master-8a18aa800e5911e785f24a8136534b63][mdmlogregistrationGolden][abf659f0175411e7ab0026b7a582476b], source[{"mdmEntityTemplateId":"704b0600108111e785f24a8136534b63","mdmGoldenFieldAndValues":{"subsidiary":"SUBSIDIARY HABILITATION ID","classdisciplineid":"20336","registrationstatus":"37","mdmeventdate":"2008-08-04","studentkey":"STUDENT KEY","logregistrationid":"2163977","studentid":"RA00030819"},"mdmGoldenFieldDetails":{"logregistrationid":{"mdmSurvivorshipRuleName":"RECENCY","mdmSurvivedApplicationMasterRecordId":{"8aa40a5010b911e785f24a8136534b63":["abc7f6f0175411e7ab0026b7a582476b"]}},"mdmeventdate":{"mdmSurvivorshipRuleName":"RECENCY","mdmSurvivedApplicationMasterRecordId":{"8aa40a5010b911e785f24a8136534b63":["abc7f6f0175411e7ab0026b7a582476b"]}},"registrationstatus":{"mdmSurvivorshipRuleName":"RECENCY","mdmSurvivedApplicationMasterRecordId":{"8aa40a5010b911e785f24a8136534b63":["abc7f6f0175411e7ab0026b7a582476b"]}},"studentid":{"mdmSurvivorshipRuleName":"RECENCY","mdmSurvivedApplicationMasterRecordId":{"8aa40a5010b911e785f24a8136534b63":["abc7f6f0175411e7ab0026b7a582476b"]}},"studentkey":{"mdmSurvivorshipRuleName":"RECENCY","mdmSurvivedApplicationMasterRecordId":{"8aa40a5010b911e785f24a8136534b63":["abc7f6f0175411e7ab0026b7a582476b"]}},"subsidiary":{"mdmSurvivorshipRuleName":"RECENCY","mdmSurvivedApplicationMasterRecordId":{"8aa40a5010b911e785f24a8136534b63":["abc7f6f0175411e7ab0026b7a582476b"]}},"classdisciplineid":{"mdmSurvivorshipRuleName":"RECENCY","mdmSurvivedApplicationMasterRecordId":{"8aa40a5010b911e785f24a8136534b63":["abc7f6f0175411e7ab0026b7a582476b"]}}},"mdmApplicationIdMasterRecordId":{"8aa40a5010b911e785f24a8136534b63":["abc7f6f0175411e7ab0026b7a582476b"]},"mdmApplicationIdMasterRecord":{},"mdmApplicationIdStagingTypeMasterRecordId":{"8aa40a5010b911e785f24a8136534b63_slogmatricula":["abc7f6f0175411e7ab0026b7a582476b"]},"mdmMasterCount":1.0,"mdmMergePending":false,"mdmRelationshipPending":false,"mdmFlaggedFieldIds":[],"mdmErrors":[],"mdmCrosswalk":[{"mdmApplicationId":"8aa40a5010b911e785f24a8136534b63","mdmCrossreference":{"SLOGMATRICULA":{"IDTURMADISC":"20336","CODCOLIGADA":"1","IDLOGMATRICULA":"2163977","RA":"RA00030819"}}}],"mdmPreviousIds":[],"mdmCounterForEntity":519884.0,"mdmId":"abf659f0175411e7ab0026b7a582476b","mdmEntityType":"mdmlogregistrationGolden","mdmCreated":"2017-04-02T03:30:08.782Z","mdmLastUpdated":"2017-04-02T03:30:08.785Z","mdmTenantId":"8a18aa800e5911e785f24a8136534b63"}]}] on [[master-index-8a18aa800e5911e785f24a8136534b63][2]]
[master-index-8a18aa800e5911e785f24a8136534b63][[master-index-8a18aa800e5911e785f24a8136534b63][2]] IllegalIndexShardStateException[CurrentState[STARTED] shard is not a primary]
        at org.elasticsearch.index.shard.IndexShard.prepareIndexOnPrimary(IndexShard.java:557)
        at org.elasticsearch.action.index.TransportIndexAction.prepareIndexOperationOnPrimary(TransportIndexAction.java:212)
        at org.elasticsearch.action.index.TransportIndexAction.executeIndexRequestOnPrimary(TransportIndexAction.java:224)
        at org.elasticsearch.action.index.TransportIndexAction.shardOperationOnPrimary(TransportIndexAction.java:158)
        at org.elasticsearch.action.index.TransportIndexAction.shardOperationOnPrimary(TransportIndexAction.java:66)
        at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.doRun(TransportReplicationAction.java:639)
        at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
        at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:279)
        at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:271)
        at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:75)
        at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:376)
        at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
*** prod-es-16
[2017-04-02 04:00:13,844][DEBUG][action.search            ] [prod-es-16] [staging-index-8cd6e43115e9416eb23609486fa053e3-new2][18], node[VZpcSkTzSTmHx62iKnj_rw], [R], v[4], s[STARTED], a[id=s2-8V-86QM2IHN3JGIpWVg]: Failed to execute [org.elasticsearch.action.search.SearchRequest@1e19cf2d]
RemoteTransportException[[prod-es-03][138.68.41.211:9300][indices:data/read/search[phase/query]]]; nested: SearchParseException[failed to parse search source [{"size":0,"query":{"bool":{"must":[{"match":{"mdmTenantId.raw":"41d17930c8e211e6aae30401f8d88101"}},{"nested":{"path":"mdmGoldenFieldAndValues.mdmaddress","query":{"bool":{"must_not":{"exists":{"field":"mdmGoldenFieldAndValues.mdmaddress.mdmcoordinates"}}}}}}]}},"aggs":{"grades_count":{"value_count":{"field":"mdmEntityType.raw"}}}}]]; nested: QueryParsingException[[nested] failed to find nested object under path [mdmGoldenFieldAndValues.mdmaddress]];
Caused by: SearchParseException[failed to parse search source [{"size":0,"query":{"bool":{"must":[{"match":{"mdmTenantId.raw":"41d17930c8e211e6aae30401f8d88101"}},{"nested":{"path":"mdmGoldenFieldAndValues.mdmaddress","query":{"bool":{"must_not":{"exists":{"field":"mdmGoldenFieldAndValues.mdmaddress.mdmcoordinates"}}}}}}]}},"aggs":{"grades_count":{"value_count":{"field":"mdmEntityType.raw"}}}}]]; nested: QueryParsingException[[nested] failed to find nested object under path [mdmGoldenFieldAndValues.mdmaddress]];
        at org.elasticsearch.search.SearchService.parseSource(SearchService.java:855)
        at org.elasticsearch.search.SearchService.createContext(SearchService.java:654)
        at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:620)
        at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:371)
        at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)
        at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)
        at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
        at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:75)
        at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.doRun(MessageChannelHandler.java:300)
        at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: [staging-index-8cd6e43115e9416eb23609486fa053e3-new2] QueryParsingException[[nested] failed to find nested object under path [mdmGoldenFieldAndValues.mdmaddress]]
        at org.elasticsearch.index.query.support.NestedInnerQueryParseSupport.setPath(NestedInnerQueryParseSupport.java:159)
        at org.elasticsearch.index.query.NestedQueryParser.parse(NestedQueryParser.java:82)
        at org.elasticsearch.index.query.QueryParseContext.parseInnerQuery(QueryParseContext.java:250)
        at org.elasticsearch.index.query.BoolQueryParser.parse(BoolQueryParser.java:110)
        at org.elasticsearch.index.query.QueryParseContext.parseInnerQuery(QueryParseContext.java:250)
        at org.elasticsearch.index.query.IndexQueryParserService.innerParse(IndexQueryParserService.java:320)
        at org.elasticsearch.index.query.IndexQueryParserService.parse(IndexQueryParserService.java:223)
        at org.elasticsearch.index.query.IndexQueryParserService.parse(IndexQueryParserService.java:218)
        at org.elasticsearch.search.query.QueryParseElement.parse(QueryParseElement.java:33)
        at org.elasticsearch.search.SearchService.parseSource(SearchService.java:838)
        ... 12 more
** TODO Avoid giant ES index
Kung Wang [4:16 PM]
@denny.zhang , there is a query people said it's very slow. but when I look into, the query is not fancy, just the data size a little large.

```curl -XPOST http://localhost:19200/staging-8a18aa800e5911e785f24a8136534b63/_search -d '{
  "size": 0,
  "query": {
    "match_all": {}
  },
  "aggs": {
    "tenant": {
      "terms": {
        "field": "_type",
        "size": 100
      }
    }
  }
}'
```

Denny Zhang [4:17 PM]
Thanks for the information.

Anything I can do about this?

Kung Wang [4:17 PM]
so, we are thinking:

curl -XGET http://localhost:19200/_cat/shards/staging-index-8a18aa800e5911e785f24a8136534b63 | grep " p "

if we can shard it to 10 shards, will it speed up? (edited)

Denny Zhang [4:18 PM]
Frankly speaking, I have doubt on that.

If the query need to scan all data, all shards will need to be proceeded. Right?

Kung Wang [4:18 PM]
or shard it to 20 shards.

[4:19]
yes, but we have 8 machines, but only 5 primary shards, so 3 machines can not help

Denny Zhang [4:19 PM]
Agree, that won't help.

[4:20]
If we have more shards, it will spread out to more machines.

So more machines will be able to provide the scan.

Thus it will speed up.

Kung Wang [4:20 PM]
yes, that's why we have this hypothesis.

[4:20]
if we can shard it more, then other machines can help

Denny Zhang [4:21 PM]
Apparently we all agree to avoid giant shards, but what about giant indices?

Do we need to re-think whether we can avoid GIANT indices?

Kung Wang [4:22 PM]
well, that we may not be able to avoid.

Denny Zhang [4:22 PM]
Then could we make some draft estimation for the maximum size to support?

new messages
Kung Wang [4:24 PM]
it is ok, we can talk on this later
** TODO How to get the progress of ES snapshot creating
** TODO ES shard initializing: how to check deeper; how much more time it would took
Every 2.0s: curl 138.197.217.98:9200/_cat/shards?v | grep master-index-8cd6e43115e9416eb23609486fa053e3          Tue Apr 11 21:58:25 2017

  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
   0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0   0     0    0     0    0     0      0      0 --:--:-- --
:--:-- --:--:--     0 100 57096  100 57096    0     0  74070      0 --:--:-- --:--:-- --:--:-- 74054
master-index-8cd6e43115e9416eb23609486fa053e3       2     r      INITIALIZING                  138.197.217.98 prod-es-18
master-index-8cd6e43115e9416eb23609486fa053e3       2     p      STARTED       8681935   6.5gb 138.68.250.138 prod-es-01
master-index-8cd6e43115e9416eb23609486fa053e3       2     r      INITIALIZING                  138.68.3.169   prod-es-16
master-index-8cd6e43115e9416eb23609486fa053e3       4     r      STARTED       8704452   6.4gb 138.197.217.98 prod-es-18
master-index-8cd6e43115e9416eb23609486fa053e3       4     p      STARTED       8704452   6.4gb 138.68.250.138 prod-es-01
master-index-8cd6e43115e9416eb23609486fa053e3       4     r      STARTED       8704452   6.4gb 138.68.41.211  prod-es-03
master-index-8cd6e43115e9416eb23609486fa053e3       3     p      STARTED       8697156   5.5gb 138.197.217.98 prod-es-18
master-index-8cd6e43115e9416eb23609486fa053e3       3     r      STARTED       8697156   5.5gb 138.68.3.169   prod-es-16
master-index-8cd6e43115e9416eb23609486fa053e3       3     r      UNASSIGNED
master-index-8cd6e43115e9416eb23609486fa053e3       1     p      STARTED       8685097   5.4gb 138.197.217.98 prod-es-18
master-index-8cd6e43115e9416eb23609486fa053e3       1     r      INITIALIZING                  138.68.5.55    prod-es-02
master-index-8cd6e43115e9416eb23609486fa053e3       1     r      STARTED       8685097   5.4gb 138.68.41.211  prod-es-03
master-index-8cd6e43115e9416eb23609486fa053e3       0     p      STARTED       8681571   6.4gb 138.197.217.98 prod-es-18
master-index-8cd6e43115e9416eb23609486fa053e3       0     r      INITIALIZING                  138.68.5.55    prod-es-02
master-index-8cd6e43115e9416eb23609486fa053e3       0     r      UNASSIGNED


** TODO Use DO private networking for ES cluster
** TODO [#A] DevOps Puzzle: Forget to add ES volume: how to avoid this, or detect this issue earlier?
ls /dev/disk/by-id

export mnt_point=/mnt/es-extra-volume
export volume_label=$(ls /dev/disk/by-id/ | grep Volume)
# TODO: verify volume_label is not empty
sudo mkfs.ext4 -F /dev/disk/by-id/$volume_label

# To mount the volume, copy and paste the text below:
# Create a mount point under /mnt
sudo mkdir -p $mnt_point

# Mount the volume
sudo mount -o discard,defaults /dev/disk/by-id/$volume_label  $mnt_point

# Change fstab so the volume will be mounted after a reboot
echo "/dev/disk/by-id/$volume_label $mnt_point ext4 defaults,nofail,discard 0 0" | sudo tee -a /etc/fstab

cat  /etc/fstab

df -h
# The volume is now accessible at $mnt_point, and you are able to write files and store other data. This data will persist if you detach the volume, and will continue to be available when the volume is reattached to another Droplet. If you want you can customize the commands above, please refer to the following articles:

# create directory
mkdir -p $mnt_point/elasticsearch
chmod 777 $mnt_point/elasticsearch
mkdir -p /data/
ln -s $mnt_point/elasticsearch /data/elasticsearch2
cd /data/elasticsearch2

** TODO [#A] run re-index again: would we missing ES mapping?
https://www.elastic.co/guide/en/elasticsearch/guide/current/reindex.html
If you continue making changes to the old index, you will want to make sure that you include the newly added documents in your new index as well. This can be done by rerunning the reindex process

** TODO [#A] After adding new ES nodes, how fast rebalancing takes
** TODO Get tenant list
Robson Poffo [4:55 PM]
@denny.zhang, @kungwang and @bruno, this URL is down: senarn.carol.ai

[4:55]
I am getting a message: Tenant not found

[4:56]
supposedly, the domain should be senar.carol.ai, but it's not working.

[4:56]
senarn is the tennat name

Robson Poffo [4:57 PM]
uploaded this image: Pasted image at 2017-05-04, 2:57 PM
Add Comment

Denny Zhang
[5:00 PM]
@kungwang any thoughts?
** TODO [#A] Configure es shards per indices on fly
** TODO [#A] ES disk issue: enforce data retention for deleted documents and old version
https://www.elastic.co/blog/lucenes-handling-of-deleted-documents
maybe ES is keeping track of deleted documents/old version, this is why it's using that much storage...

denny zhang [9:01 AM]
Yeah, 2 shards are relocating.

Bruno Volpato [9:01 AM]
uploaded an image: Pasted image at 2016-12-21, 5:01 PM
Add Comment

denny zhang [9:01 AM]
Good point.

[9:02]
Let's see how to enforce proper data retention for ES.
** TODO ES cluster running into GC
es-02:

[2017-07-05 17:38:49,664][WARN ][monitor.jvm              ] [bematech-do-es-2] [gc][old][6069033][17737] duration [31.4s], collections [1]/[31.4s], total [31.4s]/[1.6h], memory [11.9gb]->[11.8gb]/[11.9gb], all_pools {[young] [665.6mb]->[665.6mb]/[665.6mb]}{[survivor] [74mb]->[8.8mb]/[83.1mb]}{[old] [11.1gb]->[11.1gb]/[11.1gb]}

6069038
** TODO [#A] ES replace one node with another one
Bruno Volpato [6:09 PM]
but we should have excluded before adding the new node. or immediately after, because the es-13 is already filled with other stuff (not shards that were on es-12)


Denny Zhang
[6:18 PM]
Bruno, I don't quite get your point.

Once the rebalancing is done, we should be able to shutdown es-12.

About es-13, I think that's how ES cluster balancing data. Better we leave it to ES cluster, right?


Bruno Volpato
[6:27 PM]
I meant, we should've allocated es13 to replace es12


[6:27]
but we added es13 as an additional node, and it got shards from others, not es12


Denny Zhang
[6:30 PM]
We're adding es-14.

ES-13 is an old node


Bruno Volpato
[6:31 PM]
yes that's what I meant :smile:


[6:31]
es-14


[6:31]
the new node


Denny Zhang
[6:31 PM]
I see. you mean literally replace es-12 with es-14
** TODO ES ChatOps
Kung Wang
[12:50 PM]
if shard is unbalanced and has more shards for the data that are processing in that node, can also be slow too (edited)


[12:51]
 ```One node has the majority of primary shards, and will crash as a result
```


Denny Zhang
[12:52 PM]
Thanks. Will update, if I find something


Kung Wang
[12:57 PM]
@denny.zhang , maybe, we can make a bot to check ES performance, I will help listing thing what I see from other people post


Denny Zhang
[1:04 PM]
Definitely, please share me with your magic.

I will integrate them into monitoring system or ChatOps part accordingly.

** TODO monitor: Robson's ES check DNS
#+BEGIN_EXAMPLE
Robson Poffo [5:56 PM]
@denny.zhang, I am seeing that our kibana instance (stats.carol.ai) doesn't have access to do-es-001.carol.ai:9200


[5:56]
could you verify?


Denny Zhang
[5:56 PM]
Let me check.


Robson Poffo [5:56 PM]
telnet is failing

[5:58]
prod-app-01/check_mdm_healthcheck is CRITICAL:
Connection refused


Bruno Volpato [5:59 PM]
we dropped do-es-001 right?


Denny Zhang
[5:59 PM]
hmm, I see what you reports, @robson.poffo

Checked ES node, firewall doesn't allow that.

Was it working previously?
 3 replies Last reply today at 6:11 PM View thread


Denny Zhang
[6:00 PM]
Yes, @bruno

We can easily add the rule in do-es-001.carol.ai, which is bematech-do-es-2.

Just to confirm where we stand right now. (Looks like we need add some monitoring checks somewhere) (edited)



jenkins APP [6:05 PM]
----------------
DeploySystemDOProd - #282 Success after 13 min (Open)
#+END_EXAMPLE
** TODO Why Es run into yellow suddenly
Denny Zhang
[9:13 AM]
Why ES runs into yellow suddenly?

bematech-do-es-12 timeout, then rejoin the cluster.

```[2017-08-30 14:12:24,441][WARN ][discovery.zen.publish    ] [bematech-do-es-12.localdomain] timed out waiting for all nodes to process published state [99361] (timeout [30s], pending nodes: [{bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}])
[2017-08-30 14:12:24,634][WARN ][cluster.service          ] [bematech-do-es-12.localdomain] cluster state update task [shard-started ([staging-index-8a18aa800e5911e785f24a8136534b63][2], node[Sw5V83ICS92_ypNNjpOZ2A], [R], v[63], s[INITIALIZING], a[id=XaavbcvWQjyMmdigL15RDw], unassigned_info[[reason=NODE_LEFT], at[2017-08-30T14:07:34.088Z], details[node_left[I4PMZGm-Ss6DmzFXPtYjcg]]], expected_shard_size[1640641495]), reason [after recovery (replica) from node [{bematech-do-es-18.localdomain}{63ZmTqpvSs-_zxMStLAWRg}{165.227.25.149}{165.227.25.149:9300}{max_local_storage_nodes=1}]],shard-started ([staging-index-8a18aa800e5911e785f24a8136534b63][4], node[4gyYmBDXTXK6BY_ujUQGTA], [R], v[58], s[INITIALIZING], a[id=uuhSCgQiSJu6zSL9iPZWGQ], unassigned_info[[reason=NODE_LEFT], at[2017-08-30T14:07:34.088Z], details[node_left[I4PMZGm-Ss6DmzFXPtYjcg]]], expected_shard_size[1627348711]), reason [after recovery (replica) from node [{bematech-do-es-07.localdomain}{elqF0TY7R4Cbb5-DZJih2g}{165.227.21.128}{165.227.21.128:9300}{max_local_storage_nodes=1}]]] took 30.2s above the warn threshold of 30s```
*** /var/log/elasticsearch/mdm.log
#+BEGIN_EXAMPLE
root@bematech-do-es-12:~# tail -n 500 /var/log/elasticsearch/mdm.log
tail -n 500 /var/log/elasticsearch/mdm.log
[2017-08-30 00:06:15,549][INFO ][cluster.metadata         ] [bematech-do-es-12.localdomain] [staging-index-321bb9606b2111e7b579a2f42be00f79] update_mapping [mdmStagingSchema]
[2017-08-30 00:06:40,806][INFO ][cluster.metadata         ] [bematech-do-es-12.localdomain] [staging-index-321bb9606b2111e7b579a2f42be00f79] create_mapping [8bdce3206bf811e7b579a2f42be00f79_sb3010]
[2017-08-30 00:07:00,588][INFO ][cluster.metadata         ] [bematech-do-es-12.localdomain] [staging-index-321bb9606b2111e7b579a2f42be00f79] update_mapping [8bdce3206bf811e7b579a2f42be00f79_sb3010]
[2017-08-30 00:07:21,816][INFO ][cluster.metadata         ] [bematech-do-es-12.localdomain] [staging-index-321bb9606b2111e7b579a2f42be00f79] update_mapping [mdmStagingSchema]
[2017-08-30 00:07:38,403][INFO ][cluster.metadata         ] [bematech-do-es-12.localdomain] [staging-index-321bb9606b2111e7b579a2f42be00f79] create_mapping [8bdce3206bf811e7b579a2f42be00f79_sbe010]
[2017-08-30 00:07:52,744][INFO ][cluster.metadata         ] [bematech-do-es-12.localdomain] [staging-index-321bb9606b2111e7b579a2f42be00f79] update_mapping [8bdce3206bf811e7b579a2f42be00f79_sbe010]
[2017-08-30 00:53:22,259][INFO ][cluster.metadata         ] [bematech-do-es-12.localdomain] [staging-index-321bb9606b2111e7b579a2f42be00f79] update_mapping [mdmStagingSchema]
[2017-08-30 00:53:42,980][INFO ][cluster.metadata         ] [bematech-do-es-12.localdomain] [staging-index-321bb9606b2111e7b579a2f42be00f79] create_mapping [8bdce3206bf811e7b579a2f42be00f79_sf4010]
[2017-08-30 00:54:00,821][INFO ][cluster.metadata         ] [bematech-do-es-12.localdomain] [staging-index-321bb9606b2111e7b579a2f42be00f79] update_mapping [8bdce3206bf811e7b579a2f42be00f79_sf4010]
[2017-08-30 02:24:52,261][WARN ][discovery.zen.publish    ] [bematech-do-es-12.localdomain] timed out waiting for all nodes to process published state [99324] (timeout [30s], pending nodes: [{bematech-do-es-19.localdomain}{k-RJnkMxS1OyGrX95ksXKA}{138.197.205.85}{138.197.205.85:9300}{max_local_storage_nodes=1}])
[2017-08-30 02:24:53,207][WARN ][cluster.service          ] [bematech-do-es-12.localdomain] cluster state update task [shard-started ([master-index-abae8b30ac9b11e692000401f8d88101-new3][2], node[DMibMY5tQ2OAiM31rJpong], relocating [k-RJnkMxS1OyGrX95ksXKA], [R], v[157], s[INITIALIZING], a[id=fblz3JW6QoKO1VwJERcY7A, rId=EM_I6RW3TsON3j7FEMkJLg], expected_shard_size[42690164069]), reason [after recovery (replica) from node [{bematech-do-es-14.localdomain}{Sddyx4aNQaSnmRRV7uH50Q}{138.68.23.132}{138.68.23.132:9300}{max_local_storage_nodes=1}]]] took 31s above the warn threshold of 30s
[2017-08-30 02:44:47,691][WARN ][discovery.zen.publish    ] [bematech-do-es-12.localdomain] timed out waiting for all nodes to process published state [99325] (timeout [30s], pending nodes: [{bematech-do-es-19.localdomain}{k-RJnkMxS1OyGrX95ksXKA}{138.197.205.85}{138.197.205.85:9300}{max_local_storage_nodes=1}])
[2017-08-30 02:44:47,972][WARN ][cluster.service          ] [bematech-do-es-12.localdomain] cluster state update task [shard-started ([master-index-abae8b30ac9b11e692000401f8d88101-new3][5], node[U8qsG-1sQ9GYRBvuNYU_ZA], relocating [63ZmTqpvSs-_zxMStLAWRg], [R], v[127], s[INITIALIZING], a[id=8g-FzkFAQbC8fLLujyNnqg, rId=TxY3X9RiS3GV39lW-hy28A], expected_shard_size[35081993179]), reason [after recovery (replica) from node [{bematech-do-es-08.localdomain}{4gyYmBDXTXK6BY_ujUQGTA}{138.68.30.61}{138.68.30.61:9300}{max_local_storage_nodes=1}]]] took 30.3s above the warn threshold of 30s
[2017-08-30 03:44:17,754][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-abae8b30ac9b11e692000401f8d88101-new3][9] received shard failed for target shard [[master-index-abae8b30ac9b11e692000401f8d88101-new3][9], node[sn9Lk6UdSXa65A6DlPXGXg], relocating [elqF0TY7R4Cbb5-DZJih2g], [R], v[154], s[INITIALIZING], a[id=9e37XGXKS3CoUpBJDLhpRQ, rId=RQW6joHLSUCXX70om0esVA], expected_shard_size[43454556437]], indexUUID [NoVKqnGdRAaxePBg9j6uJA], message [failed recovery], failure [RecoveryFailedException[[master-index-abae8b30ac9b11e692000401f8d88101-new3][9]: Recovery failed from {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1} into {bematech-do-es-1.localdomain}{sn9Lk6UdSXa65A6DlPXGXg}{165.227.24.213}{bematech-do-es-1/165.227.24.213:9300}{max_local_storage_nodes=1} (no activity after [30m])]; nested: ElasticsearchTimeoutException[no activity after [30m]]; ]
RecoveryFailedException[[master-index-abae8b30ac9b11e692000401f8d88101-new3][9]: Recovery failed from {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1} into {bematech-do-es-1.localdomain}{sn9Lk6UdSXa65A6DlPXGXg}{165.227.24.213}{bematech-do-es-1/165.227.24.213:9300}{max_local_storage_nodes=1} (no activity after [30m])]; nested: ElasticsearchTimeoutException[no activity after [30m]];
	at org.elasticsearch.indices.recovery.RecoveriesCollection$RecoveryMonitor.doRun(RecoveriesCollection.java:236)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: ElasticsearchTimeoutException[no activity after [30m]]
	... 5 more
[2017-08-30 03:44:47,946][WARN ][discovery.zen.publish    ] [bematech-do-es-12.localdomain] timed out waiting for all nodes to process published state [99326] (timeout [30s], pending nodes: [{bematech-do-es-19.localdomain}{k-RJnkMxS1OyGrX95ksXKA}{138.197.205.85}{138.197.205.85:9300}{max_local_storage_nodes=1}])
[2017-08-30 03:44:48,250][WARN ][cluster.service          ] [bematech-do-es-12.localdomain] cluster state update task [shard-failed ([master-index-abae8b30ac9b11e692000401f8d88101-new3][9], node[sn9Lk6UdSXa65A6DlPXGXg], relocating [elqF0TY7R4Cbb5-DZJih2g], [R], v[154], s[INITIALIZING], a[id=9e37XGXKS3CoUpBJDLhpRQ, rId=RQW6joHLSUCXX70om0esVA], expected_shard_size[43454556437]), message [failed recovery]] took 30.4s above the warn threshold of 30s
[2017-08-30 13:35:58,716][WARN ][discovery.zen.publish    ] [bematech-do-es-12.localdomain] timed out waiting for all nodes to process published state [99339] (timeout [30s], pending nodes: [{bematech-do-es-1.localdomain}{sn9Lk6UdSXa65A6DlPXGXg}{165.227.24.213}{165.227.24.213:9300}{max_local_storage_nodes=1}])
[2017-08-30 13:35:58,974][WARN ][cluster.service          ] [bematech-do-es-12.localdomain] cluster state update task [shard-started ([master-index-abae8b30ac9b11e692000401f8d88101-new3][0], node[U8qsG-1sQ9GYRBvuNYU_ZA], relocating [I4PMZGm-Ss6DmzFXPtYjcg], [R], v[184], s[INITIALIZING], a[id=Krwk3-TZRim7DYOwJ51WYQ, rId=6K7c2ZzCT3i-L3lVWuP-ww], expected_shard_size[34684120436]), reason [after recovery (replica) from node [{bematech-do-es-1.localdomain}{sn9Lk6UdSXa65A6DlPXGXg}{165.227.24.213}{165.227.24.213:9300}{max_local_storage_nodes=1}]]] took 30.3s above the warn threshold of 30s
[2017-08-30 13:37:35,072][WARN ][monitor.jvm              ] [bematech-do-es-12.localdomain] [gc][young][583236][28668] duration [1.3s], collections [1]/[1.6s], total [1.3s]/[1.5h], memory [9.5gb]->[6.3gb]/[15.6gb], all_pools {[young] [3.1gb]->[2.4mb]/[3.2gb]}{[survivor] [50mb]->[58.4mb]/[409.5mb]}{[old] [6.2gb]->[6.2gb]/[12gb]}
[2017-08-30 13:41:04,124][WARN ][discovery.zen.publish    ] [bematech-do-es-12.localdomain] timed out waiting for all nodes to process published state [99340] (timeout [30s], pending nodes: [{bematech-do-es-4.localdomain}{DMibMY5tQ2OAiM31rJpong}{138.68.21.77}{138.68.21.77:9300}{max_local_storage_nodes=1}])
[2017-08-30 13:41:04,335][WARN ][cluster.service          ] [bematech-do-es-12.localdomain] cluster state update task [shard-started ([master-index-8a18aa800e5911e785f24a8136534b63][0], node[sn9Lk6UdSXa65A6DlPXGXg], relocating [mrhCiAPvRxekqyhVPTq5LQ], [P], v[70], s[INITIALIZING], a[id=3FNaM7aaTrOWI_aOuGqYzw, rId=nNyCaHQWQOOpPBrjdCGo5w], expected_shard_size[6781527273]), reason [after recovery (replica) from node [{bematech-do-es-11.localdomain}{mrhCiAPvRxekqyhVPTq5LQ}{138.197.221.161}{138.197.221.161:9300}{max_local_storage_nodes=1}]]] took 30.3s above the warn threshold of 30s
[2017-08-30 13:45:24,941][WARN ][discovery.zen.publish    ] [bematech-do-es-12.localdomain] timed out waiting for all nodes to process published state [99341] (timeout [30s], pending nodes: [{bematech-do-es-1.localdomain}{sn9Lk6UdSXa65A6DlPXGXg}{165.227.24.213}{165.227.24.213:9300}{max_local_storage_nodes=1}])
[2017-08-30 13:45:25,182][WARN ][cluster.service          ] [bematech-do-es-12.localdomain] cluster state update task [shard-started ([master-index-8a18aa800e5911e785f24a8136534b63][1], node[DMibMY5tQ2OAiM31rJpong], relocating [Sddyx4aNQaSnmRRV7uH50Q], [P], v[43], s[INITIALIZING], a[id=0gDJso2STz6HF7q1fUbQZQ, rId=cO0DLATzT3CVPqzhEGhOQg], expected_shard_size[6561544200]), reason [after recovery (replica) from node [{bematech-do-es-14.localdomain}{Sddyx4aNQaSnmRRV7uH50Q}{138.68.23.132}{138.68.23.132:9300}{max_local_storage_nodes=1}]]] took 30.3s above the warn threshold of 30s
[2017-08-30 13:48:28,050][WARN ][discovery.zen.publish    ] [bematech-do-es-12.localdomain] timed out waiting for all nodes to process published state [99342] (timeout [30s], pending nodes: [{bematech-do-es-4.localdomain}{DMibMY5tQ2OAiM31rJpong}{138.68.21.77}{138.68.21.77:9300}{max_local_storage_nodes=1}])
[2017-08-30 13:48:28,233][WARN ][cluster.service          ] [bematech-do-es-12.localdomain] cluster state update task [shard-started ([staging-index-8a18aa800e5911e785f24a8136534b63][8], node[sn9Lk6UdSXa65A6DlPXGXg], relocating [VA8KBulRQymfG8LR5DACnQ], [R], v[30], s[INITIALIZING], a[id=mFOm6dAjSPKGBgixszDk5Q, rId=7yGqrixzT3-TMsyEO3p3Yw], expected_shard_size[1824681318]), reason [after recovery (replica) from node [{bematech-do-es-10.localdomain}{ArXwkkoAQUKcxdY5N8x4DQ}{138.197.221.191}{138.197.221.191:9300}{max_local_storage_nodes=1}]]] took 30.3s above the warn threshold of 30s
[2017-08-30 13:52:46,491][WARN ][discovery.zen.publish    ] [bematech-do-es-12.localdomain] timed out waiting for all nodes to process published state [99343] (timeout [30s], pending nodes: [{bematech-do-es-2.localdomain}{U8qsG-1sQ9GYRBvuNYU_ZA}{138.68.246.50}{138.68.246.50:9300}{max_local_storage_nodes=1}])
[2017-08-30 13:52:46,671][WARN ][cluster.service          ] [bematech-do-es-12.localdomain] cluster state update task [shard-started ([staging-index-8a18aa800e5911e785f24a8136534b63][14], node[DMibMY5tQ2OAiM31rJpong], relocating [eCteNDCeTk2uXlDCz5JZxg], [R], v[2013], s[INITIALIZING], a[id=by2gnlLiSxGDyVw_3guwZw, rId=DyEUzi3aQXuI4roJCap3zw], expected_shard_size[1653933330]), reason [after recovery (replica) from node [{bematech-do-es-03.localdomain}{SrY2diUXTNiHR--I0FzXPw}{165.227.5.192}{165.227.5.192:9300}{max_local_storage_nodes=1}]]] took 30.3s above the warn threshold of 30s
[2017-08-30 13:57:32,575][WARN ][discovery.zen.publish    ] [bematech-do-es-12.localdomain] timed out waiting for all nodes to process published state [99344] (timeout [30s], pending nodes: [{bematech-do-es-3.localdomain}{lyuFLGhoRLKjXqAfxreteQ}{165.227.22.228}{165.227.22.228:9300}{max_local_storage_nodes=1}])
[2017-08-30 13:57:33,076][WARN ][cluster.service          ] [bematech-do-es-12.localdomain] cluster state update task [shard-started ([master-index-8a18aa800e5911e785f24a8136534b63][11], node[U8qsG-1sQ9GYRBvuNYU_ZA], relocating [ArXwkkoAQUKcxdY5N8x4DQ], [R], v[43], s[INITIALIZING], a[id=gmyVHIw7RreKV4d4RvzTqw, rId=ZXwvLDajRiChGjvxhDjh0g], expected_shard_size[7123289797]), reason [after recovery (replica) from node [{bematech-do-es-02.localdomain}{ppQNYbLgRLKJOrP7CbIclA}{138.68.50.117}{138.68.50.117:9300}{max_local_storage_nodes=1}]]] took 30.6s above the warn threshold of 30s
[2017-08-30 14:06:46,158][DEBUG][action.admin.cluster.node.stats] [bematech-do-es-12.localdomain] failed to execute on node [I4PMZGm-Ss6DmzFXPtYjcg]
ReceiveTimeoutTransportException[[bematech-do-es-15.localdomain][138.68.230.220:9300][cluster:monitor/nodes/stats[n]] request_id [11282476] timed out after [15003ms]]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:679)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-30 14:07:10,537][WARN ][discovery.zen.publish    ] [bematech-do-es-12.localdomain] timed out waiting for all nodes to process published state [99347] (timeout [30s], pending nodes: [{bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}])
[2017-08-30 14:07:10,717][WARN ][cluster.service          ] [bematech-do-es-12.localdomain] cluster state update task [shard-started ([master-index-839920f07e6b11e6b71d0401f8d88101-new3][0], node[lyuFLGhoRLKjXqAfxreteQ], relocating [k-RJnkMxS1OyGrX95ksXKA], [P], v[113], s[INITIALIZING], a[id=sIWjHhQ3TemwrjzS8FenyQ, rId=Fuv4inLQRq-2QTK-KvyNiA], expected_shard_size[1809995998]), reason [after recovery (replica) from node [{bematech-do-es-19.localdomain}{k-RJnkMxS1OyGrX95ksXKA}{138.197.205.85}{138.197.205.85:9300}{max_local_storage_nodes=1}]]] took 30.2s above the warn threshold of 30s
[2017-08-30 14:07:34,431][INFO ][cluster.routing.allocation] [bematech-do-es-12.localdomain] Cluster health status changed from [GREEN] to [YELLOW] (reason: [[{bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}] failed]).
[2017-08-30 14:07:34,434][INFO ][cluster.service          ] [bematech-do-es-12.localdomain] removed {{bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1},}, reason: zen-disco-node_failed({bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}), reason failed to ping, tried [3] times, each with maximum [30s] timeout
[2017-08-30 14:07:34,741][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-abae8b30ac9b11e692000401f8d88101-new3][3] received shard failed for target shard [[master-index-abae8b30ac9b11e692000401f8d88101-new3][3], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[2189], s[STARTED], a[id=fDSSTtssQ-O67xvR9Jog7g]], indexUUID [NoVKqnGdRAaxePBg9j6uJA], message [failed to perform indices:data/write/index on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/index[r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/index[r]] disconnected]
[2017-08-30 14:07:34,993][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-8cd6e43115e9416eb23609486fa053e3-new3][1] received shard failed for target shard [[master-index-8cd6e43115e9416eb23609486fa053e3-new3][1], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[96], s[STARTED], a[id=DFHBoOxpQeSi6zohGSid2Q]], indexUUID [gmf5NVEUTdCkC-P2Cxv0vA], message [failed to perform indices:data/write/index on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/index[r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/index[r]] disconnected]
[2017-08-30 14:07:35,055][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-1154b0b041d211e7b7c04a8136534b63][0] received shard failed for target shard [[master-index-1154b0b041d211e7b7c04a8136534b63][0], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[34], s[STARTED], a[id=bUvkhwEmRUqS1tM4U17IgA]], indexUUID [gJB7jAQPQX6TzmcxK9ewSQ], message [failed to perform indices:admin/refresh[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]
[2017-08-30 14:07:35,055][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-1154b0b041d211e7b7c04a8136534b63][0] received shard failed for target shard [[master-index-1154b0b041d211e7b7c04a8136534b63][0], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[34], s[STARTED], a[id=bUvkhwEmRUqS1tM4U17IgA]], indexUUID [gJB7jAQPQX6TzmcxK9ewSQ], message [failed to perform indices:admin/refresh[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]
[2017-08-30 14:07:35,055][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-1154b0b041d211e7b7c04a8136534b63][0] received shard failed for target shard [[master-index-1154b0b041d211e7b7c04a8136534b63][0], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[34], s[STARTED], a[id=bUvkhwEmRUqS1tM4U17IgA]], indexUUID [gJB7jAQPQX6TzmcxK9ewSQ], message [failed to perform indices:admin/refresh[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]
[2017-08-30 14:07:35,055][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-1154b0b041d211e7b7c04a8136534b63][0] received shard failed for target shard [[master-index-1154b0b041d211e7b7c04a8136534b63][0], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[34], s[STARTED], a[id=bUvkhwEmRUqS1tM4U17IgA]], indexUUID [gJB7jAQPQX6TzmcxK9ewSQ], message [failed to perform indices:admin/refresh[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]
[2017-08-30 14:07:35,055][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-1154b0b041d211e7b7c04a8136534b63][0] received shard failed for target shard [[master-index-1154b0b041d211e7b7c04a8136534b63][0], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[34], s[STARTED], a[id=bUvkhwEmRUqS1tM4U17IgA]], indexUUID [gJB7jAQPQX6TzmcxK9ewSQ], message [failed to perform indices:admin/refresh[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]
[2017-08-30 14:07:35,055][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-1154b0b041d211e7b7c04a8136534b63][0] received shard failed for target shard [[master-index-1154b0b041d211e7b7c04a8136534b63][0], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[34], s[STARTED], a[id=bUvkhwEmRUqS1tM4U17IgA]], indexUUID [gJB7jAQPQX6TzmcxK9ewSQ], message [failed to perform indices:admin/refresh[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]
[2017-08-30 14:07:35,057][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-1154b0b041d211e7b7c04a8136534b63][0] received shard failed for target shard [[master-index-1154b0b041d211e7b7c04a8136534b63][0], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[34], s[STARTED], a[id=bUvkhwEmRUqS1tM4U17IgA]], indexUUID [gJB7jAQPQX6TzmcxK9ewSQ], message [failed to perform indices:admin/refresh[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]
[2017-08-30 14:07:35,055][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-1154b0b041d211e7b7c04a8136534b63][0] received shard failed for target shard [[master-index-1154b0b041d211e7b7c04a8136534b63][0], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[34], s[STARTED], a[id=bUvkhwEmRUqS1tM4U17IgA]], indexUUID [gJB7jAQPQX6TzmcxK9ewSQ], message [failed to perform indices:admin/refresh[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]
[2017-08-30 14:07:35,057][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-1154b0b041d211e7b7c04a8136534b63][0] received shard failed for target shard [[master-index-1154b0b041d211e7b7c04a8136534b63][0], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[34], s[STARTED], a[id=bUvkhwEmRUqS1tM4U17IgA]], indexUUID [gJB7jAQPQX6TzmcxK9ewSQ], message [failed to perform indices:admin/refresh[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]
[2017-08-30 14:07:35,057][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-1154b0b041d211e7b7c04a8136534b63][0] received shard failed for target shard [[master-index-1154b0b041d211e7b7c04a8136534b63][0], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[34], s[STARTED], a[id=bUvkhwEmRUqS1tM4U17IgA]], indexUUID [gJB7jAQPQX6TzmcxK9ewSQ], message [failed to perform indices:admin/refresh[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]
[2017-08-30 14:07:35,144][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-abae8b30ac9b11e692000401f8d88101-new3][2] received shard failed for target shard [[master-index-abae8b30ac9b11e692000401f8d88101-new3][2], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[160], s[STARTED], a[id=O7Unb7aaSHOZLcUe0eaclQ]], indexUUID [NoVKqnGdRAaxePBg9j6uJA], message [failed to perform indices:data/write/delete on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/delete[r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/delete[r]] disconnected]
[2017-08-30 14:07:35,149][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-abae8b30ac9b11e692000401f8d88101-new3][2] received shard failed for target shard [[master-index-abae8b30ac9b11e692000401f8d88101-new3][2], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[160], s[STARTED], a[id=O7Unb7aaSHOZLcUe0eaclQ]], indexUUID [NoVKqnGdRAaxePBg9j6uJA], message [failed to perform indices:data/write/index on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/index[r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/index[r]] disconnected]
[2017-08-30 14:07:35,889][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-1154b0b041d211e7b7c04a8136534b63][7] received shard failed for target shard [[master-index-1154b0b041d211e7b7c04a8136534b63][7], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[56], s[STARTED], a[id=ItBNgHKgSRKtwkGcSOrF-g]], indexUUID [gJB7jAQPQX6TzmcxK9ewSQ], message [failed to perform indices:admin/refresh[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]
[2017-08-30 14:07:35,891][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-1154b0b041d211e7b7c04a8136534b63][7] received shard failed for target shard [[master-index-1154b0b041d211e7b7c04a8136534b63][7], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[56], s[STARTED], a[id=ItBNgHKgSRKtwkGcSOrF-g]], indexUUID [gJB7jAQPQX6TzmcxK9ewSQ], message [failed to perform indices:data/write/index on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/index[r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/index[r]] disconnected]
[2017-08-30 14:07:35,895][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-1154b0b041d211e7b7c04a8136534b63][7] received shard failed for target shard [[master-index-1154b0b041d211e7b7c04a8136534b63][7], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[56], s[STARTED], a[id=ItBNgHKgSRKtwkGcSOrF-g]], indexUUID [gJB7jAQPQX6TzmcxK9ewSQ], message [failed to perform indices:admin/refresh[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]
[2017-08-30 14:07:35,907][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-abae8b30ac9b11e692000401f8d88101-new3][7] received shard failed for target shard [[master-index-abae8b30ac9b11e692000401f8d88101-new3][7], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[127], s[STARTED], a[id=bd6rN2zOS7CIFuXatIH2ag]], indexUUID [NoVKqnGdRAaxePBg9j6uJA], message [failed to perform indices:data/write/delete on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/delete[r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/delete[r]] disconnected]
[2017-08-30 14:07:35,936][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-1154b0b041d211e7b7c04a8136534b63][7] received shard failed for target shard [[master-index-1154b0b041d211e7b7c04a8136534b63][7], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[56], s[STARTED], a[id=ItBNgHKgSRKtwkGcSOrF-g]], indexUUID [gJB7jAQPQX6TzmcxK9ewSQ], message [failed to perform indices:admin/refresh[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]
[2017-08-30 14:07:35,936][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-1154b0b041d211e7b7c04a8136534b63][7] received shard failed for target shard [[master-index-1154b0b041d211e7b7c04a8136534b63][7], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[56], s[STARTED], a[id=ItBNgHKgSRKtwkGcSOrF-g]], indexUUID [gJB7jAQPQX6TzmcxK9ewSQ], message [failed to perform indices:admin/refresh[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]
[2017-08-30 14:07:35,937][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-1154b0b041d211e7b7c04a8136534b63][7] received shard failed for target shard [[master-index-1154b0b041d211e7b7c04a8136534b63][7], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[56], s[STARTED], a[id=ItBNgHKgSRKtwkGcSOrF-g]], indexUUID [gJB7jAQPQX6TzmcxK9ewSQ], message [failed to perform indices:admin/refresh[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]
[2017-08-30 14:07:35,937][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-1154b0b041d211e7b7c04a8136534b63][7] received shard failed for target shard [[master-index-1154b0b041d211e7b7c04a8136534b63][7], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[56], s[STARTED], a[id=ItBNgHKgSRKtwkGcSOrF-g]], indexUUID [gJB7jAQPQX6TzmcxK9ewSQ], message [failed to perform indices:admin/refresh[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]
[2017-08-30 14:07:35,942][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-1154b0b041d211e7b7c04a8136534b63][7] received shard failed for target shard [[master-index-1154b0b041d211e7b7c04a8136534b63][7], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[56], s[STARTED], a[id=ItBNgHKgSRKtwkGcSOrF-g]], indexUUID [gJB7jAQPQX6TzmcxK9ewSQ], message [failed to perform indices:admin/refresh[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]
[2017-08-30 14:07:35,943][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-1154b0b041d211e7b7c04a8136534b63][7] received shard failed for target shard [[master-index-1154b0b041d211e7b7c04a8136534b63][7], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[56], s[STARTED], a[id=ItBNgHKgSRKtwkGcSOrF-g]], indexUUID [gJB7jAQPQX6TzmcxK9ewSQ], message [failed to perform indices:admin/refresh[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]
[2017-08-30 14:07:35,945][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-1154b0b041d211e7b7c04a8136534b63][7] received shard failed for target shard [[master-index-1154b0b041d211e7b7c04a8136534b63][7], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[56], s[STARTED], a[id=ItBNgHKgSRKtwkGcSOrF-g]], indexUUID [gJB7jAQPQX6TzmcxK9ewSQ], message [failed to perform indices:admin/refresh[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]
[2017-08-30 14:07:35,956][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-1154b0b041d211e7b7c04a8136534b63][7] received shard failed for target shard [[master-index-1154b0b041d211e7b7c04a8136534b63][7], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[56], s[STARTED], a[id=ItBNgHKgSRKtwkGcSOrF-g]], indexUUID [gJB7jAQPQX6TzmcxK9ewSQ], message [failed to perform indices:admin/refresh[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]
[2017-08-30 14:07:35,956][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-abae8b30ac9b11e692000401f8d88101-new3][7] received shard failed for target shard [[master-index-abae8b30ac9b11e692000401f8d88101-new3][7], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[127], s[STARTED], a[id=bd6rN2zOS7CIFuXatIH2ag]], indexUUID [NoVKqnGdRAaxePBg9j6uJA], message [failed to perform indices:data/write/index on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/index[r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/index[r]] disconnected]
[2017-08-30 14:07:35,956][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-1154b0b041d211e7b7c04a8136534b63][7] received shard failed for target shard [[master-index-1154b0b041d211e7b7c04a8136534b63][7], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[56], s[STARTED], a[id=ItBNgHKgSRKtwkGcSOrF-g]], indexUUID [gJB7jAQPQX6TzmcxK9ewSQ], message [failed to perform indices:admin/refresh[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]
[2017-08-30 14:07:35,956][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-1154b0b041d211e7b7c04a8136534b63][7] received shard failed for target shard [[master-index-1154b0b041d211e7b7c04a8136534b63][7], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[56], s[STARTED], a[id=ItBNgHKgSRKtwkGcSOrF-g]], indexUUID [gJB7jAQPQX6TzmcxK9ewSQ], message [failed to perform indices:admin/refresh[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:admin/refresh[s][r]] disconnected]
[2017-08-30 14:07:38,225][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-abae8b30ac9b11e692000401f8d88101-new3][22] received shard failed for target shard [[master-index-abae8b30ac9b11e692000401f8d88101-new3][22], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[214], s[STARTED], a[id=hjP0VxMGQoSHiq7UmHR-FQ]], indexUUID [NoVKqnGdRAaxePBg9j6uJA], message [failed to perform indices:data/write/delete on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/delete[r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/delete[r]] disconnected]
[2017-08-30 14:07:38,226][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [master-index-abae8b30ac9b11e692000401f8d88101-new3][22] received shard failed for target shard [[master-index-abae8b30ac9b11e692000401f8d88101-new3][22], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[214], s[STARTED], a[id=hjP0VxMGQoSHiq7UmHR-FQ]], indexUUID [NoVKqnGdRAaxePBg9j6uJA], message [failed to perform indices:data/write/index on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/index[r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/index[r]] disconnected]
[2017-08-30 14:07:46,179][DEBUG][action.admin.cluster.node.stats] [bematech-do-es-12.localdomain] failed to execute on node [I4PMZGm-Ss6DmzFXPtYjcg]
ReceiveTimeoutTransportException[[bematech-do-es-15.localdomain][138.68.230.220:9300][cluster:monitor/nodes/stats[n]] request_id [11284043] timed out after [15009ms]]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:679)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-08-30 14:07:51,884][INFO ][cluster.routing          ] [bematech-do-es-12.localdomain] delaying allocation for [99] unassigned shards, next check in [1m]
[2017-08-30 14:07:53,202][WARN ][action.bulk              ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] failed to perform indices:data/write/bulk[s][r] on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,202][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] received shard failed for target shard [[staging-index-0acedf50628d11e7b815a2f42be00f79][6], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[43], s[STARTED], a[id=5QUKM0Q_S7efY4vReNloyQ]], indexUUID [ECzL09ykQLS0QzeegznNEQ], message [failed to perform indices:data/write/bulk[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,203][WARN ][action.bulk              ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] failed to perform indices:data/write/bulk[s][r] on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,218][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] received shard failed for target shard [[staging-index-0acedf50628d11e7b815a2f42be00f79][6], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[43], s[STARTED], a[id=5QUKM0Q_S7efY4vReNloyQ]], indexUUID [ECzL09ykQLS0QzeegznNEQ], message [failed to perform indices:data/write/bulk[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,204][WARN ][action.bulk              ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] failed to perform indices:data/write/bulk[s][r] on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,220][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] received shard failed for target shard [[staging-index-0acedf50628d11e7b815a2f42be00f79][6], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[43], s[STARTED], a[id=5QUKM0Q_S7efY4vReNloyQ]], indexUUID [ECzL09ykQLS0QzeegznNEQ], message [failed to perform indices:data/write/bulk[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,241][WARN ][action.bulk              ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] failed to perform indices:data/write/bulk[s][r] on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,243][WARN ][action.bulk              ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] failed to perform indices:data/write/bulk[s][r] on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,244][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] received shard failed for target shard [[staging-index-0acedf50628d11e7b815a2f42be00f79][6], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[43], s[STARTED], a[id=5QUKM0Q_S7efY4vReNloyQ]], indexUUID [ECzL09ykQLS0QzeegznNEQ], message [failed to perform indices:data/write/bulk[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,244][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] received shard failed for target shard [[staging-index-0acedf50628d11e7b815a2f42be00f79][6], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[43], s[STARTED], a[id=5QUKM0Q_S7efY4vReNloyQ]], indexUUID [ECzL09ykQLS0QzeegznNEQ], message [failed to perform indices:data/write/bulk[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,247][WARN ][action.bulk              ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] failed to perform indices:data/write/bulk[s][r] on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,247][WARN ][action.bulk              ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] failed to perform indices:data/write/bulk[s][r] on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,248][WARN ][action.bulk              ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] failed to perform indices:data/write/bulk[s][r] on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,248][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] received shard failed for target shard [[staging-index-0acedf50628d11e7b815a2f42be00f79][6], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[43], s[STARTED], a[id=5QUKM0Q_S7efY4vReNloyQ]], indexUUID [ECzL09ykQLS0QzeegznNEQ], message [failed to perform indices:data/write/bulk[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,248][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] received shard failed for target shard [[staging-index-0acedf50628d11e7b815a2f42be00f79][6], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[43], s[STARTED], a[id=5QUKM0Q_S7efY4vReNloyQ]], indexUUID [ECzL09ykQLS0QzeegznNEQ], message [failed to perform indices:data/write/bulk[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,247][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] received shard failed for target shard [[staging-index-0acedf50628d11e7b815a2f42be00f79][6], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[43], s[STARTED], a[id=5QUKM0Q_S7efY4vReNloyQ]], indexUUID [ECzL09ykQLS0QzeegznNEQ], message [failed to perform indices:data/write/bulk[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,248][WARN ][action.bulk              ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] failed to perform indices:data/write/bulk[s][r] on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,248][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] received shard failed for target shard [[staging-index-0acedf50628d11e7b815a2f42be00f79][6], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[43], s[STARTED], a[id=5QUKM0Q_S7efY4vReNloyQ]], indexUUID [ECzL09ykQLS0QzeegznNEQ], message [failed to perform indices:data/write/bulk[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,248][WARN ][action.bulk              ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] failed to perform indices:data/write/bulk[s][r] on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,248][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] received shard failed for target shard [[staging-index-0acedf50628d11e7b815a2f42be00f79][6], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[43], s[STARTED], a[id=5QUKM0Q_S7efY4vReNloyQ]], indexUUID [ECzL09ykQLS0QzeegznNEQ], message [failed to perform indices:data/write/bulk[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,248][WARN ][action.bulk              ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] failed to perform indices:data/write/bulk[s][r] on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,249][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] received shard failed for target shard [[staging-index-0acedf50628d11e7b815a2f42be00f79][6], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[43], s[STARTED], a[id=5QUKM0Q_S7efY4vReNloyQ]], indexUUID [ECzL09ykQLS0QzeegznNEQ], message [failed to perform indices:data/write/bulk[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,248][WARN ][action.bulk              ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] failed to perform indices:data/write/bulk[s][r] on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,249][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] received shard failed for target shard [[staging-index-0acedf50628d11e7b815a2f42be00f79][6], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[43], s[STARTED], a[id=5QUKM0Q_S7efY4vReNloyQ]], indexUUID [ECzL09ykQLS0QzeegznNEQ], message [failed to perform indices:data/write/bulk[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,249][DEBUG][action.admin.indices.stats] [bematech-do-es-12.localdomain] failed to execute [indices:monitor/stats] on node [I4PMZGm-Ss6DmzFXPtYjcg]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:monitor/stats[n]] disconnected]
[2017-08-30 14:07:53,252][WARN ][action.bulk              ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] failed to perform indices:data/write/bulk[s][r] on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,253][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] received shard failed for target shard [[staging-index-0acedf50628d11e7b815a2f42be00f79][6], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[43], s[STARTED], a[id=5QUKM0Q_S7efY4vReNloyQ]], indexUUID [ECzL09ykQLS0QzeegznNEQ], message [failed to perform indices:data/write/bulk[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,255][WARN ][action.bulk              ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] failed to perform indices:data/write/bulk[s][r] on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,256][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] received shard failed for target shard [[staging-index-0acedf50628d11e7b815a2f42be00f79][6], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[43], s[STARTED], a[id=5QUKM0Q_S7efY4vReNloyQ]], indexUUID [ECzL09ykQLS0QzeegznNEQ], message [failed to perform indices:data/write/bulk[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,259][WARN ][action.bulk              ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] failed to perform indices:data/write/bulk[s][r] on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,259][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] received shard failed for target shard [[staging-index-0acedf50628d11e7b815a2f42be00f79][6], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[43], s[STARTED], a[id=5QUKM0Q_S7efY4vReNloyQ]], indexUUID [ECzL09ykQLS0QzeegznNEQ], message [failed to perform indices:data/write/bulk[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,259][WARN ][action.bulk              ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] failed to perform indices:data/write/bulk[s][r] on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,260][WARN ][action.bulk              ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] failed to perform indices:data/write/bulk[s][r] on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,261][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] received shard failed for target shard [[staging-index-0acedf50628d11e7b815a2f42be00f79][6], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[43], s[STARTED], a[id=5QUKM0Q_S7efY4vReNloyQ]], indexUUID [ECzL09ykQLS0QzeegznNEQ], message [failed to perform indices:data/write/bulk[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,261][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] received shard failed for target shard [[staging-index-0acedf50628d11e7b815a2f42be00f79][6], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[43], s[STARTED], a[id=5QUKM0Q_S7efY4vReNloyQ]], indexUUID [ECzL09ykQLS0QzeegznNEQ], message [failed to perform indices:data/write/bulk[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,260][WARN ][action.bulk              ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] failed to perform indices:data/write/bulk[s][r] on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,262][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] received shard failed for target shard [[staging-index-0acedf50628d11e7b815a2f42be00f79][6], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[43], s[STARTED], a[id=5QUKM0Q_S7efY4vReNloyQ]], indexUUID [ECzL09ykQLS0QzeegznNEQ], message [failed to perform indices:data/write/bulk[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,260][WARN ][action.bulk              ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] failed to perform indices:data/write/bulk[s][r] on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,262][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] received shard failed for target shard [[staging-index-0acedf50628d11e7b815a2f42be00f79][6], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[43], s[STARTED], a[id=5QUKM0Q_S7efY4vReNloyQ]], indexUUID [ECzL09ykQLS0QzeegznNEQ], message [failed to perform indices:data/write/bulk[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,262][WARN ][action.bulk              ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] failed to perform indices:data/write/bulk[s][r] on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,262][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] received shard failed for target shard [[staging-index-0acedf50628d11e7b815a2f42be00f79][6], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[43], s[STARTED], a[id=5QUKM0Q_S7efY4vReNloyQ]], indexUUID [ECzL09ykQLS0QzeegznNEQ], message [failed to perform indices:data/write/bulk[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,263][WARN ][action.bulk              ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] failed to perform indices:data/write/bulk[s][r] on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,263][WARN ][action.bulk              ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] failed to perform indices:data/write/bulk[s][r] on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,263][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] received shard failed for target shard [[staging-index-0acedf50628d11e7b815a2f42be00f79][6], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[43], s[STARTED], a[id=5QUKM0Q_S7efY4vReNloyQ]], indexUUID [ECzL09ykQLS0QzeegznNEQ], message [failed to perform indices:data/write/bulk[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,263][WARN ][action.bulk              ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] failed to perform indices:data/write/bulk[s][r] on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,263][WARN ][action.bulk              ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] failed to perform indices:data/write/bulk[s][r] on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,263][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] received shard failed for target shard [[staging-index-0acedf50628d11e7b815a2f42be00f79][6], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[43], s[STARTED], a[id=5QUKM0Q_S7efY4vReNloyQ]], indexUUID [ECzL09ykQLS0QzeegznNEQ], message [failed to perform indices:data/write/bulk[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,263][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] received shard failed for target shard [[staging-index-0acedf50628d11e7b815a2f42be00f79][6], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[43], s[STARTED], a[id=5QUKM0Q_S7efY4vReNloyQ]], indexUUID [ECzL09ykQLS0QzeegznNEQ], message [failed to perform indices:data/write/bulk[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,264][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] received shard failed for target shard [[staging-index-0acedf50628d11e7b815a2f42be00f79][6], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[43], s[STARTED], a[id=5QUKM0Q_S7efY4vReNloyQ]], indexUUID [ECzL09ykQLS0QzeegznNEQ], message [failed to perform indices:data/write/bulk[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,264][DEBUG][action.admin.indices.stats] [bematech-do-es-12.localdomain] failed to execute [indices:monitor/stats] on node [I4PMZGm-Ss6DmzFXPtYjcg]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:monitor/stats[n]] disconnected]
[2017-08-30 14:07:53,264][WARN ][action.bulk              ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] failed to perform indices:data/write/bulk[s][r] on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,264][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] received shard failed for target shard [[staging-index-0acedf50628d11e7b815a2f42be00f79][6], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[43], s[STARTED], a[id=5QUKM0Q_S7efY4vReNloyQ]], indexUUID [ECzL09ykQLS0QzeegznNEQ], message [failed to perform indices:data/write/bulk[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,265][WARN ][action.bulk              ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] failed to perform indices:data/write/bulk[s][r] on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,265][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] received shard failed for target shard [[staging-index-0acedf50628d11e7b815a2f42be00f79][6], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[43], s[STARTED], a[id=5QUKM0Q_S7efY4vReNloyQ]], indexUUID [ECzL09ykQLS0QzeegznNEQ], message [failed to perform indices:data/write/bulk[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,265][WARN ][action.bulk              ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] failed to perform indices:data/write/bulk[s][r] on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,265][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] received shard failed for target shard [[staging-index-0acedf50628d11e7b815a2f42be00f79][6], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[43], s[STARTED], a[id=5QUKM0Q_S7efY4vReNloyQ]], indexUUID [ECzL09ykQLS0QzeegznNEQ], message [failed to perform indices:data/write/bulk[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,269][WARN ][action.bulk              ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] failed to perform indices:data/write/bulk[s][r] on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,270][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] received shard failed for target shard [[staging-index-0acedf50628d11e7b815a2f42be00f79][6], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[43], s[STARTED], a[id=5QUKM0Q_S7efY4vReNloyQ]], indexUUID [ECzL09ykQLS0QzeegznNEQ], message [failed to perform indices:data/write/bulk[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,271][WARN ][action.bulk              ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] failed to perform indices:data/write/bulk[s][r] on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,271][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] received shard failed for target shard [[staging-index-0acedf50628d11e7b815a2f42be00f79][6], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[43], s[STARTED], a[id=5QUKM0Q_S7efY4vReNloyQ]], indexUUID [ECzL09ykQLS0QzeegznNEQ], message [failed to perform indices:data/write/bulk[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,271][WARN ][action.bulk              ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] failed to perform indices:data/write/bulk[s][r] on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:07:53,271][WARN ][cluster.action.shard     ] [bematech-do-es-12.localdomain] [staging-index-0acedf50628d11e7b815a2f42be00f79][6] received shard failed for target shard [[staging-index-0acedf50628d11e7b815a2f42be00f79][6], node[I4PMZGm-Ss6DmzFXPtYjcg], [R], v[43], s[STARTED], a[id=5QUKM0Q_S7efY4vReNloyQ]], indexUUID [ECzL09ykQLS0QzeegznNEQ], message [failed to perform indices:data/write/bulk[s] on replica on node {bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}], failure [NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]]
NodeDisconnectedException[[bematech-do-es-15.localdomain][138.68.230.220:9300][indices:data/write/bulk[s][r]] disconnected]
[2017-08-30 14:10:10,140][INFO ][cluster.service          ] [bematech-do-es-12.localdomain] added {{bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1},}, reason: zen-disco-join(join from node[{bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}])
[2017-08-30 14:10:40,688][WARN ][discovery.zen.publish    ] [bematech-do-es-12.localdomain] timed out waiting for all nodes to process published state [99358] (timeout [30s], pending nodes: [{bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}])
[2017-08-30 14:10:40,703][WARN ][cluster.service          ] [bematech-do-es-12.localdomain] cluster state update task [zen-disco-join(join from node[{bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}])] took 30.5s above the warn threshold of 30s
[2017-08-30 14:11:23,968][WARN ][discovery.zen.publish    ] [bematech-do-es-12.localdomain] timed out waiting for all nodes to process published state [99359] (timeout [30s], pending nodes: [{bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}])
[2017-08-30 14:11:24,205][WARN ][cluster.service          ] [bematech-do-es-12.localdomain] cluster state update task [shard-started ([master-index-1154b0b041d211e7b7c04a8136534b63][0], node[6CePE_vbRvKYu4PCICzRAw], [R], v[36], s[INITIALIZING], a[id=Bl32U2W7RQW-JRZlazM4hw], unassigned_info[[reason=NODE_LEFT], at[2017-08-30T14:07:34.088Z], details[node_left[I4PMZGm-Ss6DmzFXPtYjcg]]], expected_shard_size[554807819]), reason [after recovery (replica) from node [{bematech-do-es-10.localdomain}{ArXwkkoAQUKcxdY5N8x4DQ}{138.197.221.191}{138.197.221.191:9300}{max_local_storage_nodes=1}]]] took 30.3s above the warn threshold of 30s
[2017-08-30 14:11:54,241][WARN ][discovery.zen.publish    ] [bematech-do-es-12.localdomain] timed out waiting for all nodes to process published state [99360] (timeout [30s], pending nodes: [{bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}])
[2017-08-30 14:11:54,420][WARN ][cluster.service          ] [bematech-do-es-12.localdomain] cluster state update task [shard-started ([staging-index-b74f5a703d5e11e68ac00401f8d88501][3], node[-IC3Gx06T7WBqmGQvjOZJA], [R], v[38], s[INITIALIZING], a[id=YoarsuBoRGOYsTtVOdgX1g], unassigned_info[[reason=NODE_LEFT], at[2017-08-30T14:07:34.088Z], details[node_left[I4PMZGm-Ss6DmzFXPtYjcg]]], expected_shard_size[50780242]), reason [after recovery (replica) from node [{bematech-do-es-04.localdomain}{VA8KBulRQymfG8LR5DACnQ}{165.227.17.43}{165.227.17.43:9300}{max_local_storage_nodes=1}]],shard-started ([staging-index-03b541d0208111e7bbb0a2f42be00f79][2], node[ppQNYbLgRLKJOrP7CbIclA], [R], v[57], s[INITIALIZING], a[id=zCMSGjcWRJygaOhZ1L1OLw], unassigned_info[[reason=NODE_LEFT], at[2017-08-30T14:07:34.088Z], details[node_left[I4PMZGm-Ss6DmzFXPtYjcg]]], expected_shard_size[20513538]), reason [after recovery (replica) from node [{bematech-do-es-18.localdomain}{63ZmTqpvSs-_zxMStLAWRg}{165.227.25.149}{165.227.25.149:9300}{max_local_storage_nodes=1}]],shard-started ([master-index-03b541d0208111e7bbb0a2f42be00f79][8], node[6nppGDL-REe8UE973F6D5w], [R], v[55], s[INITIALIZING], a[id=itNrK2nXSsuB2Uh7UAmxPA], unassigned_info[[reason=NODE_LEFT], at[2017-08-30T14:07:34.088Z], details[node_left[I4PMZGm-Ss6DmzFXPtYjcg]]], expected_shard_size[38288933]), reason [after recovery (replica) from node [{bematech-do-es-04.localdomain}{VA8KBulRQymfG8LR5DACnQ}{165.227.17.43}{165.227.17.43:9300}{max_local_storage_nodes=1}]],shard-started ([staging-index-b74f5a703d5e11e68ac00401f8d88501][3], node[-IC3Gx06T7WBqmGQvjOZJA], [R], v[38], s[INITIALIZING], a[id=YoarsuBoRGOYsTtVOdgX1g], unassigned_info[[reason=NODE_LEFT], at[2017-08-30T14:07:34.088Z], details[node_left[I4PMZGm-Ss6DmzFXPtYjcg]]], expected_shard_size[50780242]), reason [master {bematech-do-es-12.localdomain}{-IC3Gx06T7WBqmGQvjOZJA}{138.197.200.214}{bematech-do-es-12/138.197.200.214:9300}{max_local_storage_nodes=1} marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started]] took 30.2s above the warn threshold of 30s
[2017-08-30 14:12:24,441][WARN ][discovery.zen.publish    ] [bematech-do-es-12.localdomain] timed out waiting for all nodes to process published state [99361] (timeout [30s], pending nodes: [{bematech-do-es-15.localdomain}{I4PMZGm-Ss6DmzFXPtYjcg}{138.68.230.220}{138.68.230.220:9300}{max_local_storage_nodes=1}])
[2017-08-30 14:12:24,634][WARN ][cluster.service          ] [bematech-do-es-12.localdomain] cluster state update task [shard-started ([staging-index-8a18aa800e5911e785f24a8136534b63][2], node[Sw5V83ICS92_ypNNjpOZ2A], [R], v[63], s[INITIALIZING], a[id=XaavbcvWQjyMmdigL15RDw], unassigned_info[[reason=NODE_LEFT], at[2017-08-30T14:07:34.088Z], details[node_left[I4PMZGm-Ss6DmzFXPtYjcg]]], expected_shard_size[1640641495]), reason [after recovery (replica) from node [{bematech-do-es-18.localdomain}{63ZmTqpvSs-_zxMStLAWRg}{165.227.25.149}{165.227.25.149:9300}{max_local_storage_nodes=1}]],shard-started ([staging-index-8a18aa800e5911e785f24a8136534b63][4], node[4gyYmBDXTXK6BY_ujUQGTA], [R], v[58], s[INITIALIZING], a[id=uuhSCgQiSJu6zSL9iPZWGQ], unassigned_info[[reason=NODE_LEFT], at[2017-08-30T14:07:34.088Z], details[node_left[I4PMZGm-Ss6DmzFXPtYjcg]]], expected_shard_size[1627348711]), reason [after recovery (replica) from node [{bematech-do-es-07.localdomain}{elqF0TY7R4Cbb5-DZJih2g}{165.227.21.128}{165.227.21.128:9300}{max_local_storage_nodes=1}]]] took 30.2s above the warn threshold of 30s
#+END_EXAMPLE

** TODO ES run into yellow
#+BEGIN_EXAMPLE
[2017-09-02 00:25:42,396][INFO ][cluster.service          ] [bematech-do-es-01.localdomain] detected_master {bematech-do-es-12.localdomain}{-IC3Gx06T7WBqmGQvjOZJA}{138.197.200.214}{138.197.200.214:9300}{max_local_storage_nodes=1}, added {{bematech-do-es-12.localdomain}{-IC3Gx06T7WBqmGQvjOZJA}{138.197.200.214}{138.197.200.214:9300}{max_local_storage_nodes=1},}, reason: zen-disco-receive(from master [{bematech-do-es-12.localdomain}{-IC3Gx06T7WBqmGQvjOZJA}{138.197.200.214}{138.197.200.214:9300}{max_local_storage_nodes=1}])
[2017-09-02 00:25:55,535][WARN ][http.netty               ] [bematech-do-es-01.localdomain] Caught exception while handling client http traffic, closing connection [id: 0xf1078a49, /12.145.25.178:39686 => /138.197.215.132:9200]
java.io.IOException: No route to host
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:64)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)
	at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-09-02 00:28:21,815][INFO ][monitor.jvm              ] [bematech-do-es-01.localdomain] [gc][young][1039465][269011] duration [809ms], collections [1]/[1.1s], total [809ms]/[14.3h], memory [10.9gb]->[10.2gb]/[15.9gb], all_pools {[young] [664.1mb]->[4.3mb]/[665.6mb]}{[survivor] [34.5mb]->[35.6mb]/[83.1mb]}{[old] [10.2gb]->[10.2gb]/[15.1gb]}
#+END_EXAMPLE
** TODO interesting es indices api return
root@bematech-do-es-01:~/elasticsearch-cli-tool# curl $es_ip:9200/_cat/indices?v
{"error":{"root_cause":[{"type":"index_not_found_exception","reason":"no such index","resource.type":"index_or_alias","resource.id":"staging-index-8e2d11502c5511e79481a2f42be00f79-new2","index":"staging-index-8e2d11502c5511e79481a2f42be00f79-new2"}],"type":"index_not_found_exception","reason":"no such index","resource.type":"index_or_alias","resource.id":"staging-index-8e2d11502c5511e79481a2f42be00f79-new2","index":"staging-index-8e2d11502c5511e79481a2f42be00f79-new2"},"status":404}

** TODO Add more ES nodes to the cluster
** TODO ES re-indexing has failed
#+BEGIN_EXAMPLE
bematech-do-es-5/check_elasticsearch_health is WARNING:
WARN: elasticsearch cluster status is yellow, by checking 159.89.140.37:9200/_cluster/health


[9:33]
bematech-do-es-32/check_elasticsearch_health is WARNING:
WARN: elasticsearch cluster status is yellow, by checking 138.68.245.64:9200/_cluster/health


[9:33]
bematech-do-es-8/check_elasticsearch_health is WARNING:
WARN: elasticsearch cluster status is yellow, by checking 159.89.140.11:9200/_cluster/health


[9:33]
bematech-do-es-29/check_elasticsearch_health is WARNING:
WARN: elasticsearch cluster status is yellow, by checking 138.68.252.11:9200/_cluster/health


[9:33]
bematech-do-es-28/check_elasticsearch_health is WARNING:
WARN: elasticsearch cluster status is yellow, by checking 165.227.16.232:9200/_cluster/health


[9:34]
bematech-do-app-3/check_mdm_server_err_rate is CRITICAL:
ERROR: 5XX error rate in latest 15 minutes is over 8000.000000! Multiply by 10^12.


[9:36]
bematech-do-app-04/check_mdm_server_err_rate is CRITICAL:
ERROR: 5XX error rate in latest 15 minutes is over 8000.000000! Multiply by 10^12.


[9:36]
bematech-do-app-7/check_mdm_server_err_rate is CRITICAL:
ERROR: 5XX error rate in latest 15 minutes is over 8000.000000! Multiply by 10^12.


[9:37]
bematech-do-es-16/check_elasticsearch_health is WARNING:
WARN: elasticsearch cluster status is yellow, by checking 165.227.49.45:9200/_cluster/health


Denny Zhang (DevOps) [9:38 AM]
Re-indexing for some tenants has failed. I'm checking


Denny Zhang (DevOps) [9:42 AM]
added this Plain Text snippet: bematech-do-es-16(165.227.49.45)
bematech-do-es-16(165.227.49.45) has been out and in for a while.
```
[2018-01-11 14:23:50,113][INFO ][cluster.metadata ] [bematech-do-es-16.localdomain] [staging-index-8e2d11502c5511e79481a2f42be00f79-new3] update_mapping [mdmStagingChunk]
[2018-01-11 15:29:22,163][INFO ][cluster.metadata ] [bematech-do-es-16.localdomain] [staging-index-c277f9b097ef11e7a69b0e4789ade3a3-new1] update_mapping [invoicemanufacturingRejected]
[2018-01-11 15:29:47,293][WARN ][discovery.zen ] [bematech-do-es-16.localdomain] received a request to rejoin the cluster from [1f9IYNkeR0GuyS3wP1FZtg], current nodes: {{bematech-do-app-05node}{fV4_NNB_Q5KiDprpBsroZQ}{138.68.252.252}{138.68.252.252:9301}{data=false, master=false},{bematech-do-app-1node}{NRJjzjnuTyaDvu2AjumrPw}{138.68.41.110}{138.68.41.110:9301}{data=false, master=false},{bematech-do-es-33.localdomain}{NTD_Kzr0SRCTcI_IRc9cBg}{165.227.5.218}{165.227.5.218:9300}{max_local_storage_nodes=1},{bematech-do-es-12.localdomain}{fDGAFRHsROKPE6O1NKk8XA}{138.68.26.13}{138.68.26.13:9300}{max_local_storage_nodes=1},{bematech-do-es-22.localdomain}{AoQPbQ6CTj-u8pO6ERDqnQ}{138.68.5.190}{138.68.5.190:9300}{max_local_storage_nodes=1},{bematech-do-es-23.localdomain}{8FuAUMf1RM-kgAdjf6MEQA}{138.68.253.40}{138.68.253.40:9300}{max_local_storage_nodes=1},{bematech-do-es-11.localdomain}{gN8gzeZwT-6Unq0jt9irTw}{159.89.140.24}{159.89.140.24:9300}{max_local_storage_nodes=1},{bematech-do-es-13.localdomain}{Fcnx_F9BTSSUt72on-JF_Q}{165.227.49.160}{165.227.49.160:9300}{max_local_storage_nodes=1},{bematech-do-es-31.localdomain}{N0wNF_TYTdusdZuAsRJfnQ}{165.227.7.221}{165.227.7.221:9300}{max_local_storage_nodes=1},{bematech-do-es-20.localdomain}{CzkrHcehQcK3SHqF0pYXyw}{138.197.219.73}{138.197.219.73:9300}{max_local_storage_nodes=1},{bematech-do-app-04node}{vHSckkHOTi2jzssrV8OsNA}{138.68.252.224}{138.68.252.224:9301}{data=false, master=false},{bematech-do-es-29.localdomain}{M6CFA7QxQiivErq0WiosYg}{138.68.252.11}{138.68.252.11:9300}{max_local_storage_nodes=1},{bematech-do-app-6node}{Toh8xlbRR667znc_dKc6cg}{165.227.18.191}{165.227.18.191:9301}{data=false, master=false},{bematech-do-es-16.localdomain}{-X2pzwOZTEqfKe94dp1tGw}{165.227.49.45}{bematech-do-es-16/165.227.49.45:9300}{max_local_storage_nodes=1},{bematech-do-es-26.localdomain}{FU2MIuv5QEqxFBrK5a1rTQ}{165.227.7.247}{165.227.7.247:9300}{max_local_storage_nodes=1},{bematech-do-es-25.localdomain}{aNk6ANPgSL6e1F8gjuDagA}{138.68.253.103}{138.68.253.103:9300}{max_local_storage_nodes=1},{bematech-do-es-27.localdomain}{Om0fJREORgeHb83OMcsK0g}{138.197.195.41}{138.197.195.41:9300}{max_local_storage_nodes=1},{bematech-do-es-4.localdomain}{kb4pbM0pT2qAzMUQjppOgQ}{138.68.59.205}{138.68.59.205:9300}{max_local_storage_nodes=1},{bematech-do-es-28.localdomain}{MHXL23OPRIe6PMA09KBFew}{165.227.16.232}{165.227.16.232:9300}{max_local_storage_nodes=1},{bematech-do-es-21.localdomain}{dOuhq_PtS8KfyrVlOCpN1Q}{165.227.24.107}{165.227.24.107:9300}{max_local_storage_nodes=1},{bematech-do-es-5.localdomain}{j6kJk_3OQRutPEDNeKjVxg}{159.89.140.37}{159.89.140.37:9300}{max_local_storage_nodes=1},{bematech-do-es-8.localdomain}{1f9IYNkeR0GuyS3wP1FZtg}{159.89.140.11}{159.89.140.11:9300}{max_local_storage_nodes=1},{bematech-do-es-6.localdomain}{RRt1LR0hRYGjOtKrWSR2_A}{165.227.19.254}{165.227.19.254:9300}{max_local_storage_nodes=1},{bematech-do-app-2node}{XhoRBsf6TRuebxkbtdHVFQ}{138.68.241.113}{138.68.241.113:9301}{data=false, master=false},{bematech-do-app-3node}{uq3_a0KxQzamNvfNQlOhLQ}{138.68.252.199}{138.68.252.199:9301}{data=false, master=false},{bematech-do-es-24.localdomain}{4H6JfqzRSpiBmMI4hR7zGg}{138.68.255.53}{138.68.255.53:9300}{max_local_storage_nodes=1},{bematech-do-app-7node}{XwQEX5pjQ0GyVBe93liAwQ}{165.227.17.174}{165.227.17.174:9301}{data=false, master=false},{bematech-do-es-35.localdomain}{JX_NvdLFT7SENYpWuaZgWg}{165.227.17.250}{165.227.17.250:9300}{max_local_storage_nodes=1},{bematech-do-es-10.localdomain}{Q0zTnfgFQeqTCGgjodjXUA}{159.89.140.56}{159.89.140.56:9300}{max_local_storage_nodes=1},{bematech-do-es-2.localdomain}{U8qsG-1sQ9GYRBvuNYU_ZA}{138.68.246.50}{138.68.246.50:9300}{max_local_storage_nodes=1},{bematech-do-es-32.localdomain}{jmMXHuYITHqk9TCYU_PsgQ}{138.68.245.64}{138.68.245.64:9300}{max_local_storage_nodes=1},{bematech-do-es-34.localdomain}{8OlLE4wFQN2M1YY0QzlYZw}{165.227.13.11}{165.227.13.11:9300}{max_local_storage_nodes=1},{bematech-do-es-3.localdomain}{lyuFLGhoRLKjXqAfxreteQ}{165.227.22.228}{165.227.22.228:9300}{max_local_storage_nodes=1},{bematech-do-es-1.localdomain}{L1BFoh5lRY-zlpy0aW0vhw}{159.89.140.13}{159.89.140.13:9300}{max_local_storage_nodes=1},{bematech-do-es-9.localdomain}{rT0BQnslRAODF3vVwhiiXA}{159.89.140.52}{159.89.140.52:9300}{max_local_storage_nodes=1},}
@
```
Add Comment Collapse



Denny Zhang (DevOps) [9:42 AM]
I will run again, once es cluster is green



Nagios APP [9:42 AM]
bematech-do-app-6/check_mdm_server_err_rate is CRITICAL:
ERROR: 5XX error rate in latest 15 minutes is over 8000.000000! Multiply by 10^12.
#+END_EXAMPLE

http://bematech-do-jenkins.carol.ai:18080/job/ESReIndex/165/parameters/
#+BEGIN_EXAMPLE

17:10:08 green  open   config-index-a5893fc08f3a11e784e50e4789ade3a3-new3    1   2          0            0       477b           159b
17:10:08 green  open   master-index-6de6b440936711e783f0dec7170128a9        10   2      24016            0     27.3mb          9.2mb
17:10:08        close  staging-index-e4010da4110ba377d100f050cb4440db-new2
17:10:08 green  open   staging-index-e4010da4110ba377d100f050cb4440db-new3   5   2      33203            0    305.5mb        102.4mb
17:10:08 green  open   config-index-1154b0b041d211e7b7c04a8136534b63-new3    1   2          0            0       477b           159b
17:10:08 green  open   master-index-78917020e67c11e7ac7edec7170128a9-new3   10   2          0            0      4.6kb          1.5kb
17:10:08 green  open   staging-index-d3ae95b0d12811e69edf0401f8d88501-new3   5   2          0            0      2.3kb           795b
17:10:08 green  open   staging-index-d3ae95b0d12811e69edf0401f8d88501-new2   5   2      13335            7     42.6mb         14.2mb
17:10:08 green  open   config-index-40e0def05c1f11e7a9954a8136534b63-new3    1   2        388            1      1.4mb        541.4kb
17:10:08        close  master-index-c277f9b097ef11e7a69b0e4789ade3a3
17:10:08 green  open   config-index-7a90c9f0b81611e7bcc70e4789ade3a3-new3    1   2          0            0       477b           159b
17:10:08 green  open   config-index-d104b4e0843111e7b589dec7170128a9         1   2        130           11    902.5kb        300.8kb
17:10:08 green  open   config-index-92c10080cf6811e7a2610e4789ade3a3-new3    1   2          0            0       477b           159b
17:10:08 green  open   config-index-f5c8d070d9a111e7844bdec7170128a9         1   2       1424        16954     10.2mb          4.5mb
17:10:08 green  open   config-index-0f65ca607d5911e7b17a0e4789ade3a3         1   2          4            0     88.2kb         29.4kb
17:10:08 green  open   staging-index-9961ac10d5ed11e785ebdec7170128a9       10   2          4            0      2.8mb        967.9kb
17:10:08        close  staging-index-c277f9b097ef11e7a69b0e4789ade3a3
17:10:08 green  open   config-index-0acedf50628d11e7b815a2f42be00f79-new3    1   2          0            0       477b           159b
17:10:08 green  open   config-index-92c10080cf6811e7a2610e4789ade3a3         1   2         18            0     30.8mb         10.2mb
17:10:08
100 44625  100 44625    0     0   7721      0  0:00:05  0:00:05 --:--:-- 12475
17:10:08 + assert_index_status 138.68.246.50 9200 staging-index-da1c1280ac9b11e68e250401f8d88501-new3
17:10:08 + local es_ip=138.68.246.50
17:10:08 + local es_port=9200
17:10:08 + local index_name=staging-index-da1c1280ac9b11e68e250401f8d88501-new3
17:10:08 ++ curl '138.68.246.50:9200/_cat/shards?v'
17:10:08 ++ grep staging-index-da1c1280ac9b11e68e250401f8d88501-new3
17:10:08 ++ grep -c -v STARTED
17:10:08   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
17:10:08                                  Dload  Upload   Total   Spent    Left  Speed
17:10:08
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:03 --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:04 --:--:--     0
  1 1336k    1 16299    0     0   3481      0  0:06:33  0:00:04  0:06:29  3481
100 1336k  100 1336k    0     0   285k      0  0:00:04  0:00:04 --:--:--  383k
17:10:13 index(staging-index-da1c1280ac9b11e68e250401f8d88501-new3) is up and running
17:10:13 + '[' 0 = 0 ']'
17:10:13 + echo 'index(staging-index-da1c1280ac9b11e68e250401f8d88501-new3) is up and running'
17:10:13 + '[' no = no ']'
17:10:13 + log 'Reindex index. Attention: this will take a very long time, if the index is big'
17:10:13 + local 'msg=Reindex index. Attention: this will take a very long time, if the index is big'
17:10:13 ++ date '+[%Y-%m-%d %H:%M:%S]'
17:10:13 [2018-01-12 01:09:59] Reindex index. Attention: this will take a very long time, if the index is big
17:10:13 + date_timestamp='[2018-01-12 01:09:59]'
17:10:13 + echo -ne '[2018-01-12 01:09:59] Reindex index. Attention: this will take a very long time, if the index is big\n'
17:10:13 + '[' -n '' ']'
17:10:13 + curl -XPOST 'http://138.68.246.50:9200/_reindex?pretty' -d '
17:10:13      {
17:10:13        "conflicts": "proceed",
17:10:13        "source": {
17:10:13        "index": "staging-index-da1c1280ac9b11e68e250401f8d88501-new2",
17:10:13        "size": "800"
17:10:13     },
17:10:13        "dest": {
17:10:13        "index": "staging-index-da1c1280ac9b11e68e250401f8d88501-new3",
17:10:13        "op_type": "create"
17:10:13     }
17:10:13  }'
17:10:13 + tee -a /var/log/run_reindex_sh_165.log
17:10:13   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
17:10:13                                  Dload  Upload   Total   Spent    Left  Speed
17:10:13
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
100   280    0     0  100   280      0    233  0:00:01  0:00:01 --:--:--   233
100   280    0     0  100   280      0    127  0:00:02  0:00:02 --:--:--   127
100   280    0     0  100   280      0     87  0:00:03  0:00:03 --:--:--    87
100   280    0     0  100   280      0     66  0:00:04  0:00:04 --:--:--    66
...
100   280    0     0    0   280      0      0 --:--:--  0:09:21 --:--:--     0
100   280    0     0    0   280      0      0 --:--:--  0:09:22 --:--:--     0
100   280    0     0    0   280      0      0 --:--:--  0:09:23 --:--:--     0
100   280    0     0    0   280      0      0 --:--:--  0:09:24 --:--:--     0{
17:19:38   "took" : 565211,
17:19:38   "timed_out" : false,
17:19:38   "total" : 72911606,
17:19:38   "updated" : 0,
17:19:38   "created" : 0,
17:19:38   "batches" : 289,
17:19:38   "version_conflicts" : 231200,
17:19:38   "noops" : 0,
17:19:38   "retries" : 0,
17:19:38   "failures" : [ {
17:19:38     "shard" : -1,
17:19:38     "index" : null,
17:19:38     "reason" : {
17:19:38       "type" : "es_rejected_execution_exception",
17:19:38       "reason" : "rejected execution of org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler@76ebc7b5 on EsThreadPoolExecutor[search, queue capacity = 1000, org.elasticsearch.common.util.concurrent.EsThreadPoolExecutor@6d13d801[Running, pool size = 19, active threads = 19, queued tasks = 1000, completed tasks = 2446638431]]"
17:19:38     }
17:19:38   } ]
17:19:38 }
17:19:38
100   946  100   666    0   280      1      0  0:11:06  0:09:25  0:01:41    87
100   946  100   666    0   280      1      0  0:11:06  0:09:25  0:01:41   113
17:19:38
17:19:38 real	9m25.226s
17:19:38 user	0m0.056s
17:19:38 sys	0m0.026s
17:19:38 + tail -n 5 /var/log/run_reindex_sh_165.log
17:19:38 + grep '"failures" : \[ \]'
17:19:38 + log 'ERROR to run previous curl command'
17:19:38 + local 'msg=ERROR to run previous curl command'
17:19:38 ++ date '+[%Y-%m-%d %H:%M:%S]'
17:19:38 [2018-01-12 01:19:24] ERROR to run previous curl command
17:19:38 + date_timestamp='[2018-01-12 01:19:24]'
17:19:38 + echo -ne '[2018-01-12 01:19:24] ERROR to run previous curl command\n'
17:19:38 + '[' -n '' ']'
17:19:38 + tail -n 5 /var/log/run_reindex_sh_165.log
17:19:38       "type" : "es_rejected_execution_exception",
17:19:38       "reason" : "rejected execution of org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler@76ebc7b5 on EsThreadPoolExecutor[search, queue capacity = 1000, org.elasticsearch.common.util.concurrent.EsThreadPoolExecutor@6d13d801[Running, pool size = 19, active threads = 19, queued tasks = 1000, completed tasks = 2446638431]]"
17:19:38     }
17:19:38   } ]
17:19:38 }
17:19:38 + exit 1
17:19:38 Build step 'Execute shell' marked build as failure
17:19:40 Finished: FAILURE
Page generated: Jan 11, 2018 5:30:19 PM PSTREST APIJenkins ver. 2.46.3
#+END_EXAMPLE

** TODO es run into red
*** healthcheck
root@bematech-do-es-34:/var/log/elasticsearch# curl $es_ip:9200/_cluster/health?pretty
{
  "error" : {
    "root_cause" : [ {
      "type" : "master_not_discovered_exception",
      "reason" : null
    } ],
    "type" : "master_not_discovered_exception",
    "reason" : null
  },
  "status" : 503
}
root@bematech-do-es-34:/var/log/elasticsearch#
You have new mail in /var/mail/root
root@bematech-do-es-34:/var/log/elasticsearch# curl $es_ip:9200/_cluster/health?pretty
{
  "cluster_name" : "mdm",
  "status" : "red",
  "timed_out" : false,
  "number_of_nodes" : 30,
  "number_of_data_nodes" : 28,
  "active_primary_shards" : 1954,
  "active_shards" : 4271,
  "relocating_shards" : 0,
  "initializing_shards" : 67,
  "unassigned_shards" : 2148,
  "delayed_unassigned_shards" : 199,
  "number_of_pending_tasks" : 383,
  "number_of_in_flight_fetch" : 0,
  "task_max_waiting_in_queue_millis" : 1250753,
  "active_shards_percent_as_number" : 65.8495220474869
}

** TODO ES improve re-index performance
#+BEGIN_EXAMPLE
Mitu Singh [4:18 PM]
https://discuss.elastic.co/t/improving-performance-of-reindex-api/58028/6

Denny Zhang (DevOps) [4:19 PM]
Yes, we tried to change the batch size to 1000
However mdm will complain slowness and errors. What's worse. es even run into red twice. So we lower it to 500 now.

Mitu Singh [4:22 PM]
ok

Denny Zhang (DevOps) [4:30 PM]
But we haven't tried to change `refresh interval`.

We can do some experiments against it. Probably this will come with some cost.
Looks like positive to us.
Thanks, @mitu
#+END_EXAMPLE
** TODO enforce check about ES hotthreads
** TODO [#A] Why only 2 ES runs into full GC requently
** TODO [#A] sometimes ES list shards API will stuck for more than 1 minute
** TODO cb node, es node -> bring prod env fail for some data, need manual intervine
** TODO update doc: When es node runs into single node, what to do?
** TODO [#A] elasticsearch: close indices and remove VMs with rebalancing, what if I want to re-open the indices?
* TODO [#A] How to migrate ES2 to ES5 without data loss?           :noexport:
